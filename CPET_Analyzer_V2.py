# === Combined CPET Directory + Dashboard ===
# Auto-generated by ChatGPT: keeps your original apps intact, just renamed & bridged.
# Files inlined: CPET_Directory.py (as make_directory_app) and PythonOnlyDashboard.py (as make_dashboard_app)

# ---- BEGIN: PythonOnlyDashboard (renamed) ----
# CPETDashboard_webview.py
# Dash (v3) + dash-mantine-components (v2) wrapped in a native desktop window via pywebview.

import threading, time, socket, sys
import numpy as np
import dash
from dash import html, dcc
import dash_mantine_components as dmc
import plotly.graph_objects as go
import pandas as pd
from pathlib import Path
import os
import math

# --- Colors to match VT_Testing.pyw ---
COL_BLUE        = "#377EB7"
COL_ORANGE      = "#FF7F0E"
COL_BLUE_DARK   = "#1E5F96"
COL_ORANGE_DARK = "#C85A0A"
COL_PURPLE      = "#800080"
COL_RED         = "#FF0000"
COL_GREEN       = "#008C46"

# --- LOESS settings to match VT_Testing.pyw ---
LOESS_SPAN_FRAC       = 0.30
LOESS_MIN_NEIGHBORS   = 9
LOESS_VO2_SPAN_FRAC   = 0.55
LOESS_VO2_MIN_NEI     = 25

# --- Broken-stick constraints (match VT_Testing.pyw) ---
BS_MIN_POINTS_PER_SIDE = 12
BS_MIN_XSPAN = 0.5
BS_Q_LO = 0.15
BS_Q_HI = 0.85
BS2_PRE_SLOPE_MIN = 0.85
BS2_PRE_SLOPE_MAX = 1.20
BS2_MID_SLOPE_MIN = 1.10
VSLOPE_GAP_POINTS = 1  # skip this many VO2 samples after a breakpoint

def loess(x, y, span_frac=LOESS_SPAN_FRAC, min_neighbors=LOESS_MIN_NEIGHBORS):
    """
    Tricube-weighted locally linear smoother (same math as VT_Testing.pyw)
    """
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    n = len(x)
    out = np.full(n, np.nan)

    mask = np.isfinite(x) & np.isfinite(y)
    xv = x[mask]; yv = y[mask]
    m = len(xv)
    if m == 0:
        return out

    k = max(min_neighbors, int(np.ceil(span_frac * m)))
    k = min(k, m)

    for i in range(n):
        if not (np.isfinite(x[i]) and np.isfinite(y[i])):
            continue
        xi = x[i]
        d = np.abs(xv - xi)
        # distance to k-th nearest neighbor
        h = np.partition(d, k-1)[k-1]
        if h <= 0:
            out[i] = y[i]
            continue
        # tricube kernel weights
        w = (1.0 - (d / h) ** 3) ** 3
        use = w > 0
        if not np.any(use):
            out[i] = y[i]
            continue
        w = w[use]
        X = np.column_stack([np.ones(np.sum(use)), xv[use]])
        Y = yv[use]
        # weighted least squares
        W = np.diag(w)
        try:
            beta = np.linalg.lstsq(W @ X, W @ Y, rcond=None)[0]
            out[i] = beta[0] + beta[1] * xi
        except Exception:
            out[i] = y[i]
    return out

# ---------- VT detectors (same math/thresholds as VT_Testing.pyw) ----------
def detect_min_time(t, y, q_lo=0.05, q_hi=0.95):
    t = np.asarray(t, float); y = np.asarray(y, float)
    n = len(t)
    mask = np.isfinite(t) & np.isfinite(y)
    if mask.sum() < 3: return np.nan
    idx = np.where(mask)[0]
    i_lo = max(idx[0], int(math.ceil(q_lo * n)))
    i_hi = min(idx[-1], int(math.floor(q_hi * n)))
    if i_lo >= i_hi: i_lo, i_hi = idx[0], idx[-1]
    seg = np.arange(i_lo, i_hi + 1, dtype=int)
    seg = seg[np.isfinite(y[seg])]
    if len(seg) == 0: return np.nan
    i_min = seg[np.argmin(y[seg])]
    return t[i_min]

def moving_slope(t, y, k):
    t = np.asarray(t, float); y = np.asarray(y, float)
    n = len(t); out = np.full(n, np.nan)
    for i in range(n):
        L = max(0, i-k); U = min(n-1, i+k)
        tx = t[L:U+1]; yy = y[L:U+1]
        m = np.isfinite(tx) & np.isfinite(yy)
        tx = tx[m]; yy = yy[m]; cnt = len(tx)
        if cnt >= 2:
            Sx = tx.sum(); Sy = yy.sum()
            Sxx = (tx*tx).sum(); Sxy = (tx*yy).sum()
            denom = cnt*Sxx - Sx*Sx
            if abs(denom) > 1e-12:
                out[i] = (cnt*Sxy - Sx*Sy) / denom
    return out

def detect_vevco2_steepest_rise_start_strict(t, y_smooth, slope_window_pts=12,
                                              pos_slope_threshold=0.02, min_run=10):
    t = np.asarray(t, float); y = np.asarray(y_smooth, float)
    n = len(t)
    if n < 5: return np.nan
    mask = np.isfinite(y)
    if mask.sum() == 0: return np.nan
    i_min = np.where(mask)[0][0]
    i_max = np.where(mask)[0][-1]
    if i_min >= i_max-2: return np.nan
    s = moving_slope(t, y, slope_window_pts//2)
    for i in range(i_min, i_max - min_run):
        run_ok = True
        for j in range(i, i+min_run):
            if not (np.isfinite(s[j]) and s[j] >= pos_slope_threshold):
                run_ok = False; break
        if run_ok:
            return t[i]
    # fallback: find longest run after 1st positive slope
    for i in range(i_min, i_max-min_run):
        if np.isfinite(s[i]) and s[i] >= pos_slope_threshold:
            k = i; run = 0
            while k < i_max and np.isfinite(s[k]) and s[k] >= pos_slope_threshold:
                run += 1; k += 1
            if run >= min_run: return t[i]
            break
    return np.nan

def detect_vt2_petco2_steepest_run_start(t, y_smooth, slope_window_pts=12,
                                         min_run=10, neg_slope_threshold=-0.03,
                                         min_cum_drop=0.0):
    t = np.asarray(t, float); y = np.asarray(y_smooth, float)
    n = len(t)
    if n < 5: return np.nan
    mask = np.isfinite(y)
    if mask.sum() == 0: return np.nan
    i_max = np.where(mask)[0][np.argmax(y[mask])]
    if i_max >= n-2: return np.nan
    s = moving_slope(t, y, slope_window_pts//2)
    best_i = -1; best_avg = np.inf
    for i in range(i_max+1, n - min_run):
        block = s[i:i+min_run]
        if np.all(np.isfinite(block)):
            if min_cum_drop > 0 and (np.isfinite(y[i]) and np.isfinite(y[i+min_run])):
                if (y[i] - y[i+min_run]) < min_cum_drop:
                    continue
            avg = float(np.mean(block))
            if avg < best_avg: best_avg, best_i = avg, i
    if best_i < 0: return np.nan
    # walk back to first point in this negative-slope run
    k = best_i
    while k > i_max+1 and np.isfinite(s[k-1]) and s[k-1] <= neg_slope_threshold:
        k -= 1
    return t[k]

# ---------- Broken-stick V-slope (2 breaks) ----------
def _hinge(x, t):
    h = x - t; h[h < 0] = 0.0; return h

def broken_stick_fit2(x, y,
                      min_span=BS_MIN_XSPAN,
                      min_pts=BS_MIN_POINTS_PER_SIDE,
                      q_lo=BS_Q_LO, q_hi=BS_Q_HI,
                      pre_min=BS2_PRE_SLOPE_MIN,
                      pre_max=BS2_PRE_SLOPE_MAX,
                      mid_min=BS2_MID_SLOPE_MIN):
    x = np.asarray(x, float); y = np.asarray(y, float)
    mask = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)
    xv = x[mask]; yv = y[mask]
    m = len(xv)
    if m < 3*min_pts: return None
    order = np.argsort(xv); xv = xv[order]; yv = yv[order]
    k_lo = max(min_pts, int(math.ceil(q_lo*m)))
    k_hi = min(m - min_pts, int(math.floor(q_hi*m)))
    if k_lo >= k_hi: return None

    best = dict(sse=np.inf)
    for k1 in range(k_lo, k_hi - min_pts + 1):
        t1 = xv[k1]
        if (t1 - xv[0]) < min_span: continue
        for k2 in range(k1 + min_pts, k_hi + 1):
            t2 = xv[k2]
            if (t2 - t1) < min_span: continue
            if (xv[-1] - t2) < min_span: continue
            H1, H2 = _hinge(xv, t1), _hinge(xv, t2)
            A = np.column_stack([np.ones_like(xv), xv, H1, H2])
            try:
                beta, *_ = np.linalg.lstsq(A, yv, rcond=None)
            except Exception:
                continue
            b0,b1,b2,b3 = map(float, beta)
            s1 = b1; s2 = b1 + b2; s3 = b1 + b2 + b3
            if not (pre_min <= s1 <= pre_max): continue
            if not (s2 >= mid_min): continue
            yhat = A @ beta
            sse = float(np.sum((yv - yhat)**2))
            if sse < best["sse"]:
                best = dict(sse=sse, t1=float(t1), t2=float(t2),
                            b0=b0, b1=b1, b2=b2, b3=b3,
                            s1=s1, s2=s2, s3=s3)
    return None if not np.isfinite(best.get("sse", np.inf)) else best

def _vslope_default_segs(bs, vo2_array):
    """Pre/mid/post segments; gap of VSLOPE_GAP_POINTS on the MIN side after each break."""
    if not bs or vo2_array is None: return None
    xs = np.asarray(vo2_array, float)
    xs = np.sort(np.unique(xs[np.isfinite(xs)]))
    if xs.size < 2: return None

    n = xs.size; b0,b1,b2,b3 = bs["b0"], bs["b1"], bs["b2"], bs["b3"]
    t1,t2 = float(bs["t1"]), float(bs["t2"])
    g = int(VSLOPE_GAP_POINTS)

    def f_pre(x):  return b0 + b1*x
    def f_mid(x):  return b0 + b1*x + b2*max(0, x - t1)
    def f_post(x): return b0 + b1*x + b2*max(0, x - t1) + b3*max(0, x - t2)

    i1 = int(np.searchsorted(xs, t1, side="left"))
    i2 = int(np.searchsorted(xs, t2, side="left"))

    pre_start, pre_end = 0, min(n - 1, i1)
    if pre_end < n and xs[pre_end] > t1 and pre_end > 0: pre_end -= 1

    mid_start, mid_end = min(n - 1, i1 + g), min(n - 1, i2)
    if mid_end < n and xs[mid_end] > t2 and mid_end > 0: mid_end -= 1

    post_start, post_end = min(n - 1, i2 + g), n - 1
    post_start = min(post_start, post_end)

    segs = []
    if pre_end > pre_start:
        x0, x1 = xs[pre_start], xs[pre_end]; segs.append(((x0, f_pre(x0)), (x1, f_pre(x1))))
    if mid_end > mid_start:
        x0, x1 = xs[mid_start], xs[mid_end]; segs.append(((x0, f_mid(x0)), (x1, f_mid(x1))))
    if post_end > post_start:
        x0, x1 = xs[post_start], xs[post_end]; segs.append(((x0, f_post(x0)), (x1, f_post(x1))))
    return segs

def _interp_at_x(x, y, x0):
    x = np.asarray(x, float); y = np.asarray(y, float)
    if not np.isfinite(x0): return np.nan
    for i in range(len(x) - 1):
        if np.isfinite(y[i]) and np.isfinite(y[i+1]):
            if (x[i] <= x0 <= x[i+1]) or (x[i] >= x0 >= x[i+1]):
                if x[i+1] != x[i]:
                    return float(y[i] + (y[i+1]-y[i])*(x0 - x[i])/(x[i+1]-x[i]))
                else:
                    return float(y[i])
    return np.nan

def _invert_y_to_x(x, y, y0):
    x = np.asarray(x, float); y = np.asarray(y, float)
    if not np.isfinite(y0): return np.nan
    for i in range(len(x) - 1):
        if np.isfinite(y[i]) and np.isfinite(y[i+1]):
            yi, yj = y[i], y[i+1]
            if (yi <= y0 <= yj) or (yi >= y0 >= yj):
                if yj != yi:
                    return float(x[i] + (x[i+1]-x[i])*(y0 - yi)/(yj - yi))
                else:
                    return float(x[i])
    return np.nan

# ----------------------------
# Sample Data (mirrors your canvas)
# ----------------------------
sample = {
    "context": {"modality": "bike", "protocol": "Ramp 25 W/min", "altitude_m": 210},
    "subject": {"name": "Alex Rider", "id": "A-1029", "age": 24, "sex": "M", "height_cm": 178, "mass_kg": 75},
    "kpi": {
        "vo2peak_L_min": 4.2, "vo2peak_ml_kg_min": 56.0, "vo2peak_pct_pred": 112,
        "peak_work_W": 360, "tte_s": 720,
        "rer_max": 1.17, "hr_peak": 196, "hr_pct_max": 98,
        "o2pulse_peak_ml_beat": 21.4, "ve_vco2_slope": 28.9, "petco2_nadir_mmHg": 39,
        "bp_peak_mmHg": "186/82",
    },
    "thresholds": {
        "vt1": {"t_s": 360, "hr": 158, "hr_pct_max": 79, "vo2_ml_kg_min": 38.5, "vo2_pct_peak": 69, "rer": 0.95,
                "work_W": 220, "ve_vo2": 26.1, "ve_vco2": 28.5, "petco2_mmHg": 42},
        "vt2": {"t_s": 600, "hr": 182, "hr_pct_max": 91, "vo2_ml_kg_min": 50.2, "vo2_pct_peak": 90, "rer": 1.05,
                "work_W": 310, "ve_vo2": 32.0, "ve_vco2": 30.5, "petco2_mmHg": 40},
    },
    "vslope": {"m1": 0.82, "m2": 1.02, "m3": 1.14, "r2": [0.98, 0.99, 0.97]},
    "economy": {
        "bike_vo2_ml_kg_min_at_W": {100: 22.0, 150: 26.5, 200: 31.0},
        "delta_vo2_per_W": 10.4, "oues": 2.35, "oues_per_kg": 0.031, "delta_hr_per_vo2": 2.8
    },
    "ventilation": {"ve_peak_L_min": 148},
}

def pct(x):    return f"{x:.0f}%"
def one(x):    return f"{x:.1f}"
def two(x):    return f"{x:.2f}"
def secs(x):   return f"{int(round(x))} s"

def vo2_abs_at(vt, vo2peak_L_min):
    return (vo2peak_L_min or 0) * ((vt.get("vo2_pct_peak", 0) or 0) / 100.0)

# ----------------------------
# Demo time-series
# ----------------------------
T = np.linspace(0, 780, 300)  # seconds
vo2 = 0.5 + 3.9 * (1 / (1 + np.exp(-(T-350)/80)))                          # VO₂
vco2 = 0.45 + 3.8 * (1 / (1 + np.exp(-(T-360)/80))) + 0.15*(T>600)         # VCO₂
ve_vo2 = 25 + 8*np.sin(T/180*np.pi)                                        # VE/VO₂
ve_vco2 = 24 + 6*np.cos(T/160*np.pi)                                       # VE/VCO₂
peto2 = 110 - 8*np.exp(-(T-360)**2/40000)                                  # PetO₂
petco2 = 38 + 3*np.exp(-(T-520)**2/50000) - 2*np.exp(-(T-360)**2/60000)    # PetCO₂
rer = vco2 / vo2

# ----------------------------
# Plotly Figures
# ----------------------------
def fig_vslope():
    m1, m2, m3 = sample["vslope"]["m1"], sample["vslope"]["m2"], sample["vslope"]["m3"]
    bp1, bp2 = 2.5, 3.7  # VO₂ breakpoints (L/min)
    x = np.concatenate([np.linspace(0.8, bp1, 30),
                        np.linspace(bp1, bp2, 30),
                        np.linspace(bp2, 4.4, 30)])
    y = np.piecewise(x,
                     [x<=bp1, (x>bp1)&(x<=bp2), x>bp2],
                     [lambda t: m1*t,
                      lambda t: m2*(t - bp1) + m1*bp1,
                      lambda t: m3*(t - bp2) + (m2*(bp2 - bp1) + m1*bp1)])
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=x, y=y, mode="lines", name="VCO₂ vs VO₂"))
    fig.add_vline(x=vo2_abs_at(sample["thresholds"]["vt1"], sample["kpi"]["vo2peak_L_min"]), line_dash="dot", line_color="#888")
    fig.add_vline(x=vo2_abs_at(sample["thresholds"]["vt2"], sample["kpi"]["vo2peak_L_min"]), line_dash="dot", line_color="#888")
    fig.add_annotation(text=f"m₁={two(m1)}<br>m₂={two(m2)}<br>m₃={two(m3)}",
                       xref="paper", yref="paper", x=0.98, y=0.98, showarrow=False,
                       align="right", bgcolor="rgba(255,255,255,0.6)")
    fig.update_layout(margin=dict(l=12,r=12,t=8,b=12), height=260,
                      xaxis_title="VO₂ (L·min⁻¹)", yaxis_title="VCO₂ (L·min⁻¹)")
    return fig

def fig_lines(xs, series, labels, x_title, y_title):
    fig = go.Figure()
    for y, label in zip(series, labels):
        fig.add_trace(go.Scatter(x=xs, y=y, mode="lines", name=label))
    fig.update_layout(margin=dict(l=12,r=12,t=8,b=12), height=260,
                      xaxis_title=x_title, yaxis_title=y_title,
                      showlegend=False)
    return fig

fig_vo2 = fig_lines(T, [vo2], ["VO₂"], "Time (s)", "VO₂ (L·min⁻¹)")
fig_ve_equiv = fig_lines(T, [ve_vo2, ve_vco2], ["VE/VO₂", "VE/VCO₂"], "Time (s)", "Ventilatory equivalents")
fig_pet = fig_lines(T, [peto2, petco2], ["PetO₂", "PetCO₂"], "Time (s)", "Partial pressure (mmHg)")
fig_rer = fig_lines(T, [rer], ["RER"], "Time (s)", "RER")
fig_vs = fig_vslope()

# ----------------------------
# UI helpers (cards/tiles)
# ----------------------------
def KPITile(label, value, sub=None, warn=False):
    return dmc.Paper(
        withBorder=True, shadow="xs", radius="xl", p="md",
        children=[
            dmc.Text(label, size="xs", tt="uppercase", c="dimmed"),
            dmc.Text(value, fw=600, size="lg"),
            dmc.Text(sub, size="xs", c="dimmed") if sub else None
        ],
        style={
            "background": "rgba(255,255,255,0.7)",
            "borderColor": "#e5e7eb",
        } | ({"borderColor": "#fca5a5", "background": "rgba(254,242,242,0.6)"} if warn else {})
    )

def Card(title, subtitle=None, right=None, content=None):
    header = dmc.Group([
        dmc.Stack([dmc.Text(title, fw=600, size="sm"), dmc.Text(subtitle, size="xs", c="dimmed")] if subtitle else [dmc.Text(title, fw=600, size="sm")]),
        right or html.Div()
    ], justify="space-between")
    return dmc.Paper(
        withBorder=True, shadow="sm", radius="xl", p=0,
        children=[dmc.Box(header, px="md", pt="md"), dmc.Box(content, p="md")]
    )

def LegendMenu(component_id: str, options: list[tuple[str, str]]):
    """
    component_id: e.g., 'legend-vslope' or 'legend-vo2'
    options: [(value, label), ...]  e.g., [('slope','Slope lines (green)'), ('vt1','VT1')]
    """
    default_vals = [v for v, _ in options]  # everything ON by default

    def swatch(val: str):
        # line sample
        def line(color: str, style: str = "solid"):
            return dmc.Box(style={
                "width": "22px", "height": 0,
                "borderTop": f"3px {style} {color}",
                "marginTop": "7px"
            })
        # dot sample (points)
        def dot(color: str):
            return dmc.Box(style={
                "width": "10px", "height": "10px",
                "borderRadius": "50%", "background": color
            })

        # --- back-compat (single-series menus) ---
        if val == "slope":   return line(COL_GREEN, "solid")
        if val == "vt1":     return line(COL_PURPLE, "dotted")
        if val == "vt2":     return line(COL_RED,    "dotted")
        if val == "trace":   return line(COL_BLUE_DARK, "solid")
        if val == "points":  return dot(COL_BLUE)

        # --- new multi-series keys: e.g., vevo2_pts / vevo2_tr, petco2_pts / petco2_tr, rer_tr ---
        if "_" in val:
            base, kind = val.rsplit("_", 1)   # base: vevo2|vevco2|peto2|petco2|rer ; kind: pts|tr
            base_colors = {
                "vevo2":  (COL_BLUE,   COL_BLUE_DARK),
                "vevco2": (COL_ORANGE, COL_ORANGE_DARK),
                "peto2":  (COL_BLUE,   COL_BLUE_DARK),
                "petco2": (COL_ORANGE, COL_ORANGE_DARK),
                "rer":    (COL_BLUE,   COL_BLUE_DARK),
            }.get(base, (COL_BLUE, COL_BLUE_DARK))
            if kind == "pts":
                return dot(base_colors[0])
            if kind == "tr":
                return line(base_colors[1], "solid")

        # fallback (no swatch)
        return dmc.Box()

    checks = [
        dmc.Checkbox(
            value=val,
            label=dmc.Group([swatch(val), dmc.Text(lbl)], gap="xs", align="center")
        )
        for val, lbl in options
    ]

    return dmc.Popover(
        width=240,
        position="bottom-end",
        withArrow=True,
        children=[
            dmc.PopoverTarget(
                dmc.Button("Legend", size="xs", variant="light", color="gray")
            ),
            dmc.PopoverDropdown(dmc.CheckboxGroup(id=component_id, value=default_vals, children=checks)),
        ],
    )

# ----------------------------
# Threshold detection table (Test | VT1 | VT2)
# ----------------------------
def threshold_detection_table(vt_source=None):
    """
    Render a single table with:
    [ Test ] | [ VT1: VO2, Time, RER, %VO2 Max, Confidence ] | [ VT2: VO2, Time, RER, %VO2 Max, Confidence ]

    vt_source (optional): dict with keys 'vt1' and 'vt2' holding the values you already show elsewhere.
    If omitted, this function will fall back to whatever you were using before (e.g., sample[...]).

    Expect each vt dict to expose:
      - 'vo2' (absolute L/min) or 'vo2_L_min'
      - 't_s' (time in seconds) or 't_min'
      - 'rer'
      - 'vo2_pct_peak' (0-1 or 0-100)
      - 'confidence' ('Low'|'Med'|'High')   # if not present we'll default sensibly
    We intentionally repeat the same numbers in each row for now, since per-detector
    breakdowns aren’t stored yet. (You can wire per-detector values later without
    changing this layout.)
    """

    # ---------- colors ----------
    VT1_BG  = "rgba(112, 72, 232, 0.06)"  # grape
    VT1_HDR = "rgba(112, 72, 232, 0.18)"
    VT1_TX  = "#7048E8"
    VT2_BG  = "rgba(230, 73, 73, 0.06)"   # red
    VT2_HDR = "rgba(230, 73, 73, 0.18)"
    VT2_TX  = "#E64949"

    # ---------- formatting helpers ----------
    import math
    def fmt2(x):
        try:
            xv = float(x)
            return f"{xv:.2f}"
        except Exception:
            return "—"

    def fmt_time_min(v):
        # supports t_s (seconds) or t_min
        if v is None:
            return "—"
        try:
            if "t_min" in v:  # dict
                tm = float(v["t_min"])
            elif "t_s" in v:
                tm = float(v["t_s"]) / 60.0
            else:
                tm = float(v)  # already minutes
            if not math.isfinite(tm): return "—"
            return f"{tm:.2f}"
        except Exception:
            return "—"

    def pct(x):
        try:
            xv = float(x)
            if xv <= 1.0:  # handle 0-1 inputs
                xv *= 100.0
            return f"{xv:.0f}%"
        except Exception:
            return "—"

    def conf_badge(level):
        level = (level or "").strip().capitalize()
        color = {"High":"green", "Med":"yellow", "Low":"red"}.get(level, "gray")
        return dmc.Badge(level or "—", color=color, variant="light", radius="sm")

    # ---------- data pull (reuse your existing values) ----------
    if vt_source and isinstance(vt_source, dict):
        vt1 = vt_source.get("vt1", {})
        vt2 = vt_source.get("vt2", {})
    else:
        # fall back to whatever you were using before
        # (replace with your own getters if you already have a Store)
        vt1 = sample["thresholds"]["vt1"]
        vt2 = sample["thresholds"]["vt2"]

    # normalize keys to a small accessor
    def vt_vals(vt):
        vo2 = vt.get("vo2") or vt.get("vo2_L_min")
        # time: accept t_min or t_s
        tmin = vt.get("t_min")
        if tmin is None and "t_s" in vt:
            tmin = vt["t_s"] / 60.0
        rer = vt.get("rer")
        vo2pct = vt.get("vo2_pct_peak")
        conf = vt.get("confidence") or vt.get("conf")
        return vo2, tmin, rer, vo2pct, conf

    vt1_vo2, vt1_tmin, vt1_rer, vt1_pct, vt1_conf = vt_vals(vt1)
    vt2_vo2, vt2_tmin, vt2_rer, vt2_pct, vt2_conf = vt_vals(vt2)

    # rows as per your spec
    tests = [
        "V-Slope",
        "VE/VO₂ , VE/VCO₂",
        "PetO₂ , PetCO₂",
        "Average",
    ]

    # build rows: left “Test”, then 5 VT1 cells, then 5 VT2 cells
    # --- if vt_source has per-row values, use them; else fall back to sample placeholders ---
    tests_left  = ["V-Slope", "VE/VO₂ minimum", "PetO₂ minimum", "Average"]
    tests_right = ["V-Slope", "VE/VCO₂ rise (start)", "PetCO₂ drop (start)", "Average"]

    def _fmt2(x):
        try: return f"{float(x):.2f}"
        except: return "—"

    body_rows = []
    for tl, tr in zip(tests_left, tests_right):
        # left cell: Test label (more fitted)
        left = html.Td(
            dmc.Text("Average", fw=600) if tl == "Average" else tl,
            style={"textAlign":"left", "whiteSpace":"normal", "lineHeight":"1.15", "padding":"6px 8px", "width":"120px", "maxWidth":"160px"}
        )

        if isinstance(vt_source, dict) and "vt1" in vt_source and "vt2" in vt_source:
            L = vt_source["vt1"].get(tl, {})
            R = vt_source["vt2"].get(tr, {})
            vt1_cells = [
                html.Td(_fmt2(L.get("vo2")),      style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(_fmt2(L.get("t_min")),    style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(_fmt2(L.get("rer")),      style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(pct(L.get("vo2_pct_peak")), style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(conf_badge(None),         style={"background":VT1_BG, "textAlign":"center"}),  # confidence TBD
            ]
            vt2_cells = [
                html.Td(_fmt2(R.get("vo2")),      style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(_fmt2(R.get("t_min")),    style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(_fmt2(R.get("rer")),      style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(pct(R.get("vo2_pct_peak")), style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(conf_badge(None),         style={"background":VT2_BG, "textAlign":"center"}),
            ]
        else:
            # fallback (unchanged)
            vt1_cells = [
                html.Td(fmt2(vt1_vo2),  style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(fmt2(vt1_tmin), style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(fmt2(vt1_rer),  style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(pct(vt1_pct),   style={"background":VT1_BG, "textAlign":"center"}),
                html.Td(conf_badge(vt1_conf), style={"background":VT1_BG, "textAlign":"center"}),
            ]
            vt2_cells = [
                html.Td(fmt2(vt2_vo2),  style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(fmt2(vt2_tmin), style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(fmt2(vt2_rer),  style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(pct(vt2_pct),   style={"background":VT2_BG, "textAlign":"center"}),
                html.Td(conf_badge(vt2_conf), style={"background":VT2_BG, "textAlign":"center"}),
            ]

        body_rows.append(html.Tr([left] + vt1_cells + vt2_cells))

    # headers (2 rows)
    header = html.Thead([
        html.Tr([
            html.Th("Test", rowSpan=2, style={"textAlign":"left", "padding":"6px 10px", "minWidth":"160px"}),
            html.Th("VT1", colSpan=5, style={"textAlign":"center", "background":VT1_HDR, "color":VT1_TX}),
            html.Th("VT2", colSpan=5, style={"textAlign":"center", "background":VT2_HDR, "color":VT2_TX}),
        ]),
        html.Tr([
            html.Th("VO₂",        style={"textAlign":"center", "background":VT1_BG}),
            html.Th("Time",       style={"textAlign":"center", "background":VT1_BG}),
            html.Th("RER",        style={"textAlign":"center", "background":VT1_BG}),
            html.Th("%VO₂ Max",   style={"textAlign":"center", "background":VT1_BG}),
            html.Th("Confidence", style={"textAlign":"center", "background":VT1_BG}),
            html.Th("VO₂",        style={"textAlign":"center", "background":VT2_BG}),
            html.Th("Time",       style={"textAlign":"center", "background":VT2_BG}),
            html.Th("RER",        style={"textAlign":"center", "background":VT2_BG}),
            html.Th("%VO₂ Max",   style={"textAlign":"center", "background":VT2_BG}),
            html.Th("Confidence", style={"textAlign":"center", "background":VT2_BG}),
        ])
    ])

    # final table (no nested Paper/Card)
    return dmc.Table(
        [header, html.Tbody(body_rows)],
        withTableBorder=True, withRowBorders=True,
        horizontalSpacing="md", verticalSpacing="xs",
        style={"width":"100%"}
    )

# ----------------------------
# Dash app factory
# ----------------------------
def make_dashboard_app():
    app = dash.Dash(__name__, title="CPET Directory", suppress_callback_exceptions=True)
    app.layout = dashboard_view()
    register_dashboard_callbacks(app)
    return app

def dashboard_view():
    return dmc.MantineProvider(
        theme={
            "fontFamily": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif",
            "defaultRadius": "xl"
        },
        children=dmc.Container(size=1200, px="md", children=[
            # Header
            dmc.Paper(
                withBorder=True, radius="xl", shadow="xs", p="md", mb="md",
                children=dmc.Group([
                    dmc.Text("CPET VO₂ Training Dashboard", fw=700),
                    dmc.Group([
                        dmc.Button("← Back to Directory", id="btn-back", variant="light", color="gray"),
                        dmc.Button("Edit VT1/VT2", id="btn-edit-vt", color="blue"),
                    ], gap="xs")
                ], justify="space-between")
            ),
            # KPI row
            dmc.SimpleGrid(cols=8, spacing="sm", children=[
                KPITile("VO₂peak", f"{two(sample['kpi']['vo2peak_L_min'])} L·min⁻¹"),
                KPITile("VO₂peak/kg", f"{one(sample['kpi']['vo2peak_ml_kg_min'])} mL·kg⁻¹·min⁻¹"),
                KPITile("Peak Output", f"{sample['kpi']['peak_work_W']} W"),
                KPITile("Critical Power", "290 W"),
                KPITile("RERmax", f"{two(sample['kpi']['rer_max'])}", warn=(sample['kpi']['rer_max']<1.05)),
                KPITile("HRpeak", f"{sample['kpi']['hr_peak']} bpm", sub=f"{pct(sample['kpi']['hr_pct_max'])} of max"),
                KPITile("VE/VCO₂ slope", f"{one(sample['kpi']['ve_vco2_slope'])}"),
                KPITile("BP Peak", sample['kpi']['bp_peak_mmHg']),
            ], mb="md"),
            # Main grid
            dmc.Grid(grow=True, gutter="md", children=[
                # Left sidebar
                dmc.GridCol(span={"base":12,"lg":3}, children=dmc.Stack(gap="sm", children=[
                    Card("Subject", subtitle=f"{sample['subject']['name']} · ID {sample['subject']['id']}",
                         content=dmc.SimpleGrid(cols=2, spacing="xs", children=[
                             dmc.Text("Age", size="xs", c="dimmed"), dmc.Text(f"{sample['subject']['age']}"),
                             dmc.Text("Sex", size="xs", c="dimmed"), dmc.Text(sample['subject']['sex']),
                             dmc.Text("Mass", size="xs", c="dimmed"), dmc.Text(f"{sample['subject']['mass_kg']} kg"),
                             dmc.Text("Height", size="xs", c="dimmed"), dmc.Text(f"{sample['subject']['height_cm']} cm"),
                         ])),
                    Card("Protocol", subtitle=("Cycling" if sample["context"]["modality"]=="bike" else "Treadmill"),
                         content=dmc.Text(sample["context"]["protocol"], size="sm")),
                    Card("Quality", content=dmc.SimpleGrid(cols=2, spacing="xs", children=[
                        dmc.Text("Max RER", size="xs", c="dimmed"), dmc.Text(two(sample["kpi"]["rer_max"])),
                        dmc.Text("Max HR", size="xs", c="dimmed"), dmc.Text(f"{sample['kpi']['hr_peak']} bpm"),
                        dmc.Text("% HRmax", size="xs", c="dimmed"), dmc.Text(pct(sample["kpi"]["hr_pct_max"])),
                    ])),
                    Card("Extra", subtitle="Supplementary metrics", content=dmc.Stack(gap=6, children=[
                        dmc.Group([dmc.Text("VO₂peak % predicted", size="xs", c="dimmed"), dmc.Text(pct(sample["kpi"]["vo2peak_pct_pred"]))], gap="xs"),
                        dmc.Group([dmc.Text("TTE @ peak", size="xs", c="dimmed"), dmc.Text(secs(sample["kpi"]["tte_s"]))], gap="xs"),
                        dmc.Group([dmc.Text("ΔVO₂/ΔWorkrate", size="xs", c="dimmed"), dmc.Text(f"{one(sample['economy']['delta_vo2_per_W'])} mL·min⁻¹·W⁻¹")], gap="xs"),
                        dmc.Text("Standardized economy", size="xs", c="dimmed"),
                        dmc.Group(gap="xs", children=[
                            dmc.Badge(f"VO₂@100 W: {one(22.0)}", variant="light"),
                            dmc.Badge(f"VO₂@150 W: {one(26.5)}", variant="light"),
                            dmc.Badge(f"VO₂@200 W: {one(31.0)}", variant="light"),
                        ]),
                        dmc.Group([dmc.Text("OUES", size="xs", c="dimmed"), dmc.Text(two(sample["economy"]["oues"]))], gap="xs"),
                        dmc.Group([dmc.Text("OUES/kg", size="xs", c="dimmed"), dmc.Text(two(sample["economy"]["oues_per_kg"]))], gap="xs"),
                        dmc.Group([dmc.Text("ΔHR/ΔVO₂", size="xs", c="dimmed"), dmc.Text(one(sample["economy"]["delta_hr_per_vo2"]))], gap="xs"),
                        dmc.Group([dmc.Text("VEpeak", size="xs", c="dimmed"), dmc.Text(f"{sample['ventilation']['ve_peak_L_min']} L·min⁻¹")], gap="xs"),
                    ])),
                ])),
                # Right content
                dmc.GridCol(span={"base":12,"lg":9}, children=dmc.Stack(gap="sm", children=[
                    Card("Threshold Detection", content=html.Div(id="threshold-table")),
                dmc.SimpleGrid(cols=2, spacing="sm", children=[
                    Card(
                        "V-Slope",
                        right=LegendMenu("legend-vslope", [
                            ("points", "VCO₂–VO₂ points"),
                            ("slope",  "Slope lines"),
                            ("vt1",    "VT1"),
                            ("vt2",    "VT2"),
                        ]),
                        content=dcc.Graph(id="fig-vslope", config={"displaylogo": False}),
                    ),
                    Card(
                        "VO₂ vs Time",
                        right=LegendMenu("legend-vo2", [
                            ("points", "VO₂ (points)"),
                            ("trace",  "VO₂ Trace"),
                            ("vt1",    "VT1"),
                            ("vt2",    "VT2"),
                        ]),
                        content=dcc.Graph(id="fig-vo2", config={"displaylogo": False}),
                    ),
                ]),
                    dmc.SimpleGrid(cols=2, spacing="sm", children=[
                        Card(
                            "VE/VO₂ & VE/VCO₂ vs Time",
                            right=LegendMenu("legend-veeq", [
                                ("vevo2_pts",  "VE/VO₂ (points)"),
                                ("vevo2_tr",   "VE/VO₂ (trend)"),
                                ("vevco2_pts", "VE/VCO₂ (points)"),
                                ("vevco2_tr",  "VE/VCO₂ (trend)"),
                                ("vt1", "VT1"),
                                ("vt2", "VT2"),
                            ]),
                        content=dcc.Graph(id="fig-ve-equiv", config={"displaylogo": False})),
                        Card(
                            "PetO₂ & PetCO₂ vs Time",
                            right=LegendMenu("legend-pet", [
                                ("peto2_pts",  "PetO₂ (points)"),
                                ("peto2_tr",   "PetO₂ (trend)"),
                                ("petco2_pts", "PetCO₂ (points)"),
                                ("petco2_tr",  "PetCO₂ (trend)"),
                                ("vt1", "VT1"),
                                ("vt2", "VT2"),
                            ]),
                        content=dcc.Graph(id="fig-pet", config={"displaylogo": False})),
                    ]),
                    dmc.SimpleGrid(cols=2, spacing="sm", children=[
                        Card(
                            "RER vs Time",
                            right=LegendMenu("legend-rer", [
                                ("rer_pts", "RER (points)"),
                                ("rer_tr",  "RER (trend)"),
                                ("vt1", "VT1"),
                                ("vt2", "VT2"),
                            ]),
                            content=dcc.Graph(id="fig-rer", config={"displaylogo": False})),
                        html.Div()
                    ]),
                ])),
            ]),
            dmc.Space(h=24),
            dmc.Text("This mock shows layout and key readouts. Wire your parser/algorithms to replace demo series.", size="xs", c="dimmed", mb="lg"),
        ])
    )

from dash import Input, Output, State, exceptions, callback
import plotly.graph_objects as go
import sqlite3

def _get_path_for_id(row_id):
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("SELECT file_path FROM participants WHERE id=?", (row_id,))
        row = cur.fetchone()
        conn.close()
        return row[0] if row else None
    except Exception:
        return None

# ----------------------------
# Native window via pywebview
# ----------------------------
def find_free_port(start=8050, attempts=50):
    for port in range(start, start + attempts):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex(("127.0.0.1", port)) != 0:
                return port
    return start

def wait_for_server(host, port, timeout=20):
    start = time.time()
    while time.time() - start < timeout:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex((host, port)) == 0:
                return True
        time.sleep(0.2)
    return False

def run_dashboard_desktop():
    # Import here so PyInstaller pulls it in only when used
    import webview

    app = make_dashboard_app()
    port = find_free_port(8050)
    url = f"http://127.0.0.1:{port}"

    def serve():
        # Dash v3: .run (not .run_server)
        app.run(debug=False, host="127.0.0.1", port=port)

    th = threading.Thread(target=serve, daemon=True)
    th.start()

    if not wait_for_server("127.0.0.1", port, timeout=20):
        # As a fallback, show a small info window
        webview.create_window("CPET Dashboard – server failed to start", html="<h3>Server failed to start.</h3><p>Check if another copy is running or port is blocked.</p>", width=520, height=240)
        webview.start()
        sys.exit(1)

    # Create the native window
    window = webview.create_window("CPET Dashboard", url, width=1280, height=800, resizable=True, confirm_close=True)
    webview.start()  # blocks until window closed; daemon thread will end with process
import os  # if not already imported

def _sniff_excel_format(path: str) -> str:
    """
    Sniff the actual file container so we treat legacy .xls correctly.
    Returns one of: 'xls', 'xlsx', 'xlsb', 'csv', 'unknown'
    """
    try:
        with open(path, 'rb') as f:
            head = f.read(8)
    except Exception:
        return 'unknown'

    # Old binary Excel
    if head.startswith(b'\xD0\xCF\x11\xE0'):
        return 'xls'

    # ZIP container (xlsx/xlsm/xltx/xltm/xlsb)
    if head.startswith(b'PK\x03\x04'):
        ext = os.path.splitext(path)[1].lower()
        if ext == '.xlsb':
            return 'xlsb'
        return 'xlsx'

    # Plain text fallback by extension
    ext = os.path.splitext(path)[1].lower()
    if ext in ('.csv', '.txt'):
        return 'csv'

    return 'unknown'

# ----------------------------
# Timeseries loader from saved file
# ----------------------------
def _nan_div(a, b):
    a = np.asarray(a, float); b = np.asarray(b, float)
    with np.errstate(divide='ignore', invalid='ignore'):
        out = a / b
        out[~np.isfinite(out)] = np.nan
    return out

def load_timeseries_from_path(path: str):
    """
    Robust CPET loader that supports:
      - .xls (BIFF) via xlrd
      - .xlsx/.xlsm via openpyxl
      - .xlsb via pyxlsb
      - CSV / mis-labeled text
      - Excel 2003 XML (SpreadsheetML) often saved as .xls
    Then parses the Parvo fixed-grid (row 30 onward).
    Returns: dict(t, vo2, vco2, ve, rer, peto2, petco2, ve_vo2, ve_vco2)
    """
    if not path:
        raise RuntimeError("No file_path stored for this entry.")
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"File does not exist: {p}")
    if p.is_dir():
        raise RuntimeError(f"Path is a directory, not a file: {p}")

    raw = p.read_bytes()
    head = raw[:4096].lstrip()

    # ---------- FIRST: handle Excel 2003 XML (SpreadsheetML) ----------
    # These files often carry a .xls extension but start with <?xml ... <Workbook ...>
    if head.startswith(b'<?xml') and b'<Workbook' in head:
        import xml.etree.ElementTree as ET, re as _re
        try:
            root = ET.fromstring(raw)
            # detect default namespace, e.g. '{urn:schemas-microsoft-com:office:spreadsheet}Workbook'
            m = _re.match(r'\{([^}]+)\}', root.tag)
            ns = m.group(1) if m else ""
            def q(tag): return f"{{{ns}}}{tag}" if ns else tag

            rows = []
            for row in root.iter(q("Row")):
                vals = []
                for cell in row.iter(q("Cell")):
                    data = cell.find(q("Data"))
                    vals.append("" if data is None or data.text is None else data.text)
                rows.append(vals)
            df = pd.DataFrame(rows)
        except Exception as e:
            raise RuntimeError(f"Unable to read Excel 2003 XML: {e}")
    else:
        # ---------- Otherwise: try a sequence of readers, regardless of extension ----------
        df = None
        errors = []

        # 1) openpyxl (xlsx container)
        try:
            df = pd.read_excel(path, sheet_name=0, header=None, engine="openpyxl")
        except Exception as e:
            errors.append(f"openpyxl: {e}")

        # 2) xlrd (legacy xls)
        if df is None:
            try:
                import xlrd
                try:
                    # try pandas first
                    df = pd.read_excel(path, sheet_name=0, header=None, engine="xlrd")
                except Exception:
                    # fall back to raw xlrd like your old script
                    book = xlrd.open_workbook(path)
                    sh = book.sheet_by_index(0)
                    data = [[sh.cell_value(r, c) for c in range(sh.ncols)] for r in range(sh.nrows)]
                    df = pd.DataFrame(data)
            except Exception as e:
                errors.append(f"xlrd: {e}")

        # 3) xlsb
        if df is None:
            try:
                df = pd.read_excel(path, sheet_name=0, header=None, engine="pyxlsb")
            except Exception as e:
                errors.append(f"pyxlsb: {e}")

        # 4) CSV sniffing (handles mislabeled text)
        if df is None:
            try:
                df = pd.read_csv(path, header=None)
            except Exception as e_csv:
                try:
                    df = pd.read_csv(path, header=None, sep=None, engine="python")
                except Exception as e2:
                    errors.append(f"csv: {e_csv} | sniff: {e2}")

        if df is None:
            raise RuntimeError("Unsupported file format or unable to read as Excel/CSV. "
                               f"Details: {' | '.join(errors[-3:])}")

    # ---------- Parvo fixed-grid parsing (row 30 onward; 0-indexed=29) ----------
    FIRST_DATA_ROW_IDX = 29
    COL_TIME, COL_VO2, COL_VCO2, COL_VE, COL_RER, COL_PETO2, COL_PETCO2 = 0, 1, 4, 5, 6, 15, 16

    if df.shape[0] <= FIRST_DATA_ROW_IDX:
        raise RuntimeError("File has fewer than 30 rows; cannot find data starting at row 30.")

    blk = df.iloc[FIRST_DATA_ROW_IDX:, :].replace("", np.nan).infer_objects(copy=False)

    def colsafe(i):
        if i >= blk.shape[1]:
            return np.full(len(blk), np.nan, dtype=float)
        return pd.to_numeric(blk.iloc[:, i], errors="coerce").to_numpy(dtype=float)

    t      = colsafe(COL_TIME)
    vo2    = colsafe(COL_VO2)
    vco2   = colsafe(COL_VCO2)
    ve     = colsafe(COL_VE)
    rer    = colsafe(COL_RER)
    peto2  = colsafe(COL_PETO2)
    petco2 = colsafe(COL_PETCO2)

    valid = np.isfinite(t)
    if valid.sum() == 0:
        raise RuntimeError("No valid time values found in time column (col A).")

    last = np.where(valid)[0][-1]
    sl = slice(0, last + 1)
    t, vo2, vco2, ve, rer, peto2, petco2 = t[sl], vo2[sl], vco2[sl], ve[sl], rer[sl], peto2[sl], petco2[sl]

    # RER fallback
    if not np.isfinite(rer).any() and np.isfinite(vco2).any() and np.isfinite(vo2).any():
        with np.errstate(divide="ignore", invalid="ignore"):
            rer = vco2 / vo2
            rer[~np.isfinite(rer)] = np.nan

    # Ventilatory equivalents
    with np.errstate(divide="ignore", invalid="ignore"):
        ve_vo2  = ve / vo2
        ve_vco2 = ve / vco2
        ve_vo2[~np.isfinite(ve_vo2)] = np.nan
        ve_vco2[~np.isfinite(ve_vco2)] = np.nan

    return dict(t=t, vo2=vo2, vco2=vco2, ve=ve, rer=rer, peto2=peto2, petco2=petco2,
                ve_vo2=ve_vo2, ve_vco2=ve_vco2)

# ----------------------------
# Figure builders (data-driven)
# ----------------------------
def _fig_lines(x, ys, labels, xlab, ylab):
    fig = go.Figure()
    for y, lab in zip(ys, labels):
        fig.add_trace(go.Scatter(x=x, y=y, mode="lines", name=lab))
    fig.update_layout(margin=dict(l=12,r=12,t=8,b=12), height=260,
                      xaxis_title=xlab, yaxis_title=ylab,
                      legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0))
    return fig

def _mk_row_from_vo2(vt_vo2, t, vo2_L, rer_L, vo2_peak):
    tm = _invert_y_to_x(t, vo2_L, vt_vo2)
    rr = _interp_at_x(t, rer_L, tm)
    return {
        "vo2": float(vt_vo2) if np.isfinite(vt_vo2) else None,
        "t_min": float(tm) if np.isfinite(tm) else None,
        "rer": float(rr) if np.isfinite(rr) else None,
        "vo2_pct_peak": float(100.0 * vt_vo2 / vo2_peak) if np.isfinite(vt_vo2) and np.isfinite(vo2_peak) and vo2_peak > 0 else None,
    }

def _mk_row_from_time(vt_t, t, vo2_L, rer_L, vo2_peak):
    v = _interp_at_x(t, vo2_L, vt_t)
    rr = _interp_at_x(t, rer_L, vt_t)
    return {
        "vo2": float(v) if np.isfinite(v) else None,
        "t_min": float(vt_t) if np.isfinite(vt_t) else None,
        "rer": float(rr) if np.isfinite(rr) else None,
        "vo2_pct_peak": float(100.0 * v / vo2_peak) if np.isfinite(v) and np.isfinite(vo2_peak) and vo2_peak > 0 else None,
    }

def build_figures_from_file(path: str):
    ts = load_timeseries_from_path(path)

    # --- Time in minutes (match VT_Testing) ---
    t = np.asarray(ts["t"], float)

    # Core series
    vo2    = np.asarray(ts["vo2"], float)
    vco2   = np.asarray(ts["vco2"], float)
    ve     = np.asarray(ts["ve"],  float)
    rer    = np.asarray(ts["rer"], float)
    peto2  = np.asarray(ts["peto2"], float)
    petco2 = np.asarray(ts["petco2"], float)

    # Ventilatory equivalents
    with np.errstate(divide="ignore", invalid="ignore"):
        ve_vo2  = ve / vo2
        ve_vco2 = ve / vco2
        ve_vo2[~np.isfinite(ve_vo2)]   = np.nan
        ve_vco2[~np.isfinite(ve_vco2)] = np.nan

    # Normalize Pet gases by each series mean
    m_peto2  = np.nanmean(peto2)  if np.isfinite(peto2).any()  else np.nan
    m_petco2 = np.nanmean(petco2) if np.isfinite(petco2).any() else np.nan
    peto2n  = (peto2  / m_peto2)  if np.isfinite(m_peto2)  and m_peto2  != 0 else np.full_like(peto2,  np.nan)
    petco2n = (petco2 / m_petco2) if np.isfinite(m_petco2) and m_petco2 != 0 else np.full_like(petco2, np.nan)

    # LOESS (match VT_Testing spans)
    vo2_L     = loess(t, vo2,   span_frac=LOESS_VO2_SPAN_FRAC, min_neighbors=LOESS_VO2_MIN_NEI)
    ve_vo2_L  = loess(t, ve_vo2)
    ve_vco2_L = loess(t, ve_vco2)
    peto2n_L  = loess(t, peto2n)
    petco2n_L = loess(t, petco2n)
    rer_L     = loess(t, rer)

    # ------------------ DETECTORS (exact VT_Testing logic grouping) ------------------
    # V-Slope broken-stick (returns t1/t2 in VO2 space)
    bs = None
    vt1_vslope_vo2 = np.nan
    vt2_vslope_vo2 = np.nan
    try:
        bs = broken_stick_fit2(vo2, vco2,
                               min_span=BS_MIN_XSPAN, min_pts=BS_MIN_POINTS_PER_SIDE,
                               q_lo=BS_Q_LO, q_hi=BS_Q_HI,
                               pre_min=BS2_PRE_SLOPE_MIN, pre_max=BS2_PRE_SLOPE_MAX,
                               mid_min=BS2_MID_SLOPE_MIN)
        if isinstance(bs, dict):
            if np.isfinite(bs.get("t1", np.nan)): vt1_vslope_vo2 = float(bs["t1"])
            if np.isfinite(bs.get("t2", np.nan)): vt2_vslope_vo2 = float(bs["t2"])
    except Exception:
        pass

    # VE/VO2 minimum (time)  → VT1 for VE/VO2 panel
    vt1_vevo2_t = detect_min_time(t, ve_vo2_L, q_lo=0.05, q_hi=0.95)
    # PetO2 minimum (time)   → VT1 for Pet gases panel
    vt1_peto2_t = detect_min_time(t, peto2n_L, q_lo=0.05, q_hi=0.95)

    # VE/VCO2 steepest sustained rise start (time) → VT2 for VE/VECO2 panel
    vt2_vevco2_t = detect_vevco2_steepest_rise_start_strict(
        t, ve_vco2_L, slope_window_pts=12, pos_slope_threshold=0.02, min_run=10
    )
    # PetCO2 steepest sustained drop start (time)  → VT2 for Pet gases panel
    vt2_petco2_t = detect_vt2_petco2_steepest_run_start(
        t, petco2n_L, slope_window_pts=12, min_run=10, neg_slope_threshold=-0.03, min_cum_drop=0.0
    )

    # Convert those *time* detectors to VO2 (for averaging & for V-Slope sanity)
    vt1_vevo2_vo2  = _interp_at_x(t, vo2_L, vt1_vevo2_t)
    vt1_peto2_vo2  = _interp_at_x(t, vo2_L, vt1_peto2_t)
    vt2_vevco2_vo2 = _interp_at_x(t, vo2_L, vt2_vevco2_t)
    vt2_petco2_vo2 = _interp_at_x(t, vo2_L, vt2_petco2_t)

    # Safe average in VO2 space (used only on VO2 & RER panels)
    def _safe_mean(vals):
        arr = np.asarray(vals, float); arr = arr[np.isfinite(arr)]
        return float(arr.mean()) if arr.size else np.nan

    avg_vt1_vo2 = _safe_mean([vt1_vslope_vo2, vt1_vevo2_vo2, vt1_peto2_vo2])
    avg_vt2_vo2 = _safe_mean([vt2_vslope_vo2, vt2_vevco2_vo2, vt2_petco2_vo2])

    # Convert average VO2 → time (minutes) via inverse of VO2-LOESS
    vt1_t_avg = _invert_y_to_x(t, vo2_L, avg_vt1_vo2)
    vt2_t_avg = _invert_y_to_x(t, vo2_L, avg_vt2_vo2)

    # ----------------------------- PLOTTING -----------------------------
    def layout(fig, xlab, ylab, h=420):
        fig.update_layout(
            margin=dict(l=12, r=12, t=8, b=12),
            height=h,
            xaxis_title=xlab,
            yaxis_title=ylab,
            showlegend=False,  # hide on-chart legend overlay
        )
        fig.update_xaxes(
            title_font=dict(color="black"),
            gridcolor="black", zerolinecolor="black",
            linecolor="black", tickcolor="black"
        )
        fig.update_yaxes(
            title_font=dict(color="black"),
            gridcolor="black", zerolinecolor="black",
            linecolor="black", tickcolor="black"
        )
        return fig

    # 1) V-Slope (VCO2 vs VO2) — VT lines from V-Slope detector ONLY
    fig_vslope = go.Figure()
    fig_vslope.add_trace(go.Scatter(
        x=vo2, y=vco2, mode="markers",
        name="VCO₂–VO₂ points",  # ← matches legend toggle mapping
        marker=dict(size=6, opacity=0.75, color=COL_BLUE)
    ))

    # piecewise green segments (legend group so we can toggle them together)
    if isinstance(bs, dict):
        segs = _vslope_default_segs(bs, vo2)
        if segs:
            for i, ((x0, y0), (x1, y1)) in enumerate(segs):
                # Densify to enable hover anywhere along the segment
                n = 60  # ~1 px per sample on typical widths; tweak if needed
                if abs(x1 - x0) < 1e-9:
                    xp = np.array([x0] * n)
                    yp = np.linspace(y0, y1, n)
                else:
                    xp = np.linspace(x0, x1, n)
                    yp = y0 + (y1 - y0) * (xp - x0) / (x1 - x0)

                fig_vslope.add_trace(go.Scatter(
                    x=xp, y=yp, mode="lines",
                    name="Slope lines",
                    legendgroup="slope",
                    line=dict(width=3, color=COL_GREEN),
                    hovertemplate="VO₂ %{x:.2f}<br>VCO₂ %{y:.2f}<extra></extra>",
                    showlegend=(i == 0)  # single legend item
                ))

    # VT1/VT2 as toggleable TRACES (not shapes)
    ymin, ymax = float(np.nanmin(vco2)), float(np.nanmax(vco2))
    if np.isfinite(vt1_vslope_vo2):
        fig_vslope.add_trace(go.Scatter(
            x=[vt1_vslope_vo2, vt1_vslope_vo2], y=[ymin, ymax],
            mode="lines", name="VT1", line=dict(dash="dot", color=COL_PURPLE)))
    if np.isfinite(vt2_vslope_vo2):
        fig_vslope.add_trace(go.Scatter(
            x=[vt2_vslope_vo2, vt2_vslope_vo2], y=[ymin, ymax],
            mode="lines", name="VT2", line=dict(dash="dot", color=COL_RED)))

    layout(fig_vslope, "VO₂ (L·min⁻¹)", "VCO₂ (L·min⁻¹)")

    # 2) VO2 vs Time — VT lines from the averaged VO2 (converted to time)
    fig_vo2 = go.Figure()
    # points
    fig_vo2.add_trace(go.Scatter(
        x=t, y=vo2, mode="markers", name="VO₂",
        legendgroup="points",
        marker=dict(size=6, opacity=0.75, color=COL_BLUE), showlegend=False))
    # trendline
    fig_vo2.add_trace(go.Scatter(
        x=t, y=vo2_L, mode="lines", name="VO₂ Trace",
        legendgroup="trace",
        line=dict(width=2, color=COL_BLUE_DARK), showlegend=False))

    # VT1/VT2 as traces (toggleable)
    ymin, ymax = float(np.nanmin([vo2, vo2_L])), float(np.nanmax([vo2, vo2_L]))
    if np.isfinite(vt1_t_avg):
        fig_vo2.add_trace(go.Scatter(
            x=[vt1_t_avg, vt1_t_avg], y=[ymin, ymax],
            mode="lines", name="VT1", line=dict(dash="dot", color=COL_PURPLE)))
    if np.isfinite(vt2_t_avg):
        fig_vo2.add_trace(go.Scatter(
            x=[vt2_t_avg, vt2_t_avg], y=[ymin, ymax],
            mode="lines", name="VT2", line=dict(dash="dot", color=COL_RED)))

    layout(fig_vo2, "Time (min)", "VO₂ (L·min⁻¹)")

    # 3) VE/VO2 & VE/VCO2 vs Time — VT1 from VE/VO2(min), VT2 from VE/VCO2 rise (times)
    fig_veeq = go.Figure()
    fig_veeq.add_trace(go.Scatter(x=t, y=ve_vo2,   mode="markers", name="VE/VO₂",
                                legendgroup="vevo2_pts",
                                marker=dict(size=6, opacity=0.75, color=COL_BLUE)))
    fig_veeq.add_trace(go.Scatter(x=t, y=ve_vo2_L, mode="lines",   name="VE/VO₂ Trace",
                                legendgroup="vevo2_tr",
                                line=dict(width=2, color=COL_BLUE_DARK), showlegend=False))
    fig_veeq.add_trace(go.Scatter(x=t, y=ve_vco2,  mode="markers", name="VE/VCO₂",
                                legendgroup="vevco2_pts",
                                marker=dict(size=6, opacity=0.75, color=COL_ORANGE)))
    fig_veeq.add_trace(go.Scatter(x=t, y=ve_vco2_L, mode="lines",   name="VE/VCO₂ Trace",
                                legendgroup="vevco2_tr",
                                line=dict(width=2, color=COL_ORANGE_DARK), showlegend=False))
    
    # --- bounds for vertical VT lines (based on this panel only) ---
    ymin = float(np.nanmin([ve_vo2, ve_vco2, ve_vo2_L, ve_vco2_L]))
    ymax = float(np.nanmax([ve_vo2, ve_vco2, ve_vo2_L, ve_vco2_L]))

    # VT lines as traces so they’re toggleable too
    if np.isfinite(vt1_vevo2_t):
        fig_veeq.add_trace(go.Scatter(
            x=[vt1_vevo2_t, vt1_vevo2_t], y=[ymin, ymax],
            mode="lines", name="VT1", legendgroup="vt1",
            line=dict(dash="dot", color=COL_PURPLE)
        ))
    if np.isfinite(vt2_vevco2_t):
        fig_veeq.add_trace(go.Scatter(
            x=[vt2_vevco2_t, vt2_vevco2_t], y=[ymin, ymax],
            mode="lines", name="VT2", legendgroup="vt2",
            line=dict(dash="dot", color=COL_RED)
        ))

    layout(fig_veeq, "Time (min)", "Ratio")

    # PetO₂ & PetCO₂ (normalized) vs Time — points (normalized) + LOESS lines
    fig_pet = go.Figure()
    fig_pet.add_trace(go.Scatter(
        x=t, y=peto2n, mode="markers", name="PetO₂",
        legendgroup="peto2_pts",
        marker=dict(size=6, opacity=0.75, color=COL_BLUE), showlegend=False
    ))
    fig_pet.add_trace(go.Scatter(
        x=t, y=peto2n_L, mode="lines", name="PetO₂ Trace",
        legendgroup="peto2_tr",
        line=dict(width=2, color=COL_BLUE_DARK), showlegend=False
    ))
    fig_pet.add_trace(go.Scatter(
        x=t, y=petco2n, mode="markers", name="PetCO₂",
        legendgroup="petco2_pts",
        marker=dict(size=6, opacity=0.75, color=COL_ORANGE), showlegend=False
    ))
    fig_pet.add_trace(go.Scatter(
        x=t, y=petco2n_L, mode="lines", name="PetCO₂ Trace",
        legendgroup="petco2_tr",
        line=dict(width=2, color=COL_ORANGE_DARK), showlegend=False
    ))

    # bounds for VT lines on THIS panel
    ymin = float(np.nanmin([peto2n, petco2n, peto2n_L, petco2n_L]))
    ymax = float(np.nanmax([peto2n, petco2n, peto2n_L, petco2n_L]))

    if np.isfinite(vt1_peto2_t):
        fig_pet.add_trace(go.Scatter(x=[vt1_peto2_t, vt1_peto2_t], y=[ymin, ymax],
                                    mode="lines", name="VT1", legendgroup="vt1",
                                    line=dict(dash="dot", color=COL_PURPLE)))
    if np.isfinite(vt2_petco2_t):
        fig_pet.add_trace(go.Scatter(x=[vt2_petco2_t, vt2_petco2_t], y=[ymin, ymax],
                                    mode="lines", name="VT2", legendgroup="vt2",
                                    line=dict(dash="dot", color=COL_RED)))
    layout(fig_pet, "Time (min)", "Normalized (÷ series mean)")

    # 5) RER vs Time — VT lines from averaged VO2 (converted to time)
    fig_rer = go.Figure()
    fig_rer.add_trace(go.Scatter(
        x=t, y=rer, mode="markers", name="RER",
        legendgroup="rer_pts",
        marker=dict(size=6, opacity=0.75, color=COL_BLUE), showlegend=False
    ))
    fig_rer.add_trace(go.Scatter(
        x=t, y=rer_L, mode="lines", name="RER Trace",
        legendgroup="rer_tr",
        line=dict(width=2, color=COL_BLUE_DARK), showlegend=False
    ))

    # bounds for VT lines on THIS panel
    ymin = float(np.nanmin([rer, rer_L]))
    ymax = float(np.nanmax([rer, rer_L]))

    if np.isfinite(vt1_t_avg):
        fig_rer.add_trace(go.Scatter(x=[vt1_t_avg, vt1_t_avg], y=[ymin, ymax],
                                    mode="lines", name="VT1", legendgroup="vt1",
                                    line=dict(dash="dot", width=2, color=COL_PURPLE)))
    if np.isfinite(vt2_t_avg):
        fig_rer.add_trace(go.Scatter(x=[vt2_t_avg, vt2_t_avg], y=[ymin, ymax],
                                    mode="lines", name="VT2", legendgroup="vt2",
                                    line=dict(dash="dot", width=2, color=COL_RED)))
    layout(fig_rer, "Time (min)", "RER")

    # ---------- Threshold tile data ----------
    vo2_peak = np.nanmax(vo2_L)

    vt1_rows = {
        "V-Slope":           _mk_row_from_vo2(vt1_vslope_vo2, t, vo2_L, rer_L, vo2_peak),
        "VE/VO₂ minimum":    _mk_row_from_time(vt1_vevo2_t,   t, vo2_L, rer_L, vo2_peak),
        "PetO₂ minimum":     _mk_row_from_time(vt1_peto2_t,   t, vo2_L, rer_L, vo2_peak),
    }
    # average (mean in VO₂ space, then invert to time and read RER)
    _vt1_mean_vo2 = np.nanmean([r["vo2"] for r in vt1_rows.values() if r["vo2"] is not None])
    vt1_rows["Average"] = _mk_row_from_vo2(_vt1_mean_vo2, t, vo2_L, rer_L, vo2_peak)

    vt2_rows = {
        "V-Slope":                 _mk_row_from_vo2(vt2_vslope_vo2, t, vo2_L, rer_L, vo2_peak),
        "VE/VCO₂ rise (start)":    _mk_row_from_time(vt2_vevco2_t,  t, vo2_L, rer_L, vo2_peak),
        "PetCO₂ drop (start)":     _mk_row_from_time(vt2_petco2_t,  t, vo2_L, rer_L, vo2_peak),
    }
    _vt2_mean_vo2 = np.nanmean([r["vo2"] for r in vt2_rows.values() if r["vo2"] is not None])
    vt2_rows["Average"] = _mk_row_from_vo2(_vt2_mean_vo2, t, vo2_L, rer_L, vo2_peak)

    vt_table_data = {"vt1": vt1_rows, "vt2": vt2_rows}

    return (
        {
            "vslope": fig_vslope,
            "vo2":    fig_vo2,
            "veeq":   fig_veeq,
            "pet":    fig_pet,
            "rer":    fig_rer,
        },
        vt_table_data,
    )

# ---- BEGIN: CPET_Directory (renamed) ----
# CPETDirectory_webview.py
# Directory start-screen with robust CPET Excel importer (.xls/.xlsx/.csv)
# Dash (v3) + dash-mantine-components (v2) + SQLite + pywebview
# Changes in this version:
# - Remove "Critical Power" from edit modal
# - Add "Study" (new column, editable, searchable, sortable, persisted)
# - Improve table alignment (tabular numbers, right/center alignment, min widths)

import base64, io, re, sqlite3, threading, time, socket, sys
from pathlib import Path
from datetime import datetime

import dash
from dash import html, dcc, Input, Output, State, ctx, ALL
import dash_mantine_components as dmc

# -------------------- Persistence --------------------
APP_DIR = Path(__file__).parent
DB_PATH = APP_DIR / "cpet_dir.db"

SORT_FIELDS = {
    "test_date": "Test Date",
    "created_at": "Date Added",
    "subject_id": "Subject ID",
    "name": "Name",
    "study": "Study",
    "modality": "Modality",
}

def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("""
      CREATE TABLE IF NOT EXISTS participants (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        subject_id TEXT,
        name TEXT,
        study TEXT,
        sex TEXT,
        age INTEGER,
        height_cm REAL,
        mass_kg REAL,
        test_date TEXT,
        modality TEXT,
        rer_max REAL,
        hr_peak INTEGER,
        hr_pct_max REAL,
        critical_power REAL,
        file_name TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
      )
    """)
    # Backfill columns for older DBs
    def ensure_column(col_name, col_type):
        c.execute("PRAGMA table_info(participants)")
        cols = {row[1] for row in c.fetchall()}
        if col_name not in cols:
            c.execute(f"ALTER TABLE participants ADD COLUMN {col_name} {col_type}")
    ensure_column("study", "TEXT")
    ensure_column("file_path", "TEXT")
    conn.commit()
    conn.close()

def row_to_dict(row):
    cols = [
        "id","subject_id","name","study","sex","age","height_cm","mass_kg",
        "test_date","modality","rer_max","hr_peak","hr_pct_max","critical_power",
        "file_name","file_path","created_at","updated_at"
    ]
    return {k:v for k,v in zip(cols, row)}

def list_participants(search="", sort_by="test_date", sort_dir="desc"):
    sort_col = sort_by if sort_by in SORT_FIELDS else "test_date"
    direction = "DESC" if sort_dir == "desc" else "ASC"
    like = f"%{(search or '').strip()}%"
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute(f"""
      SELECT id,subject_id,name,study,sex,age,height_cm,mass_kg,test_date,modality,
             rer_max,hr_peak,hr_pct_max,critical_power,file_name,file_path,created_at,updated_at
      FROM participants
      WHERE subject_id LIKE ? OR name LIKE ? OR modality LIKE ? OR IFNULL(study,'') LIKE ?
      ORDER BY {sort_col} {direction}, id DESC
    """, (like, like, like, like))
    rows = c.fetchall(); conn.close()
    return [row_to_dict(r) for r in rows]

def get_participant(pid:int):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("""SELECT id,subject_id,name,study,sex,age,height_cm,mass_kg,test_date,modality,
                rer_max,hr_peak,hr_pct_max,critical_power,file_name,file_path,created_at,updated_at
                FROM participants WHERE id=?""", (pid,))
    row = c.fetchone(); conn.close()
    return row_to_dict(row) if row else None

def insert_participant(data:dict):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("""
      INSERT INTO participants (subject_id,name,study,sex,age,height_cm,mass_kg,test_date,modality,
                                rer_max,hr_peak,hr_pct_max,critical_power,file_name,file_path,
                                created_at,updated_at)
      VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,datetime('now'),datetime('now'))
    """, (
        data.get("subject_id"), data.get("name"), data.get("study"),
        data.get("sex"), data.get("age"), data.get("height_cm"),
        data.get("mass_kg"), data.get("test_date"), data.get("modality"),
        data.get("rer_max"), data.get("hr_peak"), data.get("hr_pct_max"),
        data.get("critical_power"), data.get("file_name"), data.get("file_path")
    ))
    conn.commit(); conn.close()

def update_participant(pid:int, data:dict):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("""
    UPDATE participants SET
        subject_id=?, name=?, study=?, sex=?, age=?, height_cm=?, mass_kg=?, test_date=?, modality=?,
        rer_max=?, hr_peak=?, hr_pct_max=?, critical_power=?, file_name=?, file_path=?, updated_at=datetime('now')
    WHERE id=?
    """, (
        data.get("subject_id"), data.get("name"), data.get("study"), data.get("sex"),
        data.get("age"), data.get("height_cm"), data.get("mass_kg"),
        data.get("test_date"), data.get("modality"), data.get("rer_max"),
        data.get("hr_peak"), data.get("hr_pct_max"), data.get("critical_power"),
        data.get("file_name"), data.get("file_path"), pid
    ))
    conn.commit(); conn.close()

def delete_participant(pid:int):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("DELETE FROM participants WHERE id=?", (pid,))
    conn.commit(); conn.close()

# -------------------- Utils & Importer --------------------
def fmt_date(s):
    if not s: return "—"
    try: return datetime.fromisoformat(s).strftime("%Y-%m-%d")
    except Exception: return s

# The importer below is the same robust version you already have
# (xlrd fallback + B3/D3/F3 date + no Max VO2/VE-VCO2 slope).
# Only addition: set default study="" so it’s persisted.
def parse_excel_or_csv(contents: str, filename: str):
    warnings, error = [], None
    data = {
        "file_name": filename or "",
        "subject_id": "", "name": "", "study": "", "sex": "",
        "age": None, "height_cm": None, "mass_kg": None,
        "test_date": "", "modality": "",
        "rer_max": None, "hr_peak": None, "hr_pct_max": None,
        "critical_power": None
    }

    if not contents:
        return data, warnings, "No file content received."

    try:
        header, b64 = contents.split(",", 1)
        raw_bytes = base64.b64decode(b64)
        # Save raw upload so we can render graphs later
        uploads_dir = Path.home() / "Downloads" / "CPET_Uploads"
        uploads_dir.mkdir(parents=True, exist_ok=True)
        safe_name = re.sub(r"[^A-Za-z0-9._-]+", "_", filename or "file")
        stamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        saved_path = uploads_dir / f"{stamp}__{safe_name}"
        with open(saved_path, "wb") as f:
            f.write(raw_bytes)

        data["file_path"] = str(saved_path)
        buf = io.BytesIO(raw_bytes)
    except Exception as e:
        return data, warnings, f"Failed to decode upload: {e}"

    lower = (filename or "").lower()
    try_order = []
    if lower.endswith(".xls"):
        try_order = [("excel", {"engine": "xlrd"}), ("excel", {"engine": None})]
    elif lower.endswith(".xlsx"):
        try_order = [("excel", {"engine": "openpyxl"}), ("excel", {"engine": None})]
    else:
        try_order = [("csv", {})]

    import pandas as pd
    dfs, read_errors = [], []

    def add_frames_from_excel(excel_buffer, engine):
        try:
            xls = pd.ExcelFile(excel_buffer, engine=engine)
            for sheet in xls.sheet_names:
                try:
                    df = xls.parse(sheet)
                    if not df.empty:
                        dfs.append((sheet, df))
                except Exception as e:
                    read_errors.append(f"Pandas parse sheet '{sheet}' failed: {e}")
            return len(dfs) > 0
        except Exception as e:
            read_errors.append(f"Pandas ExcelFile(engine={engine}) failed: {e}")
            return False

    read_ok = False
    for kind, kwargs in try_order:
        try:
            buf.seek(0)
            if kind == "csv":
                df = pd.read_csv(buf)
                if not df.empty:
                    dfs.append(("CSV", df))
                    read_ok = True
                    break
            else:
                if add_frames_from_excel(buf, kwargs.get("engine")):
                    read_ok = True
                    break
        except Exception as e:
            read_errors.append(f"Pandas top-level read ({kind}) failed: {e}")

    if not read_ok and lower.endswith(".xls"):
        try:
            import xlrd
            wb = xlrd.open_workbook(file_contents=raw_bytes)
            for s in wb.sheets():
                rows = [s.row_values(r) for r in range(s.nrows)]
                if rows:
                    maxc = max(len(r) for r in rows)
                    rows = [r + [None]*(maxc - len(r)) for r in rows]
                    df = pd.DataFrame(rows)
                    dfs.append((s.name, df))
            if dfs:
                read_ok = True
        except Exception as e:
            read_errors.append(f"xlrd direct open failed: {e}")

    if not read_ok:
        msg = "Unable to read .XLS." if lower.endswith(".xls") else "Unable to read file."
        if read_errors:
            msg += " Details: " + " | ".join(read_errors[-3:])
        return data, warnings, msg

    def _to_float(x):
        try: return float(str(x).strip())
        except: return None

    def _height_to_cm(x):
        v = _to_float(x)
        if v is None: return None
        if 48 <= v <= 90: return round(v * 2.54, 1)
        if v < 3:         return round(v * 100, 1)
        return round(v, 1)

    def _mass_to_kg(x):
        v = _to_float(x)
        if v is None: return None
        return round(v / 2.20462, 1) if v > 140 else round(v, 1)

    # Try header-based scan (skip if first column not str — likely grid)
    FIELD_PATTERNS = {
        "subject_id":   [r"^subjectid$", r"^id$", r"^subjectcode$", r"^participantid$", r"^subject$"],
        "name":         [r"^name$", r"^subjectname$", r"^participant$", r"^patientname$"],
        "sex":          [r"^sex$", r"^gender$"],
        "age":          [r"^age(yrs|years)?$", r"^age$"],
        "height_cm":    [r"^height(cm)?$", r"^stature$", r"^height$"],
        "mass_kg":      [r"^mass(kg)?$", r"^weight(kg)?$", r"^weight$", r"^bodymass$"],
        "test_date":    [r"^testdate$", r"^date$", r"^testtime$", r"^collectiondate$"],
        "modality":     [r"^modality$", r"^device$", r"^mode$", r"^protocol$", r"^exercisedevice$"],
        "rer_max":      [r"^rermax$", r"^rerpeak$", r"^rer$"],
        "hr_peak":      [r"^hrmax$", r"^hrpeak$", r"^maxhr$", r"^peakhr$"],
        "hr_pct_max":   [r"^hrpctmax$", r"^percenthrmax$", r"^hrpercent$", r"^%hrmax$"],
        "critical_power":[r"^criticalpower$", r"^cp$"],
    }
    found = {k: False for k in data.keys() if k not in ("file_name","study")}

    for sheet, df in dfs:
        if not isinstance(df.columns[0], str):
            continue
        cols = list(df.columns)
        norm_cols = [re.sub(r"[^a-z0-9]", "", str(c).strip().lower()) for c in cols]
        col_map = dict(zip(norm_cols, cols))

        def take(field_key, cast):
            if found[field_key]:
                return
            pats = FIELD_PATTERNS.get(field_key, [])
            for nc in norm_cols:
                if any(re.match(p, nc) for p in pats):
                    series = df[col_map[nc]].dropna()
                    if series.empty:
                        continue
                    raw = series.iloc[0]
                    try:
                        if cast == str:   val = str(raw).strip()
                        elif cast == int: val = int(float(str(raw).strip()))
                        elif cast == float: val = float(str(raw).strip())
                        else:             val = raw
                    except Exception:
                        val = str(raw).strip()
                    data[field_key] = val
                    found[field_key] = True
                    return

        take("subject_id", str)
        take("name", str)
        take("sex", str)
        take("age", int)
        take("height_cm", float)
        take("mass_kg", float)
        take("test_date", str)
        take("modality", str)
        take("rer_max", float)
        take("hr_peak", int)
        take("hr_pct_max", float)
        take("critical_power", float)

    # Form-style + B3/D3/F3 date
    grid = dfs[0][1] if dfs else None
    def pairmap(g):
        pairs = {}
        if g is None or g.empty: return pairs
        R, C = g.shape
        for r in range(R):
            k = g.iat[r,0] if C>0 else None
            v = g.iat[r,1] if C>1 else None
            if isinstance(k, str) and str(k).strip() and (v is not None and str(v).strip() != ""):
                pairs[str(k).strip()] = v
        return pairs

    pairs = pairmap(grid)

    if not data["name"]:
        data["name"] = str(pairs.get("Name","")).strip()

    if not data["subject_id"]:
        m = re.search(r"([A-Za-z0-9]+_[A-Za-z0-9]+)", data["name"])
        if m:
            data["subject_id"] = m.group(1)

    if not data["sex"] and grid is not None:
        R, C = grid.shape
        for r in range(R):
            for c in range(C-1):
                v = grid.iat[r,c]
                if isinstance(v, str) and re.search(r"\b(sex|gender)\b", v, re.I):
                    right = grid.iat[r,c+1]
                    if right is not None and str(right).strip() != "":
                        data["sex"] = str(right).strip()
                        break

    if data["age"] in (None, ""):
        age = pairs.get("Age", None)
        try: data["age"] = int(float(age)) if age not in (None,"") else None
        except: pass

    if data["height_cm"] in (None, ""):
        hc = pairs.get("Height", None)
        data["height_cm"] = _height_to_cm(hc) if hc not in (None,"") else None

    if data["mass_kg"] in (None, "") and grid is not None:
        R, C = grid.shape
        for r in range(R):
            for c in range(C-1):
                v = grid.iat[r,c]
                if isinstance(v, str) and re.search(r"\b(weight|mass)\b", v, re.I):
                    right = grid.iat[r,c+1]
                    if right is not None and str(right).strip() != "":
                        data["mass_kg"] = _mass_to_kg(right)
                        break

    if not data["modality"]:
        mod = pairs.get("Exercise Device", None)
        if isinstance(mod, str):
            mn = mod.lower()
            data["modality"] = "treadmill" if ("tread" in mn or "run" in mn) else ("bike" if ("bike" in mn or "cycle" in mn) else mod)

    if not data["test_date"] and grid is not None and grid.shape[0]>2 and grid.shape[1]>5:
        try:
            y_raw = grid.iat[2,1]  # B3
            m_raw = grid.iat[2,3]  # D3
            d_raw = grid.iat[2,5]  # F3
            y = int(float(str(y_raw).strip()))
            def month_to_num(m):
                s = str(m).strip()
                try:
                    n = int(float(s))
                    if 1 <= n <= 12: return n
                except: pass
                months = {"jan":1,"january":1,"feb":2,"february":2,"mar":3,"march":3,"apr":4,"april":4,
                          "may":5,"jun":6,"june":6,"jul":7,"july":7,"aug":8,"august":8,
                          "sep":9,"sept":9,"september":9,"oct":10,"october":10,
                          "nov":11,"november":11,"dec":12,"december":12}
                key = re.sub(r"[^a-z]", "", s.lower())
                return months.get(key)
            m = month_to_num(m_raw)
            d = int(float(str(d_raw).strip()))
            if y and m and d:
                data["test_date"] = f"{y:04d}-{m:02d}-{d:02d}"
        except Exception:
            pass

    if not data["test_date"]:
        m = re.search(r"(20\d{2})(\d{2})(\d{2})[_\-]?\d{4}", filename or "", re.I)
        if m:
            y, mo, d = m.groups()
            try:
                data["test_date"] = f"{int(y):04d}-{int(mo):02d}-{int(d):02d}"
            except Exception:
                pass

    # Normalize if header-scan filled raw units
    if data["height_cm"] not in (None,""):
        data["height_cm"] = _height_to_cm(data["height_cm"])
    if data["mass_kg"] not in (None,""):
        data["mass_kg"] = _mass_to_kg(data["mass_kg"])

    if not data.get("subject_id"):
        error = "Missing required: subject_id"

    return data, warnings, error

# -------------------- UI --------------------
def Toolbar():
    return dmc.Paper(withBorder=True, shadow="xs", radius="xl", p="md", mb="md",
        children=dmc.Group(justify="space-between", align="center", children=[
            dmc.Text("CPET Directory", fw=700, size="lg"),
            dmc.Group(gap="sm", align="center", children=[
                dmc.TextInput(id="search", placeholder="Search by subject, name, study, or modality…", leftSection="🔎", w=360, size="sm"),
                dmc.Select(id="sort-by", size="sm", w=200, value="test_date",
                           data=[{"value":k, "label":v} for k,v in SORT_FIELDS.items()]),
                dmc.SegmentedControl(id="sort-dir", size="sm", value="desc",
                                     data=[{"value":"asc","label":"Asc"},{"value":"desc","label":"Desc"}]),
                dcc.Upload(
                    id="upload-add",
                    children=dmc.Button("Add New Entry", leftSection="➕", variant="filled", color="blue"),
                    multiple=False,
                    accept=".xls,.xlsx,.csv,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,text/csv",
                    style={"display":"inline-block"}
                ),
            ])
        ])
    )

def DirectoryTable(rows):
    # Helpers for alignment & widths
    def TH(text, minw=None, align="left"):
        style = {"minWidth": minw} if minw else {}
        if align == "right": style["textAlign"] = "right"
        elif align == "center": style["textAlign"] = "center"
        return html.Th(text, style=style)

    def TD(val, minw=None, align="left"):
        style = {"minWidth": minw} if minw else {}
        if align == "right": style["textAlign"] = "right"
        elif align == "center": style["textAlign"] = "center"
        return html.Td("—" if val in (None, "") else val, style=style)

    head = html.Thead(html.Tr([
        TH("Subject ID", "140px", "center"),   # centered
        TH("Name", "190px", "center"),         # centered
        TH("Study", "120px", "center"),
        TH("Sex", "60px", "center"),
        TH("Age", "70px", "center"),
        TH("Mass (kg)", "100px", "center"),    # centered
        TH("Height (cm)", "110px", "center"),
        TH("Test Date", "110px", "center"),
        TH("Modality", "110px", "center"),
        TH("Actions", "210px", "center"),
    ]))

    body = []
    for r in rows:
        action_bar = html.Div(
            [
                dmc.Button("Open",  size="xs", variant="light",
                           id={"type": "open-btn", "row_id": r["id"]}),
                dmc.Button("Edit",  size="xs", variant="light", color="gray",
                           id={"type": "edit-btn", "row_id": r["id"]}),
                dmc.Button("Delete", size="xs", variant="outline", color="red",
                           id={"type": "delete-btn", "row_id": r["id"]}),
            ],
            style={"display":"flex","gap":"10px","justifyContent":"center",
                   "alignItems":"center","flexWrap":"nowrap","whiteSpace":"nowrap"},
        )

        body.append(html.Tr([
            TD(r.get("subject_id"), "140px", "center"),   # centered
            TD(r.get("name"), "190px", "center"),         # centered
            TD(r.get("study"), "120px", "center"),
            TD(r.get("sex"), "60px", "center"),
            TD(r.get("age"), "70px", "center"),
            TD(r.get("mass_kg"), "100px", "center"),      # centered
            TD(r.get("height_cm"), "110px", "center"),
            TD(fmt_date(r.get("test_date")), "110px", "center"),
            TD(r.get("modality"), "110px", "center"),
            html.Td(action_bar, style={"minWidth":"210px","textAlign":"center"}),
        ]))

    table = dmc.Table(
        [head, html.Tbody(body)],
        striped=True,
        highlightOnHover=True,
        withTableBorder=True,
        withRowBorders=True,
        horizontalSpacing="md",
        verticalSpacing="xs",
        tabularNums=True,
        style={"tableLayout":"auto","width":"100%"},
    )

    return dmc.Paper(
        withBorder=True, shadow="sm", radius="xl", p="md",
        children=dmc.ScrollArea(table, type="always", offsetScrollbars=True),
    )

def EditModal():
    def ti(lbl, fid, placeholder="", **kw):
        return dmc.TextInput(label=lbl, id=f"edit-{fid}", placeholder=placeholder, size="sm", **kw)
    return dmc.Modal(
        id="modal-edit", opened=False, title="Edit Entry", size="lg",
        children=dmc.Stack(gap="sm", children=[
            dmc.Group(gap="sm", grow=True, children=[
                ti("Subject ID", "subject_id"),
                ti("Name", "name"),
                ti("Study", "study"),
            ]),
            dmc.Group(gap="sm", grow=True, children=[
                ti("Sex", "sex"),
                ti("Age", "age"),
                ti("Mass (kg)", "mass_kg"),
            ]),
            dmc.Group(gap="sm", grow=True, children=[
                ti("Height (cm)", "height_cm"),
                ti("Test Date", "test_date", placeholder="YYYY-MM-DD"),
                ti("Modality", "modality", placeholder="bike / treadmill"),
            ]),
            dmc.Group(justify="flex-end", children=[
                dmc.Button("Cancel", id="edit-cancel", variant="light", color="gray"),
                dmc.Button("Save", id="edit-save", color="blue"),
            ]),
        ])
    )

def DeleteModal():
    return dmc.Modal(
        id="modal-delete", opened=False, title="Delete entry?",
        children=dmc.Stack(gap="sm", children=[
            dmc.Text("This will permanently remove the participant from your directory.", c="red"),
            dmc.Group(justify="flex-end", children=[
                dmc.Button("Cancel", id="delete-cancel", variant="light"),
                dmc.Button("Delete", id="delete-confirm", color="red"),
            ])
        ])
    )

def ImportModal():
    return dmc.Modal(
        id="modal-import", opened=False, title="Import result",
        children=dmc.Stack(gap="sm", children=[
            dmc.Alert(id="import-alert", title="", color="blue", variant="light", children=""),
            dmc.Group(justify="flex-end", children=[dmc.Button("Close", id="import-close")])
        ])
    )

# -------------------- Dash App --------------------
def DirectoryScreen():
    return [
        Toolbar(),
        dcc.Store(id="refresh-token", data=0),
        dcc.Store(id="edit-row-id"),
        dcc.Store(id="delete-row-id"),
        dcc.Store(id="open-clicks-prev", data={}),
        dcc.Store(id="edit-clicks-prev", data={}),
        dcc.Store(id="delete-clicks-prev", data={}),
        ImportModal(),
        EditModal(),
        DeleteModal(),
        html.Div(id="table-container"),
    ]

def make_directory_app():
    init_db()
    app = dash.Dash(__name__, title="CPET Directory", suppress_callback_exceptions=True)

    app.layout = dmc.MantineProvider(
        theme={"fontFamily": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif",
            "defaultRadius": "xl"},
        children=dmc.Container(size=1460, px="md", children=[
            # routing state
            dcc.Store(id="route", data="directory"),
            dcc.Store(id="selected-row-id"),
            # where we render either the directory or the dashboard
            html.Div(id="router-outlet", children=DirectoryScreen())
        ])
    )
    # Swap the visible view
    @app.callback(
        Output("router-outlet", "children"),
        Input("route", "data"),
        prevent_initial_call=False
    )
    def route_view(route):
        if route == "dashboard":
            return dashboard_view()  # reuse the layout you exposed
        return DirectoryScreen() 

    @app.callback(
        Output("route", "data", allow_duplicate=True),
        Input("btn-back", "n_clicks"),
        prevent_initial_call=True
    )
    def go_back(n):
        if not n:
            raise dash.exceptions.PreventUpdate
        return "directory"

    # Refresh table
    @app.callback(
        Output("table-container", "children"),
        Input("search", "value"),
        Input("sort-by", "value"),
        Input("sort-dir", "value"),
        Input("refresh-token", "data"),
        prevent_initial_call=False
    )
    def refresh_table(search, sort_by, sort_dir, _):
        rows = list_participants(search or "", sort_by or "test_date", sort_dir or "desc")
        return DirectoryTable(rows)

    @app.callback(
        Output("modal-import", "opened", allow_duplicate=True),
        Output("import-alert", "title", allow_duplicate=True),
        Output("import-alert", "color", allow_duplicate=True),
        Output("import-alert", "children", allow_duplicate=True),
        Output("refresh-token", "data", allow_duplicate=True),
        Input("upload-add", "contents"),
        State("upload-add", "filename"),
        State("refresh-token", "data"),
        prevent_initial_call=True
    )
    def handle_upload(contents, filename, refresh):
        if not contents:
            raise dash.exceptions.PreventUpdate

        # Parse file
        data, warnings, error = parse_excel_or_csv(contents, filename)

        # If parser flagged a hard error (e.g., missing subject_id), show red alert
        if error:
            details = [dmc.Text(f"Error: {error}", c="red", fw=600)]
            if warnings:
                details.append(dmc.Text("Warnings:", fw=600))
                details.extend(dmc.Text(f"• {w}") for w in warnings)
            return True, "Import failed", "red", dmc.Stack(children=details, gap=6), refresh or 0

        # Deduplicate on (subject_id, test_date)
        try:
            conn = sqlite3.connect(DB_PATH); c = conn.cursor()
            c.execute(
                "SELECT id FROM participants WHERE subject_id=? AND IFNULL(test_date,'')=?",
                (data.get("subject_id") or "", data.get("test_date") or "")
            )
            exists = c.fetchone() is not None
            conn.close()
        except Exception:
            exists = False

        if exists:
            # Don’t double-add the same test
            msg = f"An entry for subject '{data.get('subject_id','?')}' on '{data.get('test_date','—')}' already exists. No changes made."
            return True, "Already exists", "yellow", dmc.Text(msg), refresh or 0

        # Insert and refresh
        insert_participant(data)


        ok = [
            dmc.Text(f"Imported: {filename or 'file'}", fw=600),
            dmc.Text(f"Subject ID: {data.get('subject_id') or '—'}"),
            dmc.Text(f"Name: {data.get('name') or '—'}"),
            dmc.Text(f"Test Date: {data.get('test_date') or '—'}"),
            dmc.Text(f"Study: {data.get('study') or '—'}"),
            dmc.Text(f"Modality: {data.get('modality') or '—'}"),
        ]
        if warnings:
            ok.append(dmc.Space(h=6))
            ok.append(dmc.Text("Warnings:", fw=600))
            ok.extend(dmc.Text(f"• {w}") for w in warnings)

        return True, "Import successful", "green", dmc.Stack(children=ok, gap=4), (refresh or 0) + 1

    from dash import ALL

    @app.callback(
        Output("route", "data", allow_duplicate=True),
        Output("selected-row-id", "data", allow_duplicate=True),
        Output("open-clicks-prev", "data"),
        Input({"type": "open-btn", "row_id": ALL}, "n_clicks"),
        State({"type": "open-btn", "row_id": ALL}, "id"),
        State("open-clicks-prev", "data"),
        prevent_initial_call=True
    )
    def on_open_click(n_list, id_list, prev_map):
        # Normalize
        n_list = [(n or 0) for n in (n_list or [])]
        id_list = id_list or []
        prev_map = dict(prev_map or {})

        if not n_list or not id_list:
            raise dash.exceptions.PreventUpdate

        # Current map of row_id -> n_clicks
        curr_map = { str(id_list[i]["row_id"]): n_list[i] for i in range(len(id_list)) }

        # Find which row actually increased
        deltas = { rid: curr_map[rid] - prev_map.get(rid, 0) for rid in curr_map }
        rid_clicked = max(deltas, key=lambda k: deltas[k]) if deltas else None

        if not rid_clicked or deltas[rid_clicked] <= 0:
            # No real click (likely a re-render from search/sort)
            return dash.no_update, dash.no_update, curr_map

        return "dashboard", int(rid_clicked), curr_map

    @app.callback(
        Output("modal-edit", "opened", allow_duplicate=True),
        Output("edit-row-id", "data", allow_duplicate=True),
        Output("modal-delete", "opened", allow_duplicate=True),
        Output("delete-row-id", "data", allow_duplicate=True),
        Output("edit-clicks-prev", "data"),
        Output("delete-clicks-prev", "data"),
        Input({"type":"edit-btn","row_id": ALL}, "n_clicks"),
        Input({"type":"delete-btn","row_id": ALL}, "n_clicks"),
        State({"type":"edit-btn","row_id": ALL}, "id"),
        State({"type":"delete-btn","row_id": ALL}, "id"),
        State("edit-clicks-prev","data"),
        State("delete-clicks-prev","data"),
        prevent_initial_call=True
    )
    def handle_row_actions(edit_n, delete_n, edit_ids, delete_ids, prev_edit_map, prev_del_map):
        # Normalize
        edit_n = [(x or 0) for x in (edit_n or [])]; edit_ids = edit_ids or []
        delete_n = [(x or 0) for x in (delete_n or [])]; delete_ids = delete_ids or []
        prev_edit_map = dict(prev_edit_map or {})
        prev_del_map  = dict(prev_del_map  or {})

        # Build current maps
        curr_edit = { str(edit_ids[i]["row_id"]): edit_n[i] for i in range(len(edit_ids)) }
        curr_del  = { str(delete_ids[i]["row_id"]): delete_n[i] for i in range(len(delete_ids)) }

        # Compute deltas
        e_deltas = { rid: curr_edit[rid] - prev_edit_map.get(rid, 0) for rid in curr_edit }
        d_deltas = { rid: curr_del[rid]  - prev_del_map.get(rid, 0)  for rid in curr_del }

        # Prefer whichever had a real new click
        e_rid = max(e_deltas, key=lambda k: e_deltas[k]) if e_deltas else None
        d_rid = max(d_deltas, key=lambda k: d_deltas[k]) if d_deltas else None

        if e_rid and e_deltas[e_rid] > 0:
            return True, int(e_rid), dash.no_update, dash.no_update, curr_edit, curr_del

        if d_rid and d_deltas[d_rid] > 0:
            return dash.no_update, dash.no_update, True, int(d_rid), curr_edit, curr_del

        # No real click—just update the maps
        return dash.no_update, dash.no_update, dash.no_update, dash.no_update, curr_edit, curr_del

    @app.callback(Output("modal-import","opened"), Input("import-close","n_clicks"), prevent_initial_call=True)
    def close_import(_): return False

    # Populate edit modal
    @app.callback(
        *(Output(f"edit-{fid}", "value") for fid in [
            "subject_id","name","study","sex","age","mass_kg","height_cm","test_date","modality"
        ]),
        Input("modal-edit", "opened"),
        State("edit-row-id","data"),
        prevent_initial_call=True
    )
    def fill_edit_fields(opened, rid):
        if not opened or not rid:
            raise dash.exceptions.PreventUpdate
        row = get_participant(int(rid))
        return (
            row.get("subject_id"), row.get("name"), row.get("study"), row.get("sex"),
            (row.get("age") if row.get("age") is not None else ""),
            (row.get("mass_kg") if row.get("mass_kg") is not None else ""),
            (row.get("height_cm") if row.get("height_cm") is not None else ""),
            row.get("test_date"), row.get("modality"),
        )

    # Save edit
    @app.callback(
        Output("modal-edit", "opened", allow_duplicate=True),
        Output("refresh-token", "data", allow_duplicate=True),
        Input("edit-save","n_clicks"),
        State("edit-row-id","data"),
        State("edit-subject_id","value"), State("edit-name","value"), State("edit-study","value"),
        State("edit-sex","value"),
        State("edit-age","value"), State("edit-height_cm","value"), State("edit-mass_kg","value"),
        State("edit-test_date","value"), State("edit-modality","value"),
        State("refresh-token","data"),
        prevent_initial_call=True
    )
    def save_edit(n, rid, subject_id, name, study, sex, age, height_cm, mass_kg, test_date, modality, refresh):
        if not n or not rid:
            raise dash.exceptions.PreventUpdate
        existing = get_participant(int(rid)) or {}
        data = {
            "subject_id": (subject_id or "").strip(),
            "name": (name or "").strip(),
            "study": (study or "").strip(),
            "sex": (sex or "").strip(),
            "age": int(float(age)) if age not in (None,"") else None,
            "height_cm": float(height_cm) if height_cm not in (None,"") else None,
            "mass_kg": float(mass_kg) if mass_kg not in (None,"") else None,
            "test_date": (test_date or "").strip(),
            "modality": (modality or "").strip(),
            "rer_max": None, "hr_peak": None, "hr_pct_max": None,
            "critical_power": None,
            "file_name": "",
            "file_path": existing.get("file_path"),
        }
        update_participant(int(rid), data)
        return False, (refresh or 0) + 1

    @app.callback(Output("modal-edit","opened"), Input("edit-cancel","n_clicks"), prevent_initial_call=True)
    def cancel_edit(n):
        if not n: raise dash.exceptions.PreventUpdate
        return False
    
    # Delete (confirm/cancel) — closes modal and refreshes table
    @app.callback(
        Output("modal-delete", "opened", allow_duplicate=True),
        Output("refresh-token", "data", allow_duplicate=True),
        Input("delete-confirm", "n_clicks"),
        Input("delete-cancel", "n_clicks"),
        State("delete-row-id", "data"),
        State("refresh-token", "data"),
        prevent_initial_call=True
    )
    def on_delete(confirm, cancel, rid, refresh):
        trigger = ctx.triggered_id
        if trigger == "delete-cancel":
            # Just close the modal, no refresh
            return False, dash.no_update
        if trigger == "delete-confirm" and (confirm or 0) > 0 and rid:
            delete_participant(int(rid))
            # Close modal and bump refresh-token so the table reloads
            return False, (refresh or 0) + 1
        raise dash.exceptions.PreventUpdate

    # ↓↓↓ NEW: build all five figures + the threshold tile when a row is opened,
    #          and honor the legend menus on each card.
    @app.callback(
        Output("fig-vslope","figure"),
        Output("fig-vo2","figure"),
        Output("fig-ve-equiv","figure"),
        Output("fig-pet","figure"),
        Output("fig-rer","figure"),
        Output("threshold-table","children"),
        Input("route","data"),
        State("selected-row-id","data"),
        Input("legend-vslope","value"),  # ["points","slope","vt1","vt2"]
        Input("legend-vo2","value"),     # ["points","trace","vt1","vt2"]
        Input("legend-veeq","value"),    # ["vevo2","vevco2","vt1","vt2"]
        Input("legend-pet","value"),     # ["peto2","petco2","vt1","vt2"]
        Input("legend-rer","value"),     # ["rer","vt1","vt2"]
        prevent_initial_call=False
    )
    def _render_dashboard(route, rid, vslope_opts, vo2_opts, veeq_opts, pet_opts, rer_opts):
        import plotly.graph_objects as go

        # nice placeholder when nothing is selected yet
        def _empty(msg="Open a test from the Directory to see graphs."):
            f = go.Figure()
            f.update_layout(margin=dict(l=12, r=12, t=8, b=12), height=260,
                            annotations=[dict(text=msg, x=0.5, y=0.5, xref="paper", yref="paper",
                                              showarrow=False, align="center")])
            return f

        if route != "dashboard" or not rid:
            msg = "Open a test from the Directory to see graphs."
            return _empty(msg), _empty(msg), _empty(msg), _empty(msg), _empty(msg), html.Div()

        row = get_participant(int(rid)) or {}
        path = (row.get("file_path") or "").strip()
        if not path:
            msg = "No file attached to this row."
            return _empty(msg), _empty(msg), _empty(msg), _empty(msg), _empty(msg), html.Div()

        try:
            figs, vt_table_data = build_figures_from_file(path)
        except Exception as e:
            msg = f"Could not render from file.<br>{e}"
            return _empty(msg), _empty(msg), _empty(msg), _empty(msg), _empty(msg), html.Div()

        # normalize selections
        vslope_opts = set(vslope_opts or [])
        vo2_opts    = set(vo2_opts or [])
        veeq_opts   = set(veeq_opts or [])
        pet_opts    = set(pet_opts or [])
        rer_opts    = set(rer_opts or [])

        # helper: toggle visibility using legendgroup first, then by name
        def _apply(fig, mapping: dict):
            g = go.Figure(fig)
            for tr in g.data:
                lg = getattr(tr, "legendgroup", None)
                if lg in mapping:
                    tr.visible = bool(mapping[lg])
                elif tr.name in mapping:
                    tr.visible = bool(mapping[tr.name])
                # else: leave default visibility
            return g

        # V-Slope  (segments have legendgroup="slope"; points are named "VCO₂–VO₂ points")
        figs["vslope"] = _apply(figs["vslope"], {
            "slope":             ("slope"  in vslope_opts),
            "VCO₂–VO₂ points":   ("points" in vslope_opts),
            "VT1":               ("vt1"    in vslope_opts),
            "VT2":               ("vt2"    in vslope_opts),
        })

        # VO₂ vs Time  (points -> legendgroup "points", trendline -> "trace")
        figs["vo2"] = _apply(figs["vo2"], {
            "points":  ("points" in vo2_opts),
            "trace":   ("trace"  in vo2_opts),
            "VT1":     ("vt1"    in vo2_opts),
            "VT2":     ("vt2"    in vo2_opts),
        })

        # VE/VO₂ & VE/VCO₂
        figs["veeq"] = _apply(figs["veeq"], {
            "vevo2_pts":  ("vevo2_pts"  in veeq_opts),
            "vevo2_tr":   ("vevo2_tr"   in veeq_opts),
            "vevco2_pts": ("vevco2_pts" in veeq_opts),
            "vevco2_tr":  ("vevco2_tr"  in veeq_opts),
            "VT1":        ("vt1"        in veeq_opts),
            "VT2":        ("vt2"        in veeq_opts),
        })

        # PetO₂ / PetCO₂
        figs["pet"] = _apply(figs["pet"], {
            "peto2_pts":  ("peto2_pts"  in pet_opts),
            "peto2_tr":   ("peto2_tr"   in pet_opts),
            "petco2_pts": ("petco2_pts" in pet_opts),
            "petco2_tr":  ("petco2_tr"  in pet_opts),
            "VT1":        ("vt1"        in pet_opts),
            "VT2":        ("vt2"        in pet_opts),
        })

        # RER
        figs["rer"] = _apply(figs["rer"], {
            "rer_pts":    ("rer_pts"    in rer_opts),
            "rer_tr":     ("rer_tr"     in rer_opts),
            "VT1":        ("vt1"        in rer_opts),
            "VT2":        ("vt2"        in rer_opts),
        })

        return (
            figs["vslope"],
            figs["vo2"],
            figs["veeq"],
            figs["pet"],
            figs["rer"],
            threshold_detection_table(vt_table_data),
        )
    return app

# -------------------- pywebview wrapper --------------------
def run_directory_desktop():
    import webview
    app = make_directory_app()
    port = find_free_port(8050)
    url = f"http://127.0.0.1:{port}"

    def serve():
        app.run(debug=False, host="127.0.0.1", port=port)

    th = threading.Thread(target=serve, daemon=True); th.start()

    if not wait_for_server("127.0.0.1", port, timeout=20):
        webview.create_window("CPET Directory – server failed to start",
                              html="<h3>Server failed to start.</h3><p>Check if another copy is running or port is blocked.</p>",
                              width=520, height=240)
        webview.start()
        sys.exit(1)

    webview.create_window("CPET Directory", url, width=1280, height=800, resizable=True, confirm_close=True)
    webview.start()

# (main block from original directory removed in combined build)

# ---- END: CPET_Directory ----

def make_directory_app_combined():
    app = make_directory_app()
    return app

def run_combined_desktop():
    import webview, sys, threading
    app = make_directory_app()  # or: make_directory_app_combined()
    port = find_free_port(8050)
    url = f'http://127.0.0.1:{port}'

    def serve():
        app.run(debug=False, host='127.0.0.1', port=port)

    th = threading.Thread(target=serve, daemon=True)
    th.start()

    if not wait_for_server('127.0.0.1', port, timeout=20):
        webview.create_window(
            'CPET Directory – server failed to start',
            html='<h3>Server failed to start.</h3><p>Check if another copy is running or port is blocked.</p>',
            width=520, height=240
        )
        webview.start()
        sys.exit(1)

    webview.create_window('CPET Directory', url, width=1280, height=800, resizable=True, confirm_close=True)
    webview.start()

if __name__ == '__main__':
    run_directory_desktop()
