# === Combined CPET Directory + Dashboard ===
# Auto-generated by ChatGPT: keeps your original apps intact, just renamed & bridged.
# Files inlined: CPET_Directory.py (as make_directory_app) and PythonOnlyDashboard.py (as make_dashboard_app)

# ---- BEGIN: PythonOnlyDashboard (renamed) ----
# CPETDashboard_webview.py
# Dash (v3) + dash-mantine-components (v2) wrapped in a native desktop window via pywebview.

import threading, time, socket, sys
import json
import copy
import re
import numpy as np
import dash
from dash import html, dcc
import dash_mantine_components as dmc
import plotly.graph_objects as go
import pandas as pd
from pathlib import Path
import os
import math

# --- Colors to match VT_Testing.pyw ---
COL_BLUE        = "#377EB7"
COL_ORANGE      = "#FF7F0E"
COL_BLUE_DARK   = "#1E5F96"
COL_ORANGE_DARK = "#C85A0A"
COL_PURPLE      = "#800080"
COL_RED         = "#FF0000"
COL_GREEN       = "#008C46"

# --- LOESS settings to match VT_Testing.pyw ---
LOESS_SPAN_FRAC       = 0.30
LOESS_MIN_NEIGHBORS   = 9
LOESS_VO2_SPAN_FRAC   = 0.55
LOESS_VO2_MIN_NEI     = 25

# --- Broken-stick constraints (match VT_Testing.pyw) ---
BS_MIN_POINTS_PER_SIDE = 12
BS_MIN_XSPAN = 0.5
BS_Q_LO = 0.15
BS_Q_HI = 0.85
BS2_PRE_SLOPE_MIN = 0.85
BS2_PRE_SLOPE_MAX = 1.20
BS2_MID_SLOPE_MIN = 1.10
VSLOPE_GAP_POINTS = 1  # skip this many VO2 samples after a breakpoint

def loess(x, y, span_frac=LOESS_SPAN_FRAC, min_neighbors=LOESS_MIN_NEIGHBORS):
    """
    Tricube-weighted locally linear smoother (same math as VT_Testing.pyw)
    """
    x = np.asarray(x, dtype=float)
    y = np.asarray(y, dtype=float)
    n = len(x)
    out = np.full(n, np.nan)

    mask = np.isfinite(x) & np.isfinite(y)
    xv = x[mask]; yv = y[mask]
    m = len(xv)
    if m == 0:
        return out

    k = max(min_neighbors, int(np.ceil(span_frac * m)))
    k = min(k, m)

    for i in range(n):
        if not (np.isfinite(x[i]) and np.isfinite(y[i])):
            continue
        xi = x[i]
        d = np.abs(xv - xi)
        # distance to k-th nearest neighbor
        h = np.partition(d, k-1)[k-1]
        if h <= 0:
            out[i] = y[i]
            continue
        # tricube kernel weights
        w = (1.0 - (d / h) ** 3) ** 3
        use = w > 0
        if not np.any(use):
            out[i] = y[i]
            continue
        w = w[use]
        X = np.column_stack([np.ones(np.sum(use)), xv[use]])
        Y = yv[use]
        # weighted least squares
        W = np.diag(w)
        try:
            beta = np.linalg.lstsq(W @ X, W @ Y, rcond=None)[0]
            out[i] = beta[0] + beta[1] * xi
        except Exception:
            out[i] = y[i]
    return out

# ---------- VT detectors (same math/thresholds as VT_Testing.pyw) ----------
def detect_min_time(t, y, q_lo=0.05, q_hi=0.95):
    t = np.asarray(t, float); y = np.asarray(y, float)
    n = len(t)
    mask = np.isfinite(t) & np.isfinite(y)
    if mask.sum() < 3: return np.nan
    idx = np.where(mask)[0]
    i_lo = max(idx[0], int(math.ceil(q_lo * n)))
    i_hi = min(idx[-1], int(math.floor(q_hi * n)))
    if i_lo >= i_hi: i_lo, i_hi = idx[0], idx[-1]
    seg = np.arange(i_lo, i_hi + 1, dtype=int)
    seg = seg[np.isfinite(y[seg])]
    if len(seg) == 0: return np.nan
    i_min = seg[np.argmin(y[seg])]
    return t[i_min]

def moving_slope(t, y, k):
    t = np.asarray(t, float); y = np.asarray(y, float)
    n = len(t); out = np.full(n, np.nan)
    for i in range(n):
        L = max(0, i-k); U = min(n-1, i+k)
        tx = t[L:U+1]; yy = y[L:U+1]
        m = np.isfinite(tx) & np.isfinite(yy)
        tx = tx[m]; yy = yy[m]; cnt = len(tx)
        if cnt >= 2:
            Sx = tx.sum(); Sy = yy.sum()
            Sxx = (tx*tx).sum(); Sxy = (tx*yy).sum()
            denom = cnt*Sxx - Sx*Sx
            if abs(denom) > 1e-12:
                out[i] = (cnt*Sxy - Sx*Sy) / denom
    return out

def detect_vevco2_steepest_rise_start_strict(t, y_smooth, slope_window_pts=12,
                                              pos_slope_threshold=0.02, min_run=10):
    t = np.asarray(t, float); y = np.asarray(y_smooth, float)
    n = len(t)
    if n < 5: return np.nan
    mask = np.isfinite(y)
    if mask.sum() == 0: return np.nan
    i_min = np.where(mask)[0][0]
    i_max = np.where(mask)[0][-1]
    if i_min >= i_max-2: return np.nan
    s = moving_slope(t, y, slope_window_pts//2)
    for i in range(i_min, i_max - min_run):
        run_ok = True
        for j in range(i, i+min_run):
            if not (np.isfinite(s[j]) and s[j] >= pos_slope_threshold):
                run_ok = False; break
        if run_ok:
            return t[i]
    # fallback: find longest run after 1st positive slope
    for i in range(i_min, i_max-min_run):
        if np.isfinite(s[i]) and s[i] >= pos_slope_threshold:
            k = i; run = 0
            while k < i_max and np.isfinite(s[k]) and s[k] >= pos_slope_threshold:
                run += 1; k += 1
            if run >= min_run: return t[i]
            break
    return np.nan

def detect_vt2_petco2_steepest_run_start(t, y_smooth, slope_window_pts=12,
                                         min_run=10, neg_slope_threshold=-0.03,
                                         min_cum_drop=0.0):
    t = np.asarray(t, float); y = np.asarray(y_smooth, float)
    n = len(t)
    if n < 5: return np.nan
    mask = np.isfinite(y)
    if mask.sum() == 0: return np.nan
    i_max = np.where(mask)[0][np.argmax(y[mask])]
    if i_max >= n-2: return np.nan
    s = moving_slope(t, y, slope_window_pts//2)
    best_i = -1; best_avg = np.inf
    for i in range(i_max+1, n - min_run):
        block = s[i:i+min_run]
        if np.all(np.isfinite(block)):
            if min_cum_drop > 0 and (np.isfinite(y[i]) and np.isfinite(y[i+min_run])):
                if (y[i] - y[i+min_run]) < min_cum_drop:
                    continue
            avg = float(np.mean(block))
            if avg < best_avg: best_avg, best_i = avg, i
    if best_i < 0: return np.nan
    # walk back to first point in this negative-slope run
    k = best_i
    while k > i_max+1 and np.isfinite(s[k-1]) and s[k-1] <= neg_slope_threshold:
        k -= 1
    return t[k]

# ---------- Broken-stick V-slope (2 breaks) ----------
def _hinge(x, t):
    h = x - t; h[h < 0] = 0.0; return h

def broken_stick_fit2(x, y,
                      min_span=BS_MIN_XSPAN,
                      min_pts=BS_MIN_POINTS_PER_SIDE,
                      q_lo=BS_Q_LO, q_hi=BS_Q_HI,
                      pre_min=BS2_PRE_SLOPE_MIN,
                      pre_max=BS2_PRE_SLOPE_MAX,
                      mid_min=BS2_MID_SLOPE_MIN):
    x = np.asarray(x, float); y = np.asarray(y, float)
    mask = np.isfinite(x) & np.isfinite(y) & (x > 0) & (y > 0)
    xv = x[mask]; yv = y[mask]
    m = len(xv)
    if m < 3*min_pts: return None
    order = np.argsort(xv); xv = xv[order]; yv = yv[order]
    k_lo = max(min_pts, int(math.ceil(q_lo*m)))
    k_hi = min(m - min_pts, int(math.floor(q_hi*m)))
    if k_lo >= k_hi: return None

    best = dict(sse=np.inf)
    for k1 in range(k_lo, k_hi - min_pts + 1):
        t1 = xv[k1]
        if (t1 - xv[0]) < min_span: continue
        for k2 in range(k1 + min_pts, k_hi + 1):
            t2 = xv[k2]
            if (t2 - t1) < min_span: continue
            if (xv[-1] - t2) < min_span: continue
            H1, H2 = _hinge(xv, t1), _hinge(xv, t2)
            A = np.column_stack([np.ones_like(xv), xv, H1, H2])
            try:
                beta, *_ = np.linalg.lstsq(A, yv, rcond=None)
            except Exception:
                continue
            b0,b1,b2,b3 = map(float, beta)
            s1 = b1; s2 = b1 + b2; s3 = b1 + b2 + b3
            if not (pre_min <= s1 <= pre_max): continue
            if not (s2 >= mid_min): continue
            yhat = A @ beta
            sse = float(np.sum((yv - yhat)**2))
            if sse < best["sse"]:
                best = dict(sse=sse, t1=float(t1), t2=float(t2),
                            b0=b0, b1=b1, b2=b2, b3=b3,
                            s1=s1, s2=s2, s3=s3)
    return None if not np.isfinite(best.get("sse", np.inf)) else best

def _vslope_default_segs(bs, vo2_array):
    """Pre/mid/post segments; gap of VSLOPE_GAP_POINTS on the MIN side after each break."""
    if not bs or vo2_array is None: return None
    xs = np.asarray(vo2_array, float)
    xs = np.sort(np.unique(xs[np.isfinite(xs)]))
    if xs.size < 2: return None

    n = xs.size; b0,b1,b2,b3 = bs["b0"], bs["b1"], bs["b2"], bs["b3"]
    t1,t2 = float(bs["t1"]), float(bs["t2"])
    g = int(VSLOPE_GAP_POINTS)

    def f_pre(x):  return b0 + b1*x
    def f_mid(x):  return b0 + b1*x + b2*max(0, x - t1)
    def f_post(x): return b0 + b1*x + b2*max(0, x - t1) + b3*max(0, x - t2)

    i1 = int(np.searchsorted(xs, t1, side="left"))
    i2 = int(np.searchsorted(xs, t2, side="left"))

    pre_start, pre_end = 0, min(n - 1, i1)
    if pre_end < n and xs[pre_end] > t1 and pre_end > 0: pre_end -= 1

    mid_start, mid_end = min(n - 1, i1 + g), min(n - 1, i2)
    if mid_end < n and xs[mid_end] > t2 and mid_end > 0: mid_end -= 1

    post_start, post_end = min(n - 1, i2 + g), n - 1
    post_start = min(post_start, post_end)

    segs = []
    if pre_end > pre_start:
        x0, x1 = xs[pre_start], xs[pre_end]; segs.append(((x0, f_pre(x0)), (x1, f_pre(x1))))
    if mid_end > mid_start:
        x0, x1 = xs[mid_start], xs[mid_end]; segs.append(((x0, f_mid(x0)), (x1, f_mid(x1))))
    if post_end > post_start:
        x0, x1 = xs[post_start], xs[post_end]; segs.append(((x0, f_post(x0)), (x1, f_post(x1))))
    return segs

def _interp_at_x(x, y, x0):
    x = np.asarray(x, float); y = np.asarray(y, float)
    if not np.isfinite(x0): return np.nan
    for i in range(len(x) - 1):
        if np.isfinite(y[i]) and np.isfinite(y[i+1]):
            if (x[i] <= x0 <= x[i+1]) or (x[i] >= x0 >= x[i+1]):
                if x[i+1] != x[i]:
                    return float(y[i] + (y[i+1]-y[i])*(x0 - x[i])/(x[i+1]-x[i]))
                else:
                    return float(y[i])
    return np.nan

def _invert_y_to_x(x, y, y0):
    x = np.asarray(x, float); y = np.asarray(y, float)
    if not np.isfinite(y0): return np.nan
    for i in range(len(x) - 1):
        if np.isfinite(y[i]) and np.isfinite(y[i+1]):
            yi, yj = y[i], y[i+1]
            if (yi <= y0 <= yj) or (yi >= y0 >= yj):
                if yj != yi:
                    return float(x[i] + (x[i+1]-x[i])*(y0 - yi)/(yj - yi))
                else:
                    return float(x[i])
    return np.nan

# ----------------------------
# Sample Data (mirrors your canvas)
# ----------------------------
sample = {
    "context": {"modality": "bike", "protocol": "Ramp 25 W/min", "altitude_m": 210},
    "subject": {"name": "Alex Rider", "id": "A-1029", "age": 24, "sex": "M", "height_cm": 178, "mass_kg": 75},
    "kpi": {
        "vo2peak_L_min": 4.2, "vo2peak_ml_kg_min": 56.0, "vo2peak_pct_pred": 112,
        "peak_work_W": 360, "tte_s": 720,
        "rer_max": 1.17, "hr_peak": 196, "hr_pct_max": 98,
        "o2pulse_peak_ml_beat": 21.4, "ve_vco2_slope": 28.9, "petco2_nadir_mmHg": 39,
        "bp_peak_mmHg": "186/82",
    },
    "thresholds": {
        "vt1": {"t_s": 360, "hr": 158, "hr_pct_max": 79, "vo2_ml_kg_min": 38.5, "vo2_pct_peak": 69, "rer": 0.95,
                "work_W": 220, "ve_vo2": 26.1, "ve_vco2": 28.5, "petco2_mmHg": 42},
        "vt2": {"t_s": 600, "hr": 182, "hr_pct_max": 91, "vo2_ml_kg_min": 50.2, "vo2_pct_peak": 90, "rer": 1.05,
                "work_W": 310, "ve_vo2": 32.0, "ve_vco2": 30.5, "petco2_mmHg": 40},
    },
    "vslope": {"m1": 0.82, "m2": 1.02, "m3": 1.14, "r2": [0.98, 0.99, 0.97]},
    "economy": {
        "bike_vo2_ml_kg_min_at_W": {100: 22.0, 150: 26.5, 200: 31.0},
        "delta_vo2_per_W": 10.4, "oues": 2.35, "oues_per_kg": 0.031, "delta_hr_per_vo2": 2.8
    },
    "ventilation": {"ve_peak_L_min": 148},
}

def pct(x):    return f"{x:.0f}%"
def one(x):    return f"{x:.1f}"
def two(x):    return f"{x:.2f}"
def secs(x):   return f"{int(round(x))} s"

def vo2_abs_at(vt, vo2peak_L_min):
    return (vo2peak_L_min or 0) * ((vt.get("vo2_pct_peak", 0) or 0) / 100.0)

# ----------------------------
# Demo time-series
# ----------------------------
T = np.linspace(0, 780, 300)  # seconds
vo2 = 0.5 + 3.9 * (1 / (1 + np.exp(-(T-350)/80)))                          # VO₂
vco2 = 0.45 + 3.8 * (1 / (1 + np.exp(-(T-360)/80))) + 0.15*(T>600)         # VCO₂
ve_vo2 = 25 + 8*np.sin(T/180*np.pi)                                        # VE/VO₂
ve_vco2 = 24 + 6*np.cos(T/160*np.pi)                                       # VE/VCO₂
peto2 = 110 - 8*np.exp(-(T-360)**2/40000)                                  # PetO₂
petco2 = 38 + 3*np.exp(-(T-520)**2/50000) - 2*np.exp(-(T-360)**2/60000)    # PetCO₂
rer = vco2 / vo2

# ----------------------------
# Plotly Figures
# ----------------------------
def fig_vslope():
    m1, m2, m3 = sample["vslope"]["m1"], sample["vslope"]["m2"], sample["vslope"]["m3"]
    bp1, bp2 = 2.5, 3.7  # VO₂ breakpoints (L/min)
    x = np.concatenate([np.linspace(0.8, bp1, 30),
                        np.linspace(bp1, bp2, 30),
                        np.linspace(bp2, 4.4, 30)])
    y = np.piecewise(x,
                     [x<=bp1, (x>bp1)&(x<=bp2), x>bp2],
                     [lambda t: m1*t,
                      lambda t: m2*(t - bp1) + m1*bp1,
                      lambda t: m3*(t - bp2) + (m2*(bp2 - bp1) + m1*bp1)])
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=x, y=y, mode="lines", name="VCO₂ vs VO₂"))
    fig.add_vline(x=vo2_abs_at(sample["thresholds"]["vt1"], sample["kpi"]["vo2peak_L_min"]), line_dash="dot", line_color="#888")
    fig.add_vline(x=vo2_abs_at(sample["thresholds"]["vt2"], sample["kpi"]["vo2peak_L_min"]), line_dash="dot", line_color="#888")
    fig.add_annotation(text=f"m₁={two(m1)}<br>m₂={two(m2)}<br>m₃={two(m3)}",
                       xref="paper", yref="paper", x=0.98, y=0.98, showarrow=False,
                       align="right", bgcolor="rgba(255,255,255,0.6)")
    fig.update_layout(margin=dict(l=12,r=12,t=8,b=12), height=260,
                      xaxis_title="VO₂ (L·min⁻¹)", yaxis_title="VCO₂ (L·min⁻¹)")
    return fig

def fig_lines(xs, series, labels, x_title, y_title):
    fig = go.Figure()
    for y, label in zip(series, labels):
        fig.add_trace(go.Scatter(x=xs, y=y, mode="lines", name=label))
    fig.update_layout(margin=dict(l=12,r=12,t=8,b=12), height=260,
                      xaxis_title=x_title, yaxis_title=y_title,
                      showlegend=False)
    return fig

fig_vo2 = fig_lines(T, [vo2], ["VO₂"], "Time (s)", "VO₂ (L·min⁻¹)")
fig_ve_equiv = fig_lines(T, [ve_vo2, ve_vco2], ["VE/VO₂", "VE/VCO₂"], "Time (s)", "Ventilatory equivalents")
fig_pet = fig_lines(T, [peto2, petco2], ["PetO₂", "PetCO₂"], "Time (s)", "Partial pressure (mmHg)")
fig_rer = fig_lines(T, [rer], ["RER"], "Time (s)", "RER")
fig_vs = fig_vslope()

# ----------------------------
# UI helpers (cards/tiles)
# ----------------------------
def KPITile(label, value, sub=None, warn=False):
    return dmc.Paper(
        withBorder=True, shadow="xs", radius="xl", p="md",
        children=[
            dmc.Text(label, size="xs", tt="uppercase", c="dimmed"),
            dmc.Text(value, fw=600, size="lg"),
            dmc.Text(sub, size="xs", c="dimmed") if sub else None
        ],
        style={
            "background": "rgba(255,255,255,0.7)",
            "borderColor": "#e5e7eb",
        } | ({"borderColor": "#fca5a5", "background": "rgba(254,242,242,0.6)"} if warn else {})
    )

def Card(title, subtitle=None, right=None, content=None):
    header = dmc.Group([
        dmc.Stack([dmc.Text(title, fw=600, size="sm"), dmc.Text(subtitle, size="xs", c="dimmed")] if subtitle else [dmc.Text(title, fw=600, size="sm")]),
        right or html.Div()
    ], justify="space-between")
    return dmc.Paper(
        withBorder=True, shadow="sm", radius="xl", p=0,
        children=[dmc.Box(header, px="md", pt="md"), dmc.Box(content, p="md")]
    )

def LegendMenu(component_id: str, options: list[tuple[str, str]]):
    """
    component_id: e.g., 'legend-vslope' or 'legend-vo2'
    options: [(value, label), ...]  e.g., [('slope','Slope lines (green)'), ('vt1','VT1')]
    """
    default_vals = [v for v, _ in options]  # everything ON by default

    def swatch(val: str):
        # line sample
        def line(color: str, style: str = "solid"):
            return dmc.Box(style={
                "width": "22px", "height": 0,
                "borderTop": f"3px {style} {color}",
                "marginTop": "7px"
            })
        # dot sample (points)
        def dot(color: str):
            return dmc.Box(style={
                "width": "10px", "height": "10px",
                "borderRadius": "50%", "background": color
            })

        # --- back-compat (single-series menus) ---
        if val == "slope":   return line(COL_GREEN, "solid")
        if val == "vt1":     return line(COL_PURPLE, "dotted")
        if val == "vt2":     return line(COL_RED,    "dotted")
        if val == "trace":   return line(COL_BLUE_DARK, "solid")
        if val == "points":  return dot(COL_BLUE)

        # --- new multi-series keys: e.g., vevo2_pts / vevo2_tr, petco2_pts / petco2_tr, rer_tr ---
        if "_" in val:
            base, kind = val.rsplit("_", 1)   # base: vevo2|vevco2|peto2|petco2|rer ; kind: pts|tr
            base_colors = {
                "vevo2":  (COL_BLUE,   COL_BLUE_DARK),
                "vevco2": (COL_ORANGE, COL_ORANGE_DARK),
                "peto2":  (COL_BLUE,   COL_BLUE_DARK),
                "petco2": (COL_ORANGE, COL_ORANGE_DARK),
                "rer":    (COL_BLUE,   COL_BLUE_DARK),
            }.get(base, (COL_BLUE, COL_BLUE_DARK))
            if kind == "pts":
                return dot(base_colors[0])
            if kind == "tr":
                return line(base_colors[1], "solid")

        # fallback (no swatch)
        return dmc.Box()

    checks = [
        dmc.Checkbox(
            value=val,
            label=dmc.Group([swatch(val), dmc.Text(lbl)], gap="xs", align="center")
        )
        for val, lbl in options
    ]

    return dmc.Popover(
        width=240,
        position="bottom-end",
        withArrow=True,
        children=[
            dmc.PopoverTarget(
                dmc.Button("Legend", size="xs", variant="light", color="gray")
            ),
            dmc.PopoverDropdown(dmc.CheckboxGroup(id=component_id, value=default_vals, children=checks)),
        ],
    )

# ----------------------------
# Threshold detection table (Test | VT1 | VT2)
# ----------------------------
def threshold_detection_table(vt_source=None, highlight=None):
    """
    Render the threshold detection table with optional row highlighting.
    highlight: {"vt1": [row names], "vt2": [row names]}
    """
    VT1_BG   = "#F3E6FF"
    VT1_HDR  = "#E3C8FF"
    VT1_TX   = "#4A2E86"
    VT2_BG   = "#FFE6E6"
    VT2_HDR  = "#FFC8C8"
    VT2_TX   = "#942626"

    import math

    def fmt2(x):
        try:
            xv = float(x)
            return f"{xv:.2f}"
        except Exception:
            return "—"

    def fmt_time_min(v):
        if v is None:
            return "—"
        try:
            if isinstance(v, dict):
                if "t_min" in v:
                    tm = float(v["t_min"])
                elif "t_s" in v:
                    tm = float(v["t_s"]) / 60.0
                else:
                    tm = float(v)
            else:
                tm = float(v)
            if not math.isfinite(tm):
                return "—"
            return f"{tm:.2f}"
        except Exception:
            return "—"

    def pct(x):
        try:
            xv = float(x)
            if xv <= 1.0:
                xv *= 100.0
            return f"{xv:.0f}%"
        except Exception:
            return "—"

    def conf_badge(level):
        level = (level or "").strip().capitalize()
        color = {"High": "green", "Med": "yellow", "Low": "red"}.get(level, "gray")
        return dmc.Badge(level or "—", color=color, variant="light", radius="sm")

    highlight = highlight or {}
    highlight_vt1 = set(highlight.get("vt1") or [])
    highlight_vt2 = set(highlight.get("vt2") or [])

    def apply_highlight(style: dict, active: bool):
        if not active:
            return style
        st = dict(style)
        st.setdefault("boxShadow", "inset 0 0 0 2px #1E5F96")
        st.setdefault("fontWeight", 600)
        return st

    if vt_source and isinstance(vt_source, dict):
        vt1 = vt_source.get("vt1", {})
        vt2 = vt_source.get("vt2", {})
    else:
        vt1 = sample["thresholds"]["vt1"]
        vt2 = sample["thresholds"]["vt2"]

    def vt_vals(vt):
        vo2 = vt.get("vo2") or vt.get("vo2_L_min")
        tmin = vt.get("t_min")
        if tmin is None and "t_s" in vt:
            tmin = vt["t_s"] / 60.0
        rer = vt.get("rer")
        vo2pct = vt.get("vo2_pct_peak")
        conf = vt.get("confidence") or vt.get("conf")
        return vo2, tmin, rer, vo2pct, conf

    vt1_vo2, vt1_tmin, vt1_rer, vt1_pct, vt1_conf = vt_vals(vt1)
    vt2_vo2, vt2_tmin, vt2_rer, vt2_pct, vt2_conf = vt_vals(vt2)

    tests_left = ["V-Slope", "VE/VO₂ minimum", "PetO₂ minimum", "Average"]
    tests_right = ["V-Slope", "VE/VCO₂ rise (start)", "PetCO₂ drop (start)", "Average"]

    def _fmt2(x):
        try:
            return f"{float(x):.2f}"
        except Exception:
            return "—"

    body_rows = []
    for tl, tr in zip(tests_left, tests_right):
        row_active_vt1 = tl in highlight_vt1
        row_active_vt2 = tr in highlight_vt2
        left_style = {"textAlign": "left", "whiteSpace": "normal", "lineHeight": "1.15", "padding": "6px 8px", "width": "120px", "maxWidth": "160px"}
        left = html.Td(
            dmc.Text("Average", fw=600) if tl == "Average" else tl,
            style=apply_highlight(left_style, row_active_vt1 or row_active_vt2)
        )

        if isinstance(vt_source, dict) and "vt1" in vt_source and "vt2" in vt_source:
            L = vt_source["vt1"].get(tl, {})
            R = vt_source["vt2"].get(tr, {})
            vt1_cells = [
                html.Td(_fmt2(L.get("vo2")),      style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(_fmt2(L.get("t_min")),    style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(_fmt2(L.get("rer")),      style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(pct(L.get("vo2_pct_peak")), style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(conf_badge(None),         style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
            ]
            vt2_cells = [
                html.Td(_fmt2(R.get("vo2")),      style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(_fmt2(R.get("t_min")),    style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(_fmt2(R.get("rer")),      style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(pct(R.get("vo2_pct_peak")), style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(conf_badge(None),         style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
            ]
        else:
            vt1_cells = [
                html.Td(fmt2(vt1_vo2),  style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(fmt2(vt1_tmin), style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(fmt2(vt1_rer),  style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(pct(vt1_pct),   style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
                html.Td(conf_badge(vt1_conf), style=apply_highlight({"background": VT1_BG, "textAlign": "center"}, row_active_vt1)),
            ]
            vt2_cells = [
                html.Td(fmt2(vt2_vo2),  style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(fmt2(vt2_tmin), style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(fmt2(vt2_rer),  style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(pct(vt2_pct),   style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
                html.Td(conf_badge(vt2_conf), style=apply_highlight({"background": VT2_BG, "textAlign": "center"}, row_active_vt2)),
            ]

        body_rows.append(html.Tr([left] + vt1_cells + vt2_cells))

    header = html.Thead([
        html.Tr([
            html.Th("Test", rowSpan=2, style={"textAlign": "left", "padding": "6px 10px", "minWidth": "160px"}),
            html.Th("VT1", colSpan=5, style={"textAlign": "center", "background": VT1_HDR, "color": VT1_TX}),
            html.Th("VT2", colSpan=5, style={"textAlign": "center", "background": VT2_HDR, "color": VT2_TX}),
        ]),
        html.Tr([
            html.Th("VO₂",        style={"textAlign": "center", "background": VT1_BG}),
            html.Th("Time",       style={"textAlign": "center", "background": VT1_BG}),
            html.Th("RER",        style={"textAlign": "center", "background": VT1_BG}),
            html.Th("%VO₂ Max",   style={"textAlign": "center", "background": VT1_BG}),
            html.Th("Confidence", style={"textAlign": "center", "background": VT1_BG}),
            html.Th("VO₂",        style={"textAlign": "center", "background": VT2_BG}),
            html.Th("Time",       style={"textAlign": "center", "background": VT2_BG}),
            html.Th("RER",        style={"textAlign": "center", "background": VT2_BG}),
            html.Th("%VO₂ Max",   style={"textAlign": "center", "background": VT2_BG}),
            html.Th("Confidence", style={"textAlign": "center", "background": VT2_BG}),
        ])
    ])

    return dmc.Table(
        [header, html.Tbody(body_rows)],
        withTableBorder=True,
        withRowBorders=True,
        horizontalSpacing="md",
        verticalSpacing="xs",
        style={"width": "100%"},
    )


# ----------------------------
# Dash app factory
# ----------------------------
def make_dashboard_app():
    app = dash.Dash(__name__, title="CPET Directory", suppress_callback_exceptions=True)
    app.layout = dashboard_view()
    register_dashboard_callbacks(app)
    return app

def dashboard_view():
    return dmc.MantineProvider(
        theme={
            "fontFamily": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif",
            "defaultRadius": "xl"
        },
        children=dmc.Container(size=1200, px="md", children=[
            # Header
            dmc.Paper(
                withBorder=True, radius="xl", shadow="xs", p="md", mb="md",
                children=dmc.Group([
                    dmc.Text("CPET VO₂ Training Dashboard", fw=700),
                    dmc.Group([
                        dmc.Button("← Back to Directory", id="btn-back", variant="light", color="gray"),
                        dmc.Button("Edit VT1/VT2", id="btn-edit-vt", color="blue"),
                    ], gap="xs")
                ], justify="space-between")
            ),
            # KPI row
            dmc.SimpleGrid(cols=8, spacing="sm", children=[
                KPITile("VO₂peak", f"{two(sample['kpi']['vo2peak_L_min'])} L·min⁻¹"),
                KPITile("VO₂peak/kg", f"{one(sample['kpi']['vo2peak_ml_kg_min'])} mL·kg⁻¹·min⁻¹"),
                KPITile("Peak Output", f"{sample['kpi']['peak_work_W']} W"),
                KPITile("Critical Power", "290 W"),
                KPITile("RERmax", f"{two(sample['kpi']['rer_max'])}", warn=(sample['kpi']['rer_max']<1.05)),
                KPITile("HRpeak", f"{sample['kpi']['hr_peak']} bpm", sub=f"{pct(sample['kpi']['hr_pct_max'])} of max"),
                KPITile("VE/VCO₂ slope", f"{one(sample['kpi']['ve_vco2_slope'])}"),
                KPITile("BP Peak", sample['kpi']['bp_peak_mmHg']),
            ], mb="md"),
            # Main grid
            dmc.Grid(grow=True, gutter="md", children=[
                # Left sidebar
                dmc.GridCol(span={"base":12,"lg":3}, children=dmc.Stack(gap="sm", children=[
                    Card("Subject", subtitle=f"{sample['subject']['name']} · ID {sample['subject']['id']}",
                         content=dmc.SimpleGrid(cols=2, spacing="xs", children=[
                             dmc.Text("Age", size="xs", c="dimmed"), dmc.Text(f"{sample['subject']['age']}"),
                             dmc.Text("Sex", size="xs", c="dimmed"), dmc.Text(sample['subject']['sex']),
                             dmc.Text("Mass", size="xs", c="dimmed"), dmc.Text(f"{sample['subject']['mass_kg']} kg"),
                             dmc.Text("Height", size="xs", c="dimmed"), dmc.Text(f"{sample['subject']['height_cm']} cm"),
                         ])),
                    Card("Protocol", subtitle=("Cycling" if sample["context"]["modality"]=="bike" else "Treadmill"),
                         content=dmc.Text(sample["context"]["protocol"], size="sm")),
                    Card("Quality", content=dmc.SimpleGrid(cols=2, spacing="xs", children=[
                        dmc.Text("Max RER", size="xs", c="dimmed"), dmc.Text(two(sample["kpi"]["rer_max"])),
                        dmc.Text("Max HR", size="xs", c="dimmed"), dmc.Text(f"{sample['kpi']['hr_peak']} bpm"),
                        dmc.Text("% HRmax", size="xs", c="dimmed"), dmc.Text(pct(sample["kpi"]["hr_pct_max"])),
                    ])),
                    Card("Extra", subtitle="Supplementary metrics", content=dmc.Stack(gap=6, children=[
                        dmc.Group([dmc.Text("VO₂peak % predicted", size="xs", c="dimmed"), dmc.Text(pct(sample["kpi"]["vo2peak_pct_pred"]))], gap="xs"),
                        dmc.Group([dmc.Text("TTE @ peak", size="xs", c="dimmed"), dmc.Text(secs(sample["kpi"]["tte_s"]))], gap="xs"),
                        dmc.Group([dmc.Text("ΔVO₂/ΔWorkrate", size="xs", c="dimmed"), dmc.Text(f"{one(sample['economy']['delta_vo2_per_W'])} mL·min⁻¹·W⁻¹")], gap="xs"),
                        dmc.Text("Standardized economy", size="xs", c="dimmed"),
                        dmc.Group(gap="xs", children=[
                            dmc.Badge(f"VO₂@100 W: {one(22.0)}", variant="light"),
                            dmc.Badge(f"VO₂@150 W: {one(26.5)}", variant="light"),
                            dmc.Badge(f"VO₂@200 W: {one(31.0)}", variant="light"),
                        ]),
                        dmc.Group([dmc.Text("OUES", size="xs", c="dimmed"), dmc.Text(two(sample["economy"]["oues"]))], gap="xs"),
                        dmc.Group([dmc.Text("OUES/kg", size="xs", c="dimmed"), dmc.Text(two(sample["economy"]["oues_per_kg"]))], gap="xs"),
                        dmc.Group([dmc.Text("ΔHR/ΔVO₂", size="xs", c="dimmed"), dmc.Text(one(sample["economy"]["delta_hr_per_vo2"]))], gap="xs"),
                        dmc.Group([dmc.Text("VEpeak", size="xs", c="dimmed"), dmc.Text(f"{sample['ventilation']['ve_peak_L_min']} L·min⁻¹")], gap="xs"),
                    ])),
                ])),
                # Right content
                dmc.GridCol(span={"base":12,"lg":9}, children=dmc.Stack(gap="sm", children=[
                    Card("Threshold Detection", content=html.Div(id="threshold-table")),
                dmc.SimpleGrid(cols=2, spacing="sm", children=[
                    Card(
                        "V-Slope",
                        right=LegendMenu("legend-vslope", [
                            ("points", "VCO₂–VO₂ points"),
                            ("slope",  "Slope lines"),
                            ("vt1",    "VT1"),
                            ("vt2",    "VT2"),
                        ]),
                        content=dcc.Graph(id="fig-vslope", config={"displaylogo": False}),
                    ),
                    Card(
                        "VO₂ vs Time",
                        right=LegendMenu("legend-vo2", [
                            ("points", "VO₂ (points)"),
                            ("trace",  "VO₂ Trace"),
                            ("vt1",    "VT1"),
                            ("vt2",    "VT2"),
                        ]),
                        content=dcc.Graph(id="fig-vo2", config={"displaylogo": False}),
                    ),
                ]),
                    dmc.SimpleGrid(cols=2, spacing="sm", children=[
                        Card(
                            "VE/VO₂ & VE/VCO₂ vs Time",
                            right=LegendMenu("legend-veeq", [
                                ("vevo2_pts",  "VE/VO₂ (points)"),
                                ("vevo2_tr",   "VE/VO₂ (trend)"),
                                ("vevco2_pts", "VE/VCO₂ (points)"),
                                ("vevco2_tr",  "VE/VCO₂ (trend)"),
                                ("vt1", "VT1"),
                                ("vt2", "VT2"),
                            ]),
                        content=dcc.Graph(id="fig-ve-equiv", config={"displaylogo": False})),
                        Card(
                            "PetO₂ & PetCO₂ vs Time",
                            right=LegendMenu("legend-pet", [
                                ("peto2_pts",  "PetO₂ (points)"),
                                ("peto2_tr",   "PetO₂ (trend)"),
                                ("petco2_pts", "PetCO₂ (points)"),
                                ("petco2_tr",  "PetCO₂ (trend)"),
                                ("vt1", "VT1"),
                                ("vt2", "VT2"),
                            ]),
                        content=dcc.Graph(id="fig-pet", config={"displaylogo": False})),
                    ]),
                    dmc.SimpleGrid(cols=2, spacing="sm", children=[
                        Card(
                            "RER vs Time",
                            right=LegendMenu("legend-rer", [
                                ("rer_pts", "RER (points)"),
                                ("rer_tr",  "RER (trend)"),
                                ("vt1", "VT1"),
                                ("vt2", "VT2"),
                            ]),
                            content=dcc.Graph(id="fig-rer", config={"displaylogo": False})),
                        html.Div()
                    ]),
                ])),
            ]),
            dmc.Space(h=24),
            dmc.Text("This mock shows layout and key readouts. Wire your parser/algorithms to replace demo series.", size="xs", c="dimmed", mb="lg"),
            dmc.Modal(
                id="modal-vt-edit",
                opened=False,
                withCloseButton=False,
                fullScreen=True,
                overlayProps={"color": "#0c0d21", "opacity": 0.55, "blur": 3},
                children=dmc.Center(
                    dmc.Paper(
                        shadow="xl",
                        radius="lg",
                        withBorder=True,
                        p="md",
                        style={"width": "100%", "maxWidth": 960, "height": "96vh", "display": "flex", "flexDirection": "column"},
                        children=[
                            dmc.Group(
                                [
                                    dmc.Group(
                                        [
                                            dmc.Button("Undo", id="vt-edit-undo", variant="light", color="gray"),
                                            dmc.Button("Redo", id="vt-edit-redo", variant="light", color="gray"),
                                            dmc.Button("Save Chart", id="vt-edit-save", color="blue"),
                                        ],
                                        gap="xs",
                                    ),
                                    dmc.Text(id="vt-edit-title", fw=600),
                                    dmc.ActionIcon(
                                        html.Span("✕", style={"fontSize": "16px", "lineHeight": 1}),
                                        id="vt-edit-close",
                                        variant="light",
                                        color="red",
                                        radius="lg",
                                        size="lg",
                                    ),
                                ],
                                justify="space-between",
                                align="center",
                                mb="sm",
                            ),
                            dmc.Group(
                                [
                                    dmc.ActionIcon(html.Span("←", style={"fontSize": "20px", "lineHeight": 1}), id="vt-edit-prev", variant="light", radius="xl", size="lg"),
                                    dcc.Graph(
                                        id="vt-edit-graph",
                                        figure=go.Figure(),
                                        config={
                                            "displaylogo": False,
                                            "scrollZoom": False,
                                            "edits": {"shapePosition": True},
                                            "modeBarButtonsToRemove": [
                                                "lasso2d",
                                                "select2d",
                                                "zoomIn2d",
                                                "zoomOut2d",
                                                "autoScale2d",
                                                "resetScale2d",
                                            ],
                                        },
                                        style={"flex": 1, "height": "60vh"},
                                    ),
                                    dmc.ActionIcon(html.Span("→", style={"fontSize": "20px", "lineHeight": 1}), id="vt-edit-next", variant="light", radius="xl", size="lg"),
                                ],
                                align="center",
                                style={"flex": 1},
                                gap="md",
                            ),
                            dmc.Space(h="md"),
                            html.Div(id="vt-edit-threshold", style={"overflowY": "auto"}),
                        ],
                    )
                ),
            ),
            dcc.Store(id="vt-edit-state"),
            dcc.Store(id="vt-overrides-version", data=0),
            html.Script(
                """
                (function(){
                    if (window.__cpetVtHotkeysAttached) {return;}
                    window.__cpetVtHotkeysAttached = true;
                    document.addEventListener('keydown', function(ev){
                        if (!ev.ctrlKey) {return;}
                        const undoBtn = document.getElementById('vt-edit-undo');
                        if (!undoBtn || undoBtn.offsetParent === null) {return;}
                        if (ev.key === 'z' || ev.key === 'Z') {
                            if (!undoBtn.disabled) { undoBtn.click(); ev.preventDefault(); }
                        } else if (ev.key === 'y' || ev.key === 'Y') {
                            const redoBtn = document.getElementById('vt-edit-redo');
                            if (redoBtn && !redoBtn.disabled) { redoBtn.click(); ev.preventDefault(); }
                        }
                    });
                })();
                """
            ),
        ])
    )

from dash import Input, Output, State, exceptions, callback
import plotly.graph_objects as go
import sqlite3

def _get_path_for_id(row_id):
    try:
        conn = sqlite3.connect(DB_PATH)
        cur = conn.cursor()
        cur.execute("SELECT file_path FROM participants WHERE id=?", (row_id,))
        row = cur.fetchone()
        conn.close()
        return row[0] if row else None
    except Exception:
        return None

# ----------------------------
# Native window via pywebview
# ----------------------------
def find_free_port(start=8050, attempts=50):
    for port in range(start, start + attempts):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex(("127.0.0.1", port)) != 0:
                return port
    return start

def wait_for_server(host, port, timeout=20):
    start = time.time()
    while time.time() - start < timeout:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            if s.connect_ex((host, port)) == 0:
                return True
        time.sleep(0.2)
    return False

def run_dashboard_desktop():
    # Import here so PyInstaller pulls it in only when used
    import webview

    app = make_dashboard_app()
    port = find_free_port(8050)
    url = f"http://127.0.0.1:{port}"

    def serve():
        # Dash v3: .run (not .run_server)
        app.run(debug=False, host="127.0.0.1", port=port)

    th = threading.Thread(target=serve, daemon=True)
    th.start()

    if not wait_for_server("127.0.0.1", port, timeout=20):
        # As a fallback, show a small info window
        webview.create_window("CPET Dashboard – server failed to start", html="<h3>Server failed to start.</h3><p>Check if another copy is running or port is blocked.</p>", width=520, height=240)
        webview.start()
        sys.exit(1)

    # Create the native window
    window = webview.create_window("CPET Dashboard", url, width=1280, height=800, resizable=True, confirm_close=True)
    webview.start()  # blocks until window closed; daemon thread will end with process
import os  # if not already imported

def _sniff_excel_format(path: str) -> str:
    """
    Sniff the actual file container so we treat legacy .xls correctly.
    Returns one of: 'xls', 'xlsx', 'xlsb', 'csv', 'unknown'
    """
    try:
        with open(path, 'rb') as f:
            head = f.read(8)
    except Exception:
        return 'unknown'

    # Old binary Excel
    if head.startswith(b'\xD0\xCF\x11\xE0'):
        return 'xls'

    # ZIP container (xlsx/xlsm/xltx/xltm/xlsb)
    if head.startswith(b'PK\x03\x04'):
        ext = os.path.splitext(path)[1].lower()
        if ext == '.xlsb':
            return 'xlsb'
        return 'xlsx'

    # Plain text fallback by extension
    ext = os.path.splitext(path)[1].lower()
    if ext in ('.csv', '.txt'):
        return 'csv'

    return 'unknown'

# ----------------------------
# Timeseries loader from saved file
# ----------------------------
def _nan_div(a, b):
    a = np.asarray(a, float); b = np.asarray(b, float)
    with np.errstate(divide='ignore', invalid='ignore'):
        out = a / b
        out[~np.isfinite(out)] = np.nan
    return out

def load_timeseries_from_path(path: str):
    """
    Robust CPET loader that supports:
      - .xls (BIFF) via xlrd
      - .xlsx/.xlsm via openpyxl
      - .xlsb via pyxlsb
      - CSV / mis-labeled text
      - Excel 2003 XML (SpreadsheetML) often saved as .xls
    Then parses the Parvo fixed-grid (row 30 onward).
    Returns: dict(t, vo2, vco2, ve, rer, peto2, petco2, ve_vo2, ve_vco2)
    """
    if not path:
        raise RuntimeError("No file_path stored for this entry.")
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"File does not exist: {p}")
    if p.is_dir():
        raise RuntimeError(f"Path is a directory, not a file: {p}")

    raw = p.read_bytes()
    head = raw[:4096].lstrip()

    # ---------- FIRST: handle Excel 2003 XML (SpreadsheetML) ----------
    # These files often carry a .xls extension but start with <?xml ... <Workbook ...>
    if head.startswith(b'<?xml') and b'<Workbook' in head:
        import xml.etree.ElementTree as ET, re as _re
        try:
            root = ET.fromstring(raw)
            # detect default namespace, e.g. '{urn:schemas-microsoft-com:office:spreadsheet}Workbook'
            m = _re.match(r'\{([^}]+)\}', root.tag)
            ns = m.group(1) if m else ""
            def q(tag): return f"{{{ns}}}{tag}" if ns else tag

            rows = []
            for row in root.iter(q("Row")):
                vals = []
                for cell in row.iter(q("Cell")):
                    data = cell.find(q("Data"))
                    vals.append("" if data is None or data.text is None else data.text)
                rows.append(vals)
            df = pd.DataFrame(rows)
        except Exception as e:
            raise RuntimeError(f"Unable to read Excel 2003 XML: {e}")
    else:
        # ---------- Otherwise: try a sequence of readers, regardless of extension ----------
        df = None
        errors = []

        # 1) openpyxl (xlsx container)
        try:
            df = pd.read_excel(path, sheet_name=0, header=None, engine="openpyxl")
        except Exception as e:
            errors.append(f"openpyxl: {e}")

        # 2) xlrd (legacy xls)
        if df is None:
            try:
                import xlrd
                try:
                    # try pandas first
                    df = pd.read_excel(path, sheet_name=0, header=None, engine="xlrd")
                except Exception:
                    # fall back to raw xlrd like your old script
                    book = xlrd.open_workbook(path)
                    sh = book.sheet_by_index(0)
                    data = [[sh.cell_value(r, c) for c in range(sh.ncols)] for r in range(sh.nrows)]
                    df = pd.DataFrame(data)
            except Exception as e:
                errors.append(f"xlrd: {e}")

        # 3) xlsb
        if df is None:
            try:
                df = pd.read_excel(path, sheet_name=0, header=None, engine="pyxlsb")
            except Exception as e:
                errors.append(f"pyxlsb: {e}")

        # 4) CSV sniffing (handles mislabeled text)
        if df is None:
            try:
                df = pd.read_csv(path, header=None)
            except Exception as e_csv:
                try:
                    df = pd.read_csv(path, header=None, sep=None, engine="python")
                except Exception as e2:
                    errors.append(f"csv: {e_csv} | sniff: {e2}")

        if df is None:
            raise RuntimeError("Unsupported file format or unable to read as Excel/CSV. "
                               f"Details: {' | '.join(errors[-3:])}")

    # ---------- Parvo fixed-grid parsing (row 30 onward; 0-indexed=29) ----------
    FIRST_DATA_ROW_IDX = 29
    COL_TIME, COL_VO2, COL_VCO2, COL_VE, COL_RER, COL_PETO2, COL_PETCO2 = 0, 1, 4, 5, 6, 15, 16

    if df.shape[0] <= FIRST_DATA_ROW_IDX:
        raise RuntimeError("File has fewer than 30 rows; cannot find data starting at row 30.")

    blk = df.iloc[FIRST_DATA_ROW_IDX:, :].replace("", np.nan).infer_objects(copy=False)

    def colsafe(i):
        if i >= blk.shape[1]:
            return np.full(len(blk), np.nan, dtype=float)
        return pd.to_numeric(blk.iloc[:, i], errors="coerce").to_numpy(dtype=float)

    t      = colsafe(COL_TIME)
    vo2    = colsafe(COL_VO2)
    vco2   = colsafe(COL_VCO2)
    ve     = colsafe(COL_VE)
    rer    = colsafe(COL_RER)
    peto2  = colsafe(COL_PETO2)
    petco2 = colsafe(COL_PETCO2)

    valid = np.isfinite(t)
    if valid.sum() == 0:
        raise RuntimeError("No valid time values found in time column (col A).")

    last = np.where(valid)[0][-1]
    sl = slice(0, last + 1)
    t, vo2, vco2, ve, rer, peto2, petco2 = t[sl], vo2[sl], vco2[sl], ve[sl], rer[sl], peto2[sl], petco2[sl]

    # RER fallback
    if not np.isfinite(rer).any() and np.isfinite(vco2).any() and np.isfinite(vo2).any():
        with np.errstate(divide="ignore", invalid="ignore"):
            rer = vco2 / vo2
            rer[~np.isfinite(rer)] = np.nan

    # Ventilatory equivalents
    with np.errstate(divide="ignore", invalid="ignore"):
        ve_vo2  = ve / vo2
        ve_vco2 = ve / vco2
        ve_vo2[~np.isfinite(ve_vo2)] = np.nan
        ve_vco2[~np.isfinite(ve_vco2)] = np.nan

    return dict(t=t, vo2=vo2, vco2=vco2, ve=ve, rer=rer, peto2=peto2, petco2=petco2,
                ve_vo2=ve_vo2, ve_vco2=ve_vco2)

# ----------------------------
# Figure builders (data-driven)
# ----------------------------
def _fig_lines(x, ys, labels, xlab, ylab):
    fig = go.Figure()
    for y, lab in zip(ys, labels):
        fig.add_trace(go.Scatter(x=x, y=y, mode="lines", name=lab))
    fig.update_layout(margin=dict(l=12,r=12,t=8,b=12), height=260,
                      xaxis_title=xlab, yaxis_title=ylab,
                      legend=dict(orientation="h", yanchor="bottom", y=1.02, x=0))
    return fig

def _mk_row_from_vo2(vt_vo2, t, vo2_L, rer_L, vo2_peak):
    tm = _invert_y_to_x(t, vo2_L, vt_vo2)
    rr = _interp_at_x(t, rer_L, tm)
    return {
        "vo2": float(vt_vo2) if np.isfinite(vt_vo2) else None,
        "t_min": float(tm) if np.isfinite(tm) else None,
        "rer": float(rr) if np.isfinite(rr) else None,
        "vo2_pct_peak": float(100.0 * vt_vo2 / vo2_peak) if np.isfinite(vt_vo2) and np.isfinite(vo2_peak) and vo2_peak > 0 else None,
    }

def _mk_row_from_time(vt_t, t, vo2_L, rer_L, vo2_peak):
    v = _interp_at_x(t, vo2_L, vt_t)
    rr = _interp_at_x(t, rer_L, vt_t)
    return {
        "vo2": float(v) if np.isfinite(v) else None,
        "t_min": float(vt_t) if np.isfinite(vt_t) else None,
        "rer": float(rr) if np.isfinite(rr) else None,
        "vo2_pct_peak": float(100.0 * v / vo2_peak) if np.isfinite(v) and np.isfinite(vo2_peak) and vo2_peak > 0 else None,
    }

def compute_cpet_analysis(path: str):
    ts = load_timeseries_from_path(path)

    t = np.asarray(ts["t"], float)
    vo2 = np.asarray(ts["vo2"], float)
    vco2 = np.asarray(ts["vco2"], float)
    ve = np.asarray(ts["ve"], float)
    rer = np.asarray(ts["rer"], float)
    peto2 = np.asarray(ts["peto2"], float)
    petco2 = np.asarray(ts["petco2"], float)

    with np.errstate(divide="ignore", invalid="ignore"):
        ve_vo2 = ve / vo2
        ve_vco2 = ve / vco2
        ve_vo2[~np.isfinite(ve_vo2)] = np.nan
        ve_vco2[~np.isfinite(ve_vco2)] = np.nan

    m_peto2 = np.nanmean(peto2) if np.isfinite(peto2).any() else np.nan
    m_petco2 = np.nanmean(petco2) if np.isfinite(petco2).any() else np.nan
    peto2n = (peto2 / m_peto2) if np.isfinite(m_peto2) and m_peto2 != 0 else np.full_like(peto2, np.nan)
    petco2n = (petco2 / m_petco2) if np.isfinite(m_petco2) and m_petco2 != 0 else np.full_like(petco2, np.nan)

    vo2_L = loess(t, vo2, span_frac=LOESS_VO2_SPAN_FRAC, min_neighbors=LOESS_VO2_MIN_NEI)
    ve_vo2_L = loess(t, ve_vo2)
    ve_vco2_L = loess(t, ve_vco2)
    peto2n_L = loess(t, peto2n)
    petco2n_L = loess(t, petco2n)
    rer_L = loess(t, rer)

    bs = None
    vt1_vslope_vo2 = np.nan
    vt2_vslope_vo2 = np.nan
    try:
        bs = broken_stick_fit2(
            vo2,
            vco2,
            min_span=BS_MIN_XSPAN,
            min_pts=BS_MIN_POINTS_PER_SIDE,
            q_lo=BS_Q_LO,
            q_hi=BS_Q_HI,
            pre_min=BS2_PRE_SLOPE_MIN,
            pre_max=BS2_PRE_SLOPE_MAX,
            mid_min=BS2_MID_SLOPE_MIN,
        )
        if isinstance(bs, dict):
            if np.isfinite(bs.get("t1", np.nan)):
                vt1_vslope_vo2 = float(bs["t1"])
            if np.isfinite(bs.get("t2", np.nan)):
                vt2_vslope_vo2 = float(bs["t2"])
    except Exception:
        pass

    vt1_vevo2_t = detect_min_time(t, ve_vo2_L, q_lo=0.05, q_hi=0.95)
    vt1_peto2_t = detect_min_time(t, peto2n_L, q_lo=0.05, q_hi=0.95)
    vt2_vevco2_t = detect_vevco2_steepest_rise_start_strict(
        t, ve_vco2_L, slope_window_pts=12, pos_slope_threshold=0.02, min_run=10
    )
    vt2_petco2_t = detect_vt2_petco2_steepest_run_start(
        t, petco2n_L, slope_window_pts=12, min_run=10, neg_slope_threshold=-0.03, min_cum_drop=0.0
    )

    segs = _vslope_default_segs(bs, vo2)

    return {
        "t": t,
        "vo2": vo2,
        "vco2": vco2,
        "ve": ve,
        "rer": rer,
        "peto2": peto2,
        "petco2": petco2,
        "ve_vo2": ve_vo2,
        "ve_vco2": ve_vco2,
        "peto2n": peto2n,
        "petco2n": petco2n,
        "vo2_L": vo2_L,
        "ve_vo2_L": ve_vo2_L,
        "ve_vco2_L": ve_vco2_L,
        "peto2n_L": peto2n_L,
        "petco2n_L": petco2n_L,
        "rer_L": rer_L,
        "vslope_bs": bs,
        "vslope_segments": segs,
        "vt_defaults": {
            "vslope_vo2": {"vt1": vt1_vslope_vo2, "vt2": vt2_vslope_vo2},
            "veeq_time": {"vt1": vt1_vevo2_t, "vt2": vt2_vevco2_t},
            "pet_time": {"vt1": vt1_peto2_t, "vt2": vt2_petco2_t},
        },
        "vo2_peak": float(np.nanmax(vo2_L)) if np.isfinite(vo2_L).any() else np.nan,
    }


def _to_nan(val):
    try:
        v = float(val)
    except Exception:
        return np.nan
    return v if math.isfinite(v) else np.nan


def compute_vt_context(analysis: dict, overrides: dict | None = None):
    overrides = overrides or {}

    vt_defaults = analysis.get("vt_defaults", {})
    vt_vslope = dict(vt_defaults.get("vslope_vo2", {}))
    vt_veeq = dict(vt_defaults.get("veeq_time", {}))
    vt_pet = dict(vt_defaults.get("pet_time", {}))

    vslope_override = overrides.get("vslope") or {}
    veeq_override = overrides.get("veeq") or {}
    pet_override = overrides.get("pet") or {}

    for key in ("vt1", "vt2"):
        if key in vslope_override:
            vt_vslope[key] = _to_nan(vslope_override[key])
        if key in veeq_override:
            vt_veeq[key] = _to_nan(veeq_override[key])
        if key in pet_override:
            vt_pet[key] = _to_nan(pet_override[key])

    segments = analysis.get("vslope_segments") or []
    seg_override = vslope_override.get("segments")
    if seg_override:
        segs = []
        for seg in seg_override:
            try:
                x0 = float(seg["x0"])
                y0 = float(seg["y0"])
                x1 = float(seg["x1"])
                y1 = float(seg["y1"])
            except Exception:
                continue
            if not (math.isfinite(x0) and math.isfinite(y0) and math.isfinite(x1) and math.isfinite(y1)):
                continue
            segs.append(((x0, y0), (x1, y1)))
        if segs:
            segments = segs

    t = np.asarray(analysis["t"], float)
    vo2_L = np.asarray(analysis["vo2_L"], float)
    rer_L = np.asarray(analysis["rer_L"], float)

    vt1_vevo2_vo2 = _interp_at_x(t, vo2_L, vt_veeq.get("vt1")) if np.isfinite(vt_veeq.get("vt1", np.nan)) else np.nan
    vt1_peto2_vo2 = _interp_at_x(t, vo2_L, vt_pet.get("vt1")) if np.isfinite(vt_pet.get("vt1", np.nan)) else np.nan
    vt2_vevco2_vo2 = _interp_at_x(t, vo2_L, vt_veeq.get("vt2")) if np.isfinite(vt_veeq.get("vt2", np.nan)) else np.nan
    vt2_petco2_vo2 = _interp_at_x(t, vo2_L, vt_pet.get("vt2")) if np.isfinite(vt_pet.get("vt2", np.nan)) else np.nan

    def _safe_mean(vals):
        arr = np.asarray([_to_nan(v) for v in vals], float)
        arr = arr[np.isfinite(arr)]
        return float(arr.mean()) if arr.size else np.nan

    avg_vt1_vo2 = _safe_mean([vt_vslope.get("vt1"), vt1_vevo2_vo2, vt1_peto2_vo2])
    avg_vt2_vo2 = _safe_mean([vt_vslope.get("vt2"), vt2_vevco2_vo2, vt2_petco2_vo2])

    vt1_t_avg = _invert_y_to_x(t, vo2_L, avg_vt1_vo2)
    vt2_t_avg = _invert_y_to_x(t, vo2_L, avg_vt2_vo2)

    vo2_peak = analysis.get("vo2_peak", np.nan)

    vt1_rows = {
        "V-Slope": _mk_row_from_vo2(vt_vslope.get("vt1"), t, vo2_L, rer_L, vo2_peak),
        "VE/VO₂ minimum": _mk_row_from_time(vt_veeq.get("vt1"), t, vo2_L, rer_L, vo2_peak),
        "PetO₂ minimum": _mk_row_from_time(vt_pet.get("vt1"), t, vo2_L, rer_L, vo2_peak),
    }
    _vt1_mean_vo2 = _safe_mean([row["vo2"] for row in vt1_rows.values() if row.get("vo2") is not None])
    vt1_rows["Average"] = _mk_row_from_vo2(_vt1_mean_vo2, t, vo2_L, rer_L, vo2_peak)

    vt2_rows = {
        "V-Slope": _mk_row_from_vo2(vt_vslope.get("vt2"), t, vo2_L, rer_L, vo2_peak),
        "VE/VCO₂ rise (start)": _mk_row_from_time(vt_veeq.get("vt2"), t, vo2_L, rer_L, vo2_peak),
        "PetCO₂ drop (start)": _mk_row_from_time(vt_pet.get("vt2"), t, vo2_L, rer_L, vo2_peak),
    }
    _vt2_mean_vo2 = _safe_mean([row["vo2"] for row in vt2_rows.values() if row.get("vo2") is not None])
    vt2_rows["Average"] = _mk_row_from_vo2(_vt2_mean_vo2, t, vo2_L, rer_L, vo2_peak)

    return {
        "vslope_segments": segments,
        "vslope_vo2": vt_vslope,
        "veeq_time": vt_veeq,
        "pet_time": vt_pet,
        "avg_vo2": {"vt1": avg_vt1_vo2, "vt2": avg_vt2_vo2},
        "avg_time": {"vt1": vt1_t_avg, "vt2": vt2_t_avg},
        "vt_table_data": {"vt1": vt1_rows, "vt2": vt2_rows},
    }


def build_figures_from_file(path: str, overrides: dict | None = None):
    analysis = compute_cpet_analysis(path)
    context = compute_vt_context(analysis, overrides)

    t = np.asarray(analysis["t"], float)
    vo2 = np.asarray(analysis["vo2"], float)
    vco2 = np.asarray(analysis["vco2"], float)
    vo2_L = np.asarray(analysis["vo2_L"], float)
    ve_vo2 = np.asarray(analysis["ve_vo2"], float)
    ve_vo2_L = np.asarray(analysis["ve_vo2_L"], float)
    ve_vco2 = np.asarray(analysis["ve_vco2"], float)
    ve_vco2_L = np.asarray(analysis["ve_vco2_L"], float)
    peto2n = np.asarray(analysis["peto2n"], float)
    peto2n_L = np.asarray(analysis["peto2n_L"], float)
    petco2n = np.asarray(analysis["petco2n"], float)
    petco2n_L = np.asarray(analysis["petco2n_L"], float)
    rer = np.asarray(analysis["rer"], float)
    rer_L = np.asarray(analysis["rer_L"], float)

    vt_vslope = context["vslope_vo2"]
    vt_veeq = context["veeq_time"]
    vt_pet = context["pet_time"]
    vt_avg_time = context["avg_time"]

    def layout(fig, xlab, ylab, h=420):
        fig.update_layout(
            margin=dict(l=12, r=12, t=8, b=12),
            height=h,
            xaxis_title=xlab,
            yaxis_title=ylab,
            showlegend=False,
        )
        fig.update_xaxes(
            title_font=dict(color="black"),
            gridcolor="black",
            zerolinecolor="black",
            linecolor="black",
            tickcolor="black",
        )
        fig.update_yaxes(
            title_font=dict(color="black"),
            gridcolor="black",
            zerolinecolor="black",
            linecolor="black",
            tickcolor="black",
        )
        return fig

    fig_vslope = go.Figure()
    fig_vslope.add_trace(
        go.Scatter(
            x=vo2,
            y=vco2,
            mode="markers",
            name="VCO₂–VO₂ points",
            marker=dict(size=6, opacity=0.75, color=COL_BLUE),
        )
    )

    segs = context["vslope_segments"]
    if segs:
        for i, ((x0, y0), (x1, y1)) in enumerate(segs):
            n = 60
            if abs(x1 - x0) < 1e-9:
                xp = np.array([x0] * n)
                yp = np.linspace(y0, y1, n)
            else:
                xp = np.linspace(x0, x1, n)
                yp = y0 + (y1 - y0) * (xp - x0) / (x1 - x0)

            fig_vslope.add_trace(
                go.Scatter(
                    x=xp,
                    y=yp,
                    mode="lines",
                    name="Slope lines",
                    legendgroup="slope",
                    line=dict(width=3, color=COL_GREEN),
                    hovertemplate="VO₂ %{x:.2f}<br>VCO₂ %{y:.2f}<extra></extra>",
                    showlegend=(i == 0),
                )
            )

    ymin, ymax = float(np.nanmin(vco2)), float(np.nanmax(vco2))
    vt1_vslope = vt_vslope.get("vt1", np.nan)
    vt2_vslope = vt_vslope.get("vt2", np.nan)
    if np.isfinite(vt1_vslope):
        fig_vslope.add_trace(
            go.Scatter(
                x=[vt1_vslope, vt1_vslope],
                y=[ymin, ymax],
                mode="lines",
                name="VT1",
                line=dict(dash="dot", color=COL_PURPLE),
            )
        )
    if np.isfinite(vt2_vslope):
        fig_vslope.add_trace(
            go.Scatter(
                x=[vt2_vslope, vt2_vslope],
                y=[ymin, ymax],
                mode="lines",
                name="VT2",
                line=dict(dash="dot", color=COL_RED),
            )
        )

    layout(fig_vslope, "VO₂ (L·min⁻¹)", "VCO₂ (L·min⁻¹)")

    fig_vo2 = go.Figure()
    fig_vo2.add_trace(
        go.Scatter(
            x=t,
            y=vo2,
            mode="markers",
            name="VO₂",
            legendgroup="points",
            marker=dict(size=6, opacity=0.75, color=COL_BLUE),
            showlegend=False,
        )
    )
    fig_vo2.add_trace(
        go.Scatter(
            x=t,
            y=vo2_L,
            mode="lines",
            name="VO₂ Trace",
            legendgroup="trace",
            line=dict(width=2, color=COL_BLUE_DARK),
            showlegend=False,
        )
    )

    ymin, ymax = float(np.nanmin([vo2, vo2_L])), float(np.nanmax([vo2, vo2_L]))
    vt1_t_avg = vt_avg_time.get("vt1", np.nan)
    vt2_t_avg = vt_avg_time.get("vt2", np.nan)
    if np.isfinite(vt1_t_avg):
        fig_vo2.add_trace(
            go.Scatter(
                x=[vt1_t_avg, vt1_t_avg],
                y=[ymin, ymax],
                mode="lines",
                name="VT1",
                line=dict(dash="dot", color=COL_PURPLE),
            )
        )
    if np.isfinite(vt2_t_avg):
        fig_vo2.add_trace(
            go.Scatter(
                x=[vt2_t_avg, vt2_t_avg],
                y=[ymin, ymax],
                mode="lines",
                name="VT2",
                line=dict(dash="dot", color=COL_RED),
            )
        )

    layout(fig_vo2, "Time (min)", "VO₂ (L·min⁻¹)")

    fig_veeq = go.Figure()
    fig_veeq.add_trace(
        go.Scatter(
            x=t,
            y=ve_vo2,
            mode="markers",
            name="VE/VO₂",
            legendgroup="vevo2_pts",
            marker=dict(size=6, opacity=0.75, color=COL_BLUE),
        )
    )
    fig_veeq.add_trace(
        go.Scatter(
            x=t,
            y=ve_vo2_L,
            mode="lines",
            name="VE/VO₂ Trace",
            legendgroup="vevo2_tr",
            line=dict(width=2, color=COL_BLUE_DARK),
            showlegend=False,
        )
    )
    fig_veeq.add_trace(
        go.Scatter(
            x=t,
            y=ve_vco2,
            mode="markers",
            name="VE/VCO₂",
            legendgroup="vevco2_pts",
            marker=dict(size=6, opacity=0.75, color=COL_ORANGE),
        )
    )
    fig_veeq.add_trace(
        go.Scatter(
            x=t,
            y=ve_vco2_L,
            mode="lines",
            name="VE/VCO₂ Trace",
            legendgroup="vevco2_tr",
            line=dict(width=2, color=COL_ORANGE_DARK),
            showlegend=False,
        )
    )

    ymin = float(np.nanmin([ve_vo2, ve_vco2, ve_vo2_L, ve_vco2_L]))
    ymax = float(np.nanmax([ve_vo2, ve_vco2, ve_vo2_L, ve_vco2_L]))
    vt1_vevo2_t = vt_veeq.get("vt1", np.nan)
    vt2_vevco2_t = vt_veeq.get("vt2", np.nan)
    if np.isfinite(vt1_vevo2_t):
        fig_veeq.add_trace(
            go.Scatter(
                x=[vt1_vevo2_t, vt1_vevo2_t],
                y=[ymin, ymax],
                mode="lines",
                name="VT1",
                legendgroup="vt1",
                line=dict(dash="dot", color=COL_PURPLE),
            )
        )
    if np.isfinite(vt2_vevco2_t):
        fig_veeq.add_trace(
            go.Scatter(
                x=[vt2_vevco2_t, vt2_vevco2_t],
                y=[ymin, ymax],
                mode="lines",
                name="VT2",
                legendgroup="vt2",
                line=dict(dash="dot", color=COL_RED),
            )
        )

    layout(fig_veeq, "Time (min)", "Ratio")

    fig_pet = go.Figure()
    fig_pet.add_trace(
        go.Scatter(
            x=t,
            y=peto2n,
            mode="markers",
            name="PetO₂",
            legendgroup="peto2_pts",
            marker=dict(size=6, opacity=0.75, color=COL_BLUE),
            showlegend=False,
        )
    )
    fig_pet.add_trace(
        go.Scatter(
            x=t,
            y=peto2n_L,
            mode="lines",
            name="PetO₂ Trace",
            legendgroup="peto2_tr",
            line=dict(width=2, color=COL_BLUE_DARK),
            showlegend=False,
        )
    )
    fig_pet.add_trace(
        go.Scatter(
            x=t,
            y=petco2n,
            mode="markers",
            name="PetCO₂",
            legendgroup="petco2_pts",
            marker=dict(size=6, opacity=0.75, color=COL_ORANGE),
            showlegend=False,
        )
    )
    fig_pet.add_trace(
        go.Scatter(
            x=t,
            y=petco2n_L,
            mode="lines",
            name="PetCO₂ Trace",
            legendgroup="petco2_tr",
            line=dict(width=2, color=COL_ORANGE_DARK),
            showlegend=False,
        )
    )

    ymin = float(np.nanmin([peto2n, petco2n, peto2n_L, petco2n_L]))
    ymax = float(np.nanmax([peto2n, petco2n, peto2n_L, petco2n_L]))
    vt1_peto2_t = vt_pet.get("vt1", np.nan)
    vt2_petco2_t = vt_pet.get("vt2", np.nan)
    if np.isfinite(vt1_peto2_t):
        fig_pet.add_trace(
            go.Scatter(
                x=[vt1_peto2_t, vt1_peto2_t],
                y=[ymin, ymax],
                mode="lines",
                name="VT1",
                legendgroup="vt1",
                line=dict(dash="dot", color=COL_PURPLE),
            )
        )
    if np.isfinite(vt2_petco2_t):
        fig_pet.add_trace(
            go.Scatter(
                x=[vt2_petco2_t, vt2_petco2_t],
                y=[ymin, ymax],
                mode="lines",
                name="VT2",
                legendgroup="vt2",
                line=dict(dash="dot", color=COL_RED),
            )
        )

    layout(fig_pet, "Time (min)", "Normalized (÷ series mean)")

    fig_rer = go.Figure()
    fig_rer.add_trace(
        go.Scatter(
            x=t,
            y=rer,
            mode="markers",
            name="RER",
            legendgroup="rer_pts",
            marker=dict(size=6, opacity=0.75, color=COL_BLUE),
            showlegend=False,
        )
    )
    fig_rer.add_trace(
        go.Scatter(
            x=t,
            y=rer_L,
            mode="lines",
            name="RER Trace",
            legendgroup="rer_tr",
            line=dict(width=2, color=COL_BLUE_DARK),
            showlegend=False,
        )
    )

    ymin = float(np.nanmin([rer, rer_L]))
    ymax = float(np.nanmax([rer, rer_L]))
    if np.isfinite(vt1_t_avg):
        fig_rer.add_trace(
            go.Scatter(
                x=[vt1_t_avg, vt1_t_avg],
                y=[ymin, ymax],
                mode="lines",
                name="VT1",
                legendgroup="vt1",
                line=dict(dash="dot", width=2, color=COL_PURPLE),
            )
        )
    if np.isfinite(vt2_t_avg):
        fig_rer.add_trace(
            go.Scatter(
                x=[vt2_t_avg, vt2_t_avg],
                y=[ymin, ymax],
                mode="lines",
                name="VT2",
                legendgroup="vt2",
                line=dict(dash="dot", width=2, color=COL_RED),
            )
        )

    layout(fig_rer, "Time (min)", "RER")

    return (
        {
            "vslope": fig_vslope,
            "vo2": fig_vo2,
            "veeq": fig_veeq,
            "pet": fig_pet,
            "rer": fig_rer,
        },
        context["vt_table_data"],
    )


def _to_store_float(val):
    try:
        v = float(val)
    except Exception:
        return None
    return v if math.isfinite(v) else None


def _from_store_float(val):
    if val is None:
        return np.nan
    try:
        v = float(val)
    except Exception:
        return np.nan
    return v if math.isfinite(v) else np.nan


def _arr_to_list(arr):
    arr = np.asarray(arr, float)
    return [float(v) if np.isfinite(v) else None for v in arr]


def _list_to_array(lst):
    if lst is None:
        return np.array([], dtype=float)
    out = []
    for v in lst:
        if v is None:
            out.append(np.nan)
        else:
            try:
                f = float(v)
            except Exception:
                f = np.nan
            out.append(f if math.isfinite(f) else np.nan)
    return np.array(out, dtype=float)


def _segments_to_payload(segs):
    payload = []
    if not segs:
        return payload
    for (x0, y0), (x1, y1) in segs:
        payload.append({
            "x0": _to_store_float(x0),
            "y0": _to_store_float(y0),
            "x1": _to_store_float(x1),
            "y1": _to_store_float(y1),
        })
    return payload


def _segments_from_payload(payload):
    segs = []
    for item in payload or []:
        x0 = _from_store_float(item.get("x0"))
        y0 = _from_store_float(item.get("y0"))
        x1 = _from_store_float(item.get("x1"))
        y1 = _from_store_float(item.get("y1"))
        if all(np.isfinite(v) for v in (x0, y0, x1, y1)):
            segs.append(((float(x0), float(y0)), (float(x1), float(y1))))
    return segs


def analysis_to_store_payload(analysis: dict):
    vt_defaults = analysis.get("vt_defaults", {})

    def _convert_vt(d):
        return {k: _to_store_float(v) for k, v in (d or {}).items()}

    return {
        "t": _arr_to_list(analysis["t"]),
        "vo2": _arr_to_list(analysis["vo2"]),
        "vco2": _arr_to_list(analysis["vco2"]),
        "ve": _arr_to_list(analysis["ve"]),
        "rer": _arr_to_list(analysis["rer"]),
        "peto2": _arr_to_list(analysis["peto2"]),
        "petco2": _arr_to_list(analysis["petco2"]),
        "ve_vo2": _arr_to_list(analysis["ve_vo2"]),
        "ve_vco2": _arr_to_list(analysis["ve_vco2"]),
        "peto2n": _arr_to_list(analysis["peto2n"]),
        "petco2n": _arr_to_list(analysis["petco2n"]),
        "vo2_L": _arr_to_list(analysis["vo2_L"]),
        "ve_vo2_L": _arr_to_list(analysis["ve_vo2_L"]),
        "ve_vco2_L": _arr_to_list(analysis["ve_vco2_L"]),
        "peto2n_L": _arr_to_list(analysis["peto2n_L"]),
        "petco2n_L": _arr_to_list(analysis["petco2n_L"]),
        "rer_L": _arr_to_list(analysis["rer_L"]),
        "vt_defaults": {
            "vslope_vo2": _convert_vt(vt_defaults.get("vslope_vo2")),
            "veeq_time": _convert_vt(vt_defaults.get("veeq_time")),
            "pet_time": _convert_vt(vt_defaults.get("pet_time")),
        },
        "vslope_segments": _segments_to_payload(analysis.get("vslope_segments")),
        "vo2_peak": _to_store_float(analysis.get("vo2_peak")),
    }


def analysis_from_store(payload: dict):
    vt_defaults = payload.get("vt_defaults", {})

    def _convert(d):
        return {k: _from_store_float(v) for k, v in (d or {}).items()}

    return {
        "t": _list_to_array(payload.get("t")),
        "vo2": _list_to_array(payload.get("vo2")),
        "vco2": _list_to_array(payload.get("vco2")),
        "ve": _list_to_array(payload.get("ve")),
        "rer": _list_to_array(payload.get("rer")),
        "peto2": _list_to_array(payload.get("peto2")),
        "petco2": _list_to_array(payload.get("petco2")),
        "ve_vo2": _list_to_array(payload.get("ve_vo2")),
        "ve_vco2": _list_to_array(payload.get("ve_vco2")),
        "peto2n": _list_to_array(payload.get("peto2n")),
        "petco2n": _list_to_array(payload.get("petco2n")),
        "vo2_L": _list_to_array(payload.get("vo2_L")),
        "ve_vo2_L": _list_to_array(payload.get("ve_vo2_L")),
        "ve_vco2_L": _list_to_array(payload.get("ve_vco2_L")),
        "peto2n_L": _list_to_array(payload.get("peto2n_L")),
        "petco2n_L": _list_to_array(payload.get("petco2n_L")),
        "rer_L": _list_to_array(payload.get("rer_L")),
        "vt_defaults": {
            "vslope_vo2": _convert(vt_defaults.get("vslope_vo2")),
            "veeq_time": _convert(vt_defaults.get("veeq_time")),
            "pet_time": _convert(vt_defaults.get("pet_time")),
        },
        "vslope_segments": _segments_from_payload(payload.get("vslope_segments")),
        "vo2_peak": _from_store_float(payload.get("vo2_peak")),
    }


def _init_edit_state(row_id: int, analysis: dict, context: dict):
    analysis_payload = analysis_to_store_payload(analysis)

    graphs = {
        "vslope": {
            "current": {
                "segments": _segments_to_payload(context.get("vslope_segments")),
                "vt1": _to_store_float(context.get("vslope_vo2", {}).get("vt1")),
                "vt2": _to_store_float(context.get("vslope_vo2", {}).get("vt2")),
            },
        },
        "veeq": {
            "current": {
                "vt1": _to_store_float(context.get("veeq_time", {}).get("vt1")),
                "vt2": _to_store_float(context.get("veeq_time", {}).get("vt2")),
            },
        },
        "pet": {
            "current": {
                "vt1": _to_store_float(context.get("pet_time", {}).get("vt1")),
                "vt2": _to_store_float(context.get("pet_time", {}).get("vt2")),
            },
        },
    }

    for g in graphs.values():
        g["saved"] = copy.deepcopy(g["current"])
        g["undo"] = []
        g["redo"] = []
        g["meta"] = {}

    return {
        "row_id": row_id,
        "analysis": analysis_payload,
        "graphs": graphs,
        "active": "vslope",
    }


def _graph_states_equal(a: dict, b: dict, tol: float = 1e-6) -> bool:
    def _eq(v1, v2):
        if v1 is None and v2 is None:
            return True
        if v1 is None or v2 is None:
            return False
        try:
            return abs(float(v1) - float(v2)) <= tol
        except Exception:
            return False

    seg_a = a.get("segments") or []
    seg_b = b.get("segments") or []
    if len(seg_a) != len(seg_b):
        return False
    for sa, sb in zip(seg_a, seg_b):
        for key in ("x0", "y0", "x1", "y1"):
            if not _eq(sa.get(key), sb.get(key)):
                return False

    return _eq(a.get("vt1"), b.get("vt1")) and _eq(a.get("vt2"), b.get("vt2"))


def _graphs_to_overrides(graphs: dict, use_saved: bool = False):
    out = {}
    source_key = "saved" if use_saved else "current"

    vs = graphs.get("vslope", {}).get(source_key, {})
    ve = graphs.get("veeq", {}).get(source_key, {})
    pt = graphs.get("pet", {}).get(source_key, {})

    vs_override = {}
    if vs.get("segments"):
        vs_override["segments"] = vs.get("segments")
    if vs.get("vt1") is not None:
        vs_override["vt1"] = vs.get("vt1")
    if vs.get("vt2") is not None:
        vs_override["vt2"] = vs.get("vt2")
    if vs_override:
        out["vslope"] = vs_override

    ve_override = {}
    if ve.get("vt1") is not None:
        ve_override["vt1"] = ve.get("vt1")
    if ve.get("vt2") is not None:
        ve_override["vt2"] = ve.get("vt2")
    if ve_override:
        out["veeq"] = ve_override

    pet_override = {}
    if pt.get("vt1") is not None:
        pet_override["vt1"] = pt.get("vt1")
    if pt.get("vt2") is not None:
        pet_override["vt2"] = pt.get("vt2")
    if pet_override:
        out["pet"] = pet_override

    return out


def _build_edit_figure(graph_key: str, analysis_payload: dict, graph_state: dict):
    analysis = analysis_from_store(analysis_payload)
    fig = go.Figure()
    meta = {"segments": [], "vt1": None, "vt2": None}

    if graph_key == "vslope":
        vo2 = analysis["vo2"]
        vco2 = analysis["vco2"]
        fig.add_trace(go.Scatter(x=vo2, y=vco2, mode="markers", marker=dict(size=6, opacity=0.75, color=COL_BLUE)))

        shapes = []
        segments = _segments_from_payload(graph_state.get("current", {}).get("segments"))
        for idx, ((x0, y0), (x1, y1)) in enumerate(segments):
            shapes.append(dict(type="line", x0=x0, y0=y0, x1=x1, y1=y1, line=dict(color=COL_GREEN, width=3)))
            meta["segments"].append(idx)

        ymin = float(np.nanmin(vco2)) if vco2.size else 0.0
        ymax = float(np.nanmax(vco2)) if vco2.size else 1.0
        vt1 = graph_state.get("current", {}).get("vt1")
        vt2 = graph_state.get("current", {}).get("vt2")
        base = len(shapes)
        if vt1 is not None:
            x = float(vt1)
            shapes.append(dict(type="line", x0=x, x1=x, y0=ymin, y1=ymax, line=dict(color=COL_PURPLE, dash="dot", width=2)))
            meta["vt1"] = base
            base += 1
        if vt2 is not None:
            x = float(vt2)
            shapes.append(dict(type="line", x0=x, x1=x, y0=ymin, y1=ymax, line=dict(color=COL_RED, dash="dot", width=2)))
            meta["vt2"] = base

        fig.update_layout(shapes=shapes)
        fig.update_xaxes(title="VO₂ (L·min⁻¹)")
        fig.update_yaxes(title="VCO₂ (L·min⁻¹)")

    elif graph_key == "veeq":
        t = analysis["t"]
        ve_vo2 = analysis["ve_vo2"]
        ve_vco2 = analysis["ve_vco2"]
        ve_vo2_L = analysis["ve_vo2_L"]
        ve_vco2_L = analysis["ve_vco2_L"]

        fig.add_trace(go.Scatter(x=t, y=ve_vo2, mode="markers", marker=dict(size=6, opacity=0.75, color=COL_BLUE)))
        fig.add_trace(go.Scatter(x=t, y=ve_vo2_L, mode="lines", line=dict(color=COL_BLUE_DARK, width=2)))
        fig.add_trace(go.Scatter(x=t, y=ve_vco2, mode="markers", marker=dict(size=6, opacity=0.75, color=COL_ORANGE)))
        fig.add_trace(go.Scatter(x=t, y=ve_vco2_L, mode="lines", line=dict(color=COL_ORANGE_DARK, width=2)))

        ymin = float(np.nanmin([ve_vo2, ve_vco2, ve_vo2_L, ve_vco2_L]))
        ymax = float(np.nanmax([ve_vo2, ve_vco2, ve_vo2_L, ve_vco2_L]))
        shapes = []
        vt1 = graph_state.get("current", {}).get("vt1")
        vt2 = graph_state.get("current", {}).get("vt2")
        idx = 0
        if vt1 is not None:
            x = float(vt1)
            shapes.append(dict(type="line", x0=x, x1=x, y0=ymin, y1=ymax, line=dict(color=COL_PURPLE, dash="dot", width=2)))
            meta["vt1"] = idx
            idx += 1
        if vt2 is not None:
            x = float(vt2)
            shapes.append(dict(type="line", x0=x, x1=x, y0=ymin, y1=ymax, line=dict(color=COL_RED, dash="dot", width=2)))
            meta["vt2"] = idx

        fig.update_layout(shapes=shapes)
        fig.update_xaxes(title="Time (min)")
        fig.update_yaxes(title="Ratio")

    elif graph_key == "pet":
        t = analysis["t"]
        peto2n = analysis["peto2n"]
        petco2n = analysis["petco2n"]
        peto2n_L = analysis["peto2n_L"]
        petco2n_L = analysis["petco2n_L"]

        fig.add_trace(go.Scatter(x=t, y=peto2n, mode="markers", marker=dict(size=6, opacity=0.75, color=COL_BLUE)))
        fig.add_trace(go.Scatter(x=t, y=peto2n_L, mode="lines", line=dict(color=COL_BLUE_DARK, width=2)))
        fig.add_trace(go.Scatter(x=t, y=petco2n, mode="markers", marker=dict(size=6, opacity=0.75, color=COL_ORANGE)))
        fig.add_trace(go.Scatter(x=t, y=petco2n_L, mode="lines", line=dict(color=COL_ORANGE_DARK, width=2)))

        ymin = float(np.nanmin([peto2n, petco2n, peto2n_L, petco2n_L]))
        ymax = float(np.nanmax([peto2n, petco2n, peto2n_L, petco2n_L]))
        shapes = []
        vt1 = graph_state.get("current", {}).get("vt1")
        vt2 = graph_state.get("current", {}).get("vt2")
        idx = 0
        if vt1 is not None:
            x = float(vt1)
            shapes.append(dict(type="line", x0=x, x1=x, y0=ymin, y1=ymax, line=dict(color=COL_PURPLE, dash="dot", width=2)))
            meta["vt1"] = idx
            idx += 1
        if vt2 is not None:
            x = float(vt2)
            shapes.append(dict(type="line", x0=x, x1=x, y0=ymin, y1=ymax, line=dict(color=COL_RED, dash="dot", width=2)))
            meta["vt2"] = idx

        fig.update_layout(shapes=shapes)
        fig.update_xaxes(title="Time (min)")
        fig.update_yaxes(title="Normalized (÷ series mean)")

    fig.update_layout(
        margin=dict(l=12, r=12, t=8, b=12),
        dragmode="pan",
        uirevision=f"vt-edit-{graph_key}",
    )

    return fig, meta


EDIT_GRAPH_ORDER = ["vslope", "veeq", "pet"]
EDIT_GRAPH_LABELS = {
    "vslope": "V-Slope",
    "veeq": "VE/VO₂ & VE/VCO₂",
    "pet": "PetO₂ & PetCO₂",
}
EDIT_HIGHLIGHT = {
    "vslope": {"vt1": ["V-Slope"], "vt2": ["V-Slope"]},
    "veeq": {"vt1": ["VE/VO₂ minimum"], "vt2": ["VE/VCO₂ rise (start)"]},
    "pet": {"vt1": ["PetO₂ minimum"], "vt2": ["PetCO₂ drop (start)"]},
}


def _apply_relayout(state: dict, graph_key: str, relayout: dict):
    if not relayout or not state or "graphs" not in state:
        return state, False
    graph = state["graphs"].get(graph_key)
    if not graph:
        return state, False

    meta = graph.get("meta") or {}
    updates = {}
    for key, val in relayout.items():
        m = re.match(r"shapes\[(\d+)\]\.(x0|x1|y0|y1)", str(key))
        if not m:
            continue
        idx = int(m.group(1))
        attr = m.group(2)
        updates.setdefault(idx, {})[attr] = val

    if not updates:
        return state, False

    original_current = copy.deepcopy(graph.get("current", {}))
    new_state = copy.deepcopy(state)
    g = new_state["graphs"][graph_key]
    current = copy.deepcopy(g.get("current", {}))
    segments = list(current.get("segments") or [])
    changed = False

    for idx, vals in updates.items():
        if idx in (meta.get("segments") or []):
            try:
                pos = meta["segments"].index(idx)
            except ValueError:
                continue
            if pos >= len(segments):
                continue
            seg = dict(segments[pos])
            if "x0" in vals:
                seg["x0"] = _to_store_float(vals["x0"])
            if "y0" in vals:
                seg["y0"] = _to_store_float(vals["y0"])
            if "x1" in vals:
                seg["x1"] = _to_store_float(vals["x1"])
            if "y1" in vals:
                seg["y1"] = _to_store_float(vals["y1"])
            segments[pos] = seg
            changed = True
        elif idx == meta.get("vt1"):
            x = vals.get("x0", vals.get("x1"))
            if x is not None:
                current["vt1"] = _to_store_float(x)
                changed = True
        elif idx == meta.get("vt2"):
            x = vals.get("x0", vals.get("x1"))
            if x is not None:
                current["vt2"] = _to_store_float(x)
                changed = True

    if not changed:
        return state, False

    current["segments"] = segments
    g["undo"].append(original_current)
    g["redo"] = []
    g["current"] = current
    return new_state, True


def _perform_undo(state: dict, graph_key: str):
    graph = (state or {}).get("graphs", {}).get(graph_key)
    if not graph or not graph.get("undo"):
        return state, False
    new_state = copy.deepcopy(state)
    g = new_state["graphs"][graph_key]
    prev = g["undo"].pop()
    g.setdefault("redo", []).append(copy.deepcopy(g.get("current", {})))
    g["current"] = prev
    return new_state, True


def _perform_redo(state: dict, graph_key: str):
    graph = (state or {}).get("graphs", {}).get(graph_key)
    if not graph or not graph.get("redo"):
        return state, False
    new_state = copy.deepcopy(state)
    g = new_state["graphs"][graph_key]
    nxt = g["redo"].pop()
    g.setdefault("undo", []).append(copy.deepcopy(g.get("current", {})))
    g["current"] = nxt
    return new_state, True

# ---- BEGIN: CPET_Directory (renamed) ----
# CPETDirectory_webview.py
# Directory start-screen with robust CPET Excel importer (.xls/.xlsx/.csv)
# Dash (v3) + dash-mantine-components (v2) + SQLite + pywebview
# Changes in this version:
# - Remove "Critical Power" from edit modal
# - Add "Study" (new column, editable, searchable, sortable, persisted)
# - Improve table alignment (tabular numbers, right/center alignment, min widths)

import base64, io, re, sqlite3, threading, time, socket, sys
from pathlib import Path
from datetime import datetime

import dash
from dash import html, dcc, Input, Output, State, ctx, ALL
import dash_mantine_components as dmc

# -------------------- Persistence --------------------
APP_DIR = Path(__file__).parent
DB_PATH = APP_DIR / "cpet_dir.db"

SORT_FIELDS = {
    "test_date": "Test Date",
    "created_at": "Date Added",
    "subject_id": "Subject ID",
    "name": "Name",
    "study": "Study",
    "modality": "Modality",
}

def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("""
      CREATE TABLE IF NOT EXISTS participants (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        subject_id TEXT,
        name TEXT,
        study TEXT,
        sex TEXT,
        age INTEGER,
        height_cm REAL,
        mass_kg REAL,
        test_date TEXT,
        modality TEXT,
        rer_max REAL,
        hr_peak INTEGER,
        hr_pct_max REAL,
        critical_power REAL,
        file_name TEXT,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
      )
    """)
    # Backfill columns for older DBs
    def ensure_column(col_name, col_type):
        c.execute("PRAGMA table_info(participants)")
        cols = {row[1] for row in c.fetchall()}
        if col_name not in cols:
            c.execute(f"ALTER TABLE participants ADD COLUMN {col_name} {col_type}")
    ensure_column("study", "TEXT")
    ensure_column("file_path", "TEXT")
    c.execute(
        """
        CREATE TABLE IF NOT EXISTS vt_overrides (
            participant_id INTEGER PRIMARY KEY,
            data TEXT,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
        """
    )
    conn.commit()
    conn.close()

def row_to_dict(row):
    cols = [
        "id","subject_id","name","study","sex","age","height_cm","mass_kg",
        "test_date","modality","rer_max","hr_peak","hr_pct_max","critical_power",
        "file_name","file_path","created_at","updated_at"
    ]
    return {k:v for k,v in zip(cols, row)}

def list_participants(search="", sort_by="test_date", sort_dir="desc"):
    sort_col = sort_by if sort_by in SORT_FIELDS else "test_date"
    direction = "DESC" if sort_dir == "desc" else "ASC"
    like = f"%{(search or '').strip()}%"
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute(f"""
      SELECT id,subject_id,name,study,sex,age,height_cm,mass_kg,test_date,modality,
             rer_max,hr_peak,hr_pct_max,critical_power,file_name,file_path,created_at,updated_at
      FROM participants
      WHERE subject_id LIKE ? OR name LIKE ? OR modality LIKE ? OR IFNULL(study,'') LIKE ?
      ORDER BY {sort_col} {direction}, id DESC
    """, (like, like, like, like))
    rows = c.fetchall(); conn.close()
    return [row_to_dict(r) for r in rows]

def get_participant(pid:int):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("""SELECT id,subject_id,name,study,sex,age,height_cm,mass_kg,test_date,modality,
                rer_max,hr_peak,hr_pct_max,critical_power,file_name,file_path,created_at,updated_at
                FROM participants WHERE id=?""", (pid,))
    row = c.fetchone(); conn.close()
    return row_to_dict(row) if row else None

def insert_participant(data:dict):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("""
      INSERT INTO participants (subject_id,name,study,sex,age,height_cm,mass_kg,test_date,modality,
                                rer_max,hr_peak,hr_pct_max,critical_power,file_name,file_path,
                                created_at,updated_at)
      VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,datetime('now'),datetime('now'))
    """, (
        data.get("subject_id"), data.get("name"), data.get("study"),
        data.get("sex"), data.get("age"), data.get("height_cm"),
        data.get("mass_kg"), data.get("test_date"), data.get("modality"),
        data.get("rer_max"), data.get("hr_peak"), data.get("hr_pct_max"),
        data.get("critical_power"), data.get("file_name"), data.get("file_path")
    ))
    conn.commit(); conn.close()

def update_participant(pid:int, data:dict):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("""
    UPDATE participants SET
        subject_id=?, name=?, study=?, sex=?, age=?, height_cm=?, mass_kg=?, test_date=?, modality=?,
        rer_max=?, hr_peak=?, hr_pct_max=?, critical_power=?, file_name=?, file_path=?, updated_at=datetime('now')
    WHERE id=?
    """, (
        data.get("subject_id"), data.get("name"), data.get("study"), data.get("sex"),
        data.get("age"), data.get("height_cm"), data.get("mass_kg"),
        data.get("test_date"), data.get("modality"), data.get("rer_max"),
        data.get("hr_peak"), data.get("hr_pct_max"), data.get("critical_power"),
        data.get("file_name"), data.get("file_path"), pid
    ))
    conn.commit(); conn.close()

def delete_participant(pid:int):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("DELETE FROM participants WHERE id=?", (pid,))
    c.execute("DELETE FROM vt_overrides WHERE participant_id=?", (pid,))
    conn.commit(); conn.close()

def get_vt_overrides(pid: int):
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute("SELECT data FROM vt_overrides WHERE participant_id=?", (pid,))
    row = c.fetchone()
    conn.close()
    if not row or not row[0]:
        return {}
    try:
        return json.loads(row[0])
    except Exception:
        return {}

def save_vt_overrides(pid: int, data: dict):
    payload = json.dumps(data or {})
    conn = sqlite3.connect(DB_PATH); c = conn.cursor()
    c.execute(
        """
        INSERT INTO vt_overrides (participant_id, data, updated_at)
        VALUES (?, ?, datetime('now'))
        ON CONFLICT(participant_id) DO UPDATE SET
            data=excluded.data,
            updated_at=datetime('now')
        """,
        (pid, payload),
    )
    conn.commit(); conn.close()

# -------------------- Utils & Importer --------------------
def fmt_date(s):
    if not s: return "—"
    try: return datetime.fromisoformat(s).strftime("%Y-%m-%d")
    except Exception: return s

# The importer below is the same robust version you already have
# (xlrd fallback + B3/D3/F3 date + no Max VO2/VE-VCO2 slope).
# Only addition: set default study="" so it’s persisted.
def parse_excel_or_csv(contents: str, filename: str):
    warnings, error = [], None
    data = {
        "file_name": filename or "",
        "subject_id": "", "name": "", "study": "", "sex": "",
        "age": None, "height_cm": None, "mass_kg": None,
        "test_date": "", "modality": "",
        "rer_max": None, "hr_peak": None, "hr_pct_max": None,
        "critical_power": None
    }

    if not contents:
        return data, warnings, "No file content received."

    try:
        header, b64 = contents.split(",", 1)
        raw_bytes = base64.b64decode(b64)
        # Save raw upload so we can render graphs later
        uploads_dir = Path.home() / "OneDrive - University of Iowa" / "VO2 Max App Project" / "CPET_Uploads"
        uploads_dir.mkdir(parents=True, exist_ok=True)
        safe_name = re.sub(r"[^A-Za-z0-9._-]+", "_", filename or "file")
        stamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        saved_path = uploads_dir / f"{stamp}__{safe_name}"
        with open(saved_path, "wb") as f:
            f.write(raw_bytes)

        data["file_path"] = str(saved_path)
        buf = io.BytesIO(raw_bytes)
    except Exception as e:
        return data, warnings, f"Failed to decode upload: {e}"

    lower = (filename or "").lower()
    try_order = []
    if lower.endswith(".xls"):
        try_order = [("excel", {"engine": "xlrd"}), ("excel", {"engine": None})]
    elif lower.endswith(".xlsx"):
        try_order = [("excel", {"engine": "openpyxl"}), ("excel", {"engine": None})]
    else:
        try_order = [("csv", {})]

    import pandas as pd
    dfs, read_errors = [], []

    def add_frames_from_excel(excel_buffer, engine):
        try:
            xls = pd.ExcelFile(excel_buffer, engine=engine)
            for sheet in xls.sheet_names:
                try:
                    df = xls.parse(sheet)
                    if not df.empty:
                        dfs.append((sheet, df))
                except Exception as e:
                    read_errors.append(f"Pandas parse sheet '{sheet}' failed: {e}")
            return len(dfs) > 0
        except Exception as e:
            read_errors.append(f"Pandas ExcelFile(engine={engine}) failed: {e}")
            return False

    read_ok = False
    for kind, kwargs in try_order:
        try:
            buf.seek(0)
            if kind == "csv":
                df = pd.read_csv(buf)
                if not df.empty:
                    dfs.append(("CSV", df))
                    read_ok = True
                    break
            else:
                if add_frames_from_excel(buf, kwargs.get("engine")):
                    read_ok = True
                    break
        except Exception as e:
            read_errors.append(f"Pandas top-level read ({kind}) failed: {e}")

    if not read_ok and lower.endswith(".xls"):
        try:
            import xlrd
            wb = xlrd.open_workbook(file_contents=raw_bytes)
            for s in wb.sheets():
                rows = [s.row_values(r) for r in range(s.nrows)]
                if rows:
                    maxc = max(len(r) for r in rows)
                    rows = [r + [None]*(maxc - len(r)) for r in rows]
                    df = pd.DataFrame(rows)
                    dfs.append((s.name, df))
            if dfs:
                read_ok = True
        except Exception as e:
            read_errors.append(f"xlrd direct open failed: {e}")

    if not read_ok:
        msg = "Unable to read .XLS." if lower.endswith(".xls") else "Unable to read file."
        if read_errors:
            msg += " Details: " + " | ".join(read_errors[-3:])
        return data, warnings, msg

    def _to_float(x):
        try: return float(str(x).strip())
        except: return None

    def _height_to_cm(x):
        v = _to_float(x)
        if v is None: return None
        if 48 <= v <= 90: return round(v * 2.54, 1)
        if v < 3:         return round(v * 100, 1)
        return round(v, 1)

    def _mass_to_kg(x):
        v = _to_float(x)
        if v is None: return None
        return round(v / 2.20462, 1) if v > 140 else round(v, 1)

    # Try header-based scan (skip if first column not str — likely grid)
    FIELD_PATTERNS = {
        "subject_id":   [r"^subjectid$", r"^id$", r"^subjectcode$", r"^participantid$", r"^subject$"],
        "name":         [r"^name$", r"^subjectname$", r"^participant$", r"^patientname$"],
        "sex":          [r"^sex$", r"^gender$"],
        "age":          [r"^age(yrs|years)?$", r"^age$"],
        "height_cm":    [r"^height(cm)?$", r"^stature$", r"^height$"],
        "mass_kg":      [r"^mass(kg)?$", r"^weight(kg)?$", r"^weight$", r"^bodymass$"],
        "test_date":    [r"^testdate$", r"^date$", r"^testtime$", r"^collectiondate$"],
        "modality":     [r"^modality$", r"^device$", r"^mode$", r"^protocol$", r"^exercisedevice$"],
        "rer_max":      [r"^rermax$", r"^rerpeak$", r"^rer$"],
        "hr_peak":      [r"^hrmax$", r"^hrpeak$", r"^maxhr$", r"^peakhr$"],
        "hr_pct_max":   [r"^hrpctmax$", r"^percenthrmax$", r"^hrpercent$", r"^%hrmax$"],
        "critical_power":[r"^criticalpower$", r"^cp$"],
    }
    found = {k: False for k in data.keys() if k not in ("file_name","study")}

    for sheet, df in dfs:
        if not isinstance(df.columns[0], str):
            continue
        cols = list(df.columns)
        norm_cols = [re.sub(r"[^a-z0-9]", "", str(c).strip().lower()) for c in cols]
        col_map = dict(zip(norm_cols, cols))

        def take(field_key, cast):
            if found[field_key]:
                return
            pats = FIELD_PATTERNS.get(field_key, [])
            for nc in norm_cols:
                if any(re.match(p, nc) for p in pats):
                    series = df[col_map[nc]].dropna()
                    if series.empty:
                        continue
                    raw = series.iloc[0]
                    try:
                        if cast == str:   val = str(raw).strip()
                        elif cast == int: val = int(float(str(raw).strip()))
                        elif cast == float: val = float(str(raw).strip())
                        else:             val = raw
                    except Exception:
                        val = str(raw).strip()
                    data[field_key] = val
                    found[field_key] = True
                    return

        take("subject_id", str)
        take("name", str)
        take("sex", str)
        take("age", int)
        take("height_cm", float)
        take("mass_kg", float)
        take("test_date", str)
        take("modality", str)
        take("rer_max", float)
        take("hr_peak", int)
        take("hr_pct_max", float)
        take("critical_power", float)

    # Form-style + B3/D3/F3 date
    grid = dfs[0][1] if dfs else None
    def pairmap(g):
        pairs = {}
        if g is None or g.empty: return pairs
        R, C = g.shape
        for r in range(R):
            k = g.iat[r,0] if C>0 else None
            v = g.iat[r,1] if C>1 else None
            if isinstance(k, str) and str(k).strip() and (v is not None and str(v).strip() != ""):
                pairs[str(k).strip()] = v
        return pairs

    pairs = pairmap(grid)

    if not data["name"]:
        data["name"] = str(pairs.get("Name","")).strip()

    if not data["subject_id"]:
        m = re.search(r"([A-Za-z0-9]+_[A-Za-z0-9]+)", data["name"])
        if m:
            data["subject_id"] = m.group(1)

    if not data["sex"] and grid is not None:
        R, C = grid.shape
        for r in range(R):
            for c in range(C-1):
                v = grid.iat[r,c]
                if isinstance(v, str) and re.search(r"\b(sex|gender)\b", v, re.I):
                    right = grid.iat[r,c+1]
                    if right is not None and str(right).strip() != "":
                        data["sex"] = str(right).strip()
                        break

    if data["age"] in (None, ""):
        age = pairs.get("Age", None)
        try: data["age"] = int(float(age)) if age not in (None,"") else None
        except: pass

    if data["height_cm"] in (None, ""):
        hc = pairs.get("Height", None)
        data["height_cm"] = _height_to_cm(hc) if hc not in (None,"") else None

    if data["mass_kg"] in (None, "") and grid is not None:
        R, C = grid.shape
        for r in range(R):
            for c in range(C-1):
                v = grid.iat[r,c]
                if isinstance(v, str) and re.search(r"\b(weight|mass)\b", v, re.I):
                    right = grid.iat[r,c+1]
                    if right is not None and str(right).strip() != "":
                        data["mass_kg"] = _mass_to_kg(right)
                        break

    if not data["modality"]:
        mod = pairs.get("Exercise Device", None)
        if isinstance(mod, str):
            mn = mod.lower()
            data["modality"] = "treadmill" if ("tread" in mn or "run" in mn) else ("bike" if ("bike" in mn or "cycle" in mn) else mod)

    if not data["test_date"] and grid is not None and grid.shape[0]>2 and grid.shape[1]>5:
        try:
            y_raw = grid.iat[2,1]  # B3
            m_raw = grid.iat[2,3]  # D3
            d_raw = grid.iat[2,5]  # F3
            y = int(float(str(y_raw).strip()))
            def month_to_num(m):
                s = str(m).strip()
                try:
                    n = int(float(s))
                    if 1 <= n <= 12: return n
                except: pass
                months = {"jan":1,"january":1,"feb":2,"february":2,"mar":3,"march":3,"apr":4,"april":4,
                          "may":5,"jun":6,"june":6,"jul":7,"july":7,"aug":8,"august":8,
                          "sep":9,"sept":9,"september":9,"oct":10,"october":10,
                          "nov":11,"november":11,"dec":12,"december":12}
                key = re.sub(r"[^a-z]", "", s.lower())
                return months.get(key)
            m = month_to_num(m_raw)
            d = int(float(str(d_raw).strip()))
            if y and m and d:
                data["test_date"] = f"{y:04d}-{m:02d}-{d:02d}"
        except Exception:
            pass

    if not data["test_date"]:
        m = re.search(r"(20\d{2})(\d{2})(\d{2})[_\-]?\d{4}", filename or "", re.I)
        if m:
            y, mo, d = m.groups()
            try:
                data["test_date"] = f"{int(y):04d}-{int(mo):02d}-{int(d):02d}"
            except Exception:
                pass

    # Normalize if header-scan filled raw units
    if data["height_cm"] not in (None,""):
        data["height_cm"] = _height_to_cm(data["height_cm"])
    if data["mass_kg"] not in (None,""):
        data["mass_kg"] = _mass_to_kg(data["mass_kg"])

    if not data.get("subject_id"):
        error = "Missing required: subject_id"

    return data, warnings, error

# -------------------- UI --------------------
def Toolbar():
    return dmc.Paper(withBorder=True, shadow="xs", radius="xl", p="md", mb="md",
        children=dmc.Group(justify="space-between", align="center", children=[
            dmc.Text("CPET Directory", fw=700, size="lg"),
            dmc.Group(gap="sm", align="center", children=[
                dmc.TextInput(id="search", placeholder="Search by subject, name, study, or modality…", leftSection="🔎", w=360, size="sm"),
                dmc.Select(id="sort-by", size="sm", w=200, value="test_date",
                           data=[{"value":k, "label":v} for k,v in SORT_FIELDS.items()]),
                dmc.SegmentedControl(id="sort-dir", size="sm", value="desc",
                                     data=[{"value":"asc","label":"Asc"},{"value":"desc","label":"Desc"}]),
                dcc.Upload(
                    id="upload-add",
                    children=dmc.Button("Add New Entry", leftSection="➕", variant="filled", color="blue"),
                    multiple=False,
                    accept=".xls,.xlsx,.csv,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet,text/csv",
                    style={"display":"inline-block"}
                ),
            ])
        ])
    )

def DirectoryTable(rows):
    # Helpers for alignment & widths
    def TH(text, minw=None, align="left"):
        style = {"minWidth": minw} if minw else {}
        if align == "right": style["textAlign"] = "right"
        elif align == "center": style["textAlign"] = "center"
        return html.Th(text, style=style)

    def TD(val, minw=None, align="left"):
        style = {"minWidth": minw} if minw else {}
        if align == "right": style["textAlign"] = "right"
        elif align == "center": style["textAlign"] = "center"
        return html.Td("—" if val in (None, "") else val, style=style)

    head = html.Thead(html.Tr([
        TH("Subject ID", "140px", "center"),   # centered
        TH("Name", "190px", "center"),         # centered
        TH("Study", "120px", "center"),
        TH("Sex", "60px", "center"),
        TH("Age", "70px", "center"),
        TH("Mass (kg)", "100px", "center"),    # centered
        TH("Height (cm)", "110px", "center"),
        TH("Test Date", "110px", "center"),
        TH("Modality", "110px", "center"),
        TH("Actions", "210px", "center"),
    ]))

    body = []
    for r in rows:
        action_bar = html.Div(
            [
                dmc.Button("Open",  size="xs", variant="light",
                           id={"type": "open-btn", "row_id": r["id"]}),
                dmc.Button("Edit",  size="xs", variant="light", color="gray",
                           id={"type": "edit-btn", "row_id": r["id"]}),
                dmc.Button("Delete", size="xs", variant="outline", color="red",
                           id={"type": "delete-btn", "row_id": r["id"]}),
            ],
            style={"display":"flex","gap":"10px","justifyContent":"center",
                   "alignItems":"center","flexWrap":"nowrap","whiteSpace":"nowrap"},
        )

        body.append(html.Tr([
            TD(r.get("subject_id"), "140px", "center"),   # centered
            TD(r.get("name"), "190px", "center"),         # centered
            TD(r.get("study"), "120px", "center"),
            TD(r.get("sex"), "60px", "center"),
            TD(r.get("age"), "70px", "center"),
            TD(r.get("mass_kg"), "100px", "center"),      # centered
            TD(r.get("height_cm"), "110px", "center"),
            TD(fmt_date(r.get("test_date")), "110px", "center"),
            TD(r.get("modality"), "110px", "center"),
            html.Td(action_bar, style={"minWidth":"210px","textAlign":"center"}),
        ]))

    table = dmc.Table(
        [head, html.Tbody(body)],
        striped=True,
        highlightOnHover=True,
        withTableBorder=True,
        withRowBorders=True,
        horizontalSpacing="md",
        verticalSpacing="xs",
        tabularNums=True,
        style={"tableLayout":"auto","width":"100%"},
    )

    return dmc.Paper(
        withBorder=True, shadow="sm", radius="xl", p="md",
        children=dmc.ScrollArea(table, type="always", offsetScrollbars=True),
    )

def EditModal():
    def ti(lbl, fid, placeholder="", **kw):
        return dmc.TextInput(label=lbl, id=f"edit-{fid}", placeholder=placeholder, size="sm", **kw)
    return dmc.Modal(
        id="modal-edit", opened=False, title="Edit Entry", size="lg",
        children=dmc.Stack(gap="sm", children=[
            dmc.Group(gap="sm", grow=True, children=[
                ti("Subject ID", "subject_id"),
                ti("Name", "name"),
                ti("Study", "study"),
            ]),
            dmc.Group(gap="sm", grow=True, children=[
                ti("Sex", "sex"),
                ti("Age", "age"),
                ti("Mass (kg)", "mass_kg"),
            ]),
            dmc.Group(gap="sm", grow=True, children=[
                ti("Height (cm)", "height_cm"),
                ti("Test Date", "test_date", placeholder="YYYY-MM-DD"),
                ti("Modality", "modality", placeholder="bike / treadmill"),
            ]),
            dmc.Group(justify="flex-end", children=[
                dmc.Button("Cancel", id="edit-cancel", variant="light", color="gray"),
                dmc.Button("Save", id="edit-save", color="blue"),
            ]),
        ])
    )

def DeleteModal():
    return dmc.Modal(
        id="modal-delete", opened=False, title="Delete entry?",
        children=dmc.Stack(gap="sm", children=[
            dmc.Text("This will permanently remove the participant from your directory.", c="red"),
            dmc.Group(justify="flex-end", children=[
                dmc.Button("Cancel", id="delete-cancel", variant="light"),
                dmc.Button("Delete", id="delete-confirm", color="red"),
            ])
        ])
    )

def ImportModal():
    return dmc.Modal(
        id="modal-import", opened=False, title="Import result",
        children=dmc.Stack(gap="sm", children=[
            dmc.Alert(id="import-alert", title="", color="blue", variant="light", children=""),
            dmc.Group(justify="flex-end", children=[dmc.Button("Close", id="import-close")])
        ])
    )

# -------------------- Dash App --------------------
def DirectoryScreen():
    return [
        Toolbar(),
        dcc.Store(id="refresh-token", data=0),
        dcc.Store(id="edit-row-id"),
        dcc.Store(id="delete-row-id"),
        dcc.Store(id="open-clicks-prev", data={}),
        dcc.Store(id="edit-clicks-prev", data={}),
        dcc.Store(id="delete-clicks-prev", data={}),
        ImportModal(),
        EditModal(),
        DeleteModal(),
        html.Div(id="table-container"),
    ]

def make_directory_app():
    init_db()
    app = dash.Dash(__name__, title="CPET Directory", suppress_callback_exceptions=True)

    app.layout = dmc.MantineProvider(
        theme={"fontFamily": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif",
            "defaultRadius": "xl"},
        children=dmc.Container(size=1460, px="md", children=[
            # routing state
            dcc.Store(id="route", data="directory"),
            dcc.Store(id="selected-row-id"),
            # where we render either the directory or the dashboard
            html.Div(id="router-outlet", children=DirectoryScreen())
        ])
    )
    # Swap the visible view
    @app.callback(
        Output("router-outlet", "children"),
        Input("route", "data"),
        prevent_initial_call=False
    )
    def route_view(route):
        if route == "dashboard":
            return dashboard_view()  # reuse the layout you exposed
        return DirectoryScreen() 

    @app.callback(
        Output("route", "data", allow_duplicate=True),
        Input("btn-back", "n_clicks"),
        prevent_initial_call=True
    )
    def go_back(n):
        if not n:
            raise dash.exceptions.PreventUpdate
        return "directory"

    # Refresh table
    @app.callback(
        Output("table-container", "children"),
        Input("search", "value"),
        Input("sort-by", "value"),
        Input("sort-dir", "value"),
        Input("refresh-token", "data"),
        prevent_initial_call=False
    )
    def refresh_table(search, sort_by, sort_dir, _):
        rows = list_participants(search or "", sort_by or "test_date", sort_dir or "desc")
        return DirectoryTable(rows)

    @app.callback(
        Output("modal-import", "opened", allow_duplicate=True),
        Output("import-alert", "title", allow_duplicate=True),
        Output("import-alert", "color", allow_duplicate=True),
        Output("import-alert", "children", allow_duplicate=True),
        Output("refresh-token", "data", allow_duplicate=True),
        Input("upload-add", "contents"),
        State("upload-add", "filename"),
        State("refresh-token", "data"),
        prevent_initial_call=True
    )
    def handle_upload(contents, filename, refresh):
        if not contents:
            raise dash.exceptions.PreventUpdate

        # Parse file
        data, warnings, error = parse_excel_or_csv(contents, filename)

        # If parser flagged a hard error (e.g., missing subject_id), show red alert
        if error:
            details = [dmc.Text(f"Error: {error}", c="red", fw=600)]
            if warnings:
                details.append(dmc.Text("Warnings:", fw=600))
                details.extend(dmc.Text(f"• {w}") for w in warnings)
            return True, "Import failed", "red", dmc.Stack(children=details, gap=6), refresh or 0

        # Deduplicate on (subject_id, test_date)
        try:
            conn = sqlite3.connect(DB_PATH); c = conn.cursor()
            c.execute(
                "SELECT id FROM participants WHERE subject_id=? AND IFNULL(test_date,'')=?",
                (data.get("subject_id") or "", data.get("test_date") or "")
            )
            exists = c.fetchone() is not None
            conn.close()
        except Exception:
            exists = False

        if exists:
            # Don’t double-add the same test
            msg = f"An entry for subject '{data.get('subject_id','?')}' on '{data.get('test_date','—')}' already exists. No changes made."
            return True, "Already exists", "yellow", dmc.Text(msg), refresh or 0

        # Insert and refresh
        insert_participant(data)


        ok = [
            dmc.Text(f"Imported: {filename or 'file'}", fw=600),
            dmc.Text(f"Subject ID: {data.get('subject_id') or '—'}"),
            dmc.Text(f"Name: {data.get('name') or '—'}"),
            dmc.Text(f"Test Date: {data.get('test_date') or '—'}"),
            dmc.Text(f"Study: {data.get('study') or '—'}"),
            dmc.Text(f"Modality: {data.get('modality') or '—'}"),
        ]
        if warnings:
            ok.append(dmc.Space(h=6))
            ok.append(dmc.Text("Warnings:", fw=600))
            ok.extend(dmc.Text(f"• {w}") for w in warnings)

        return True, "Import successful", "green", dmc.Stack(children=ok, gap=4), (refresh or 0) + 1

    from dash import ALL

    @app.callback(
        Output("route", "data", allow_duplicate=True),
        Output("selected-row-id", "data", allow_duplicate=True),
        Output("open-clicks-prev", "data"),
        Input({"type": "open-btn", "row_id": ALL}, "n_clicks"),
        State({"type": "open-btn", "row_id": ALL}, "id"),
        State("open-clicks-prev", "data"),
        prevent_initial_call=True
    )
    def on_open_click(n_list, id_list, prev_map):
        # Normalize
        n_list = [(n or 0) for n in (n_list or [])]
        id_list = id_list or []
        prev_map = dict(prev_map or {})

        if not n_list or not id_list:
            raise dash.exceptions.PreventUpdate

        # Current map of row_id -> n_clicks
        curr_map = { str(id_list[i]["row_id"]): n_list[i] for i in range(len(id_list)) }

        # Find which row actually increased
        deltas = { rid: curr_map[rid] - prev_map.get(rid, 0) for rid in curr_map }
        rid_clicked = max(deltas, key=lambda k: deltas[k]) if deltas else None

        if not rid_clicked or deltas[rid_clicked] <= 0:
            # No real click (likely a re-render from search/sort)
            return dash.no_update, dash.no_update, curr_map

        return "dashboard", int(rid_clicked), curr_map

    @app.callback(
        Output("modal-edit", "opened", allow_duplicate=True),
        Output("edit-row-id", "data", allow_duplicate=True),
        Output("modal-delete", "opened", allow_duplicate=True),
        Output("delete-row-id", "data", allow_duplicate=True),
        Output("edit-clicks-prev", "data"),
        Output("delete-clicks-prev", "data"),
        Input({"type":"edit-btn","row_id": ALL}, "n_clicks"),
        Input({"type":"delete-btn","row_id": ALL}, "n_clicks"),
        State({"type":"edit-btn","row_id": ALL}, "id"),
        State({"type":"delete-btn","row_id": ALL}, "id"),
        State("edit-clicks-prev","data"),
        State("delete-clicks-prev","data"),
        prevent_initial_call=True
    )
    def handle_row_actions(edit_n, delete_n, edit_ids, delete_ids, prev_edit_map, prev_del_map):
        # Normalize
        edit_n = [(x or 0) for x in (edit_n or [])]; edit_ids = edit_ids or []
        delete_n = [(x or 0) for x in (delete_n or [])]; delete_ids = delete_ids or []
        prev_edit_map = dict(prev_edit_map or {})
        prev_del_map  = dict(prev_del_map  or {})

        # Build current maps
        curr_edit = { str(edit_ids[i]["row_id"]): edit_n[i] for i in range(len(edit_ids)) }
        curr_del  = { str(delete_ids[i]["row_id"]): delete_n[i] for i in range(len(delete_ids)) }

        # Compute deltas
        e_deltas = { rid: curr_edit[rid] - prev_edit_map.get(rid, 0) for rid in curr_edit }
        d_deltas = { rid: curr_del[rid]  - prev_del_map.get(rid, 0)  for rid in curr_del }

        # Prefer whichever had a real new click
        e_rid = max(e_deltas, key=lambda k: e_deltas[k]) if e_deltas else None
        d_rid = max(d_deltas, key=lambda k: d_deltas[k]) if d_deltas else None

        if e_rid and e_deltas[e_rid] > 0:
            return True, int(e_rid), dash.no_update, dash.no_update, curr_edit, curr_del

        if d_rid and d_deltas[d_rid] > 0:
            return dash.no_update, dash.no_update, True, int(d_rid), curr_edit, curr_del

        # No real click—just update the maps
        return dash.no_update, dash.no_update, dash.no_update, dash.no_update, curr_edit, curr_del

    @app.callback(Output("modal-import","opened"), Input("import-close","n_clicks"), prevent_initial_call=True)
    def close_import(_): return False

    # Populate edit modal
    @app.callback(
        *(Output(f"edit-{fid}", "value") for fid in [
            "subject_id","name","study","sex","age","mass_kg","height_cm","test_date","modality"
        ]),
        Input("modal-edit", "opened"),
        State("edit-row-id","data"),
        prevent_initial_call=True
    )
    def fill_edit_fields(opened, rid):
        if not opened or not rid:
            raise dash.exceptions.PreventUpdate
        row = get_participant(int(rid))
        return (
            row.get("subject_id"), row.get("name"), row.get("study"), row.get("sex"),
            (row.get("age") if row.get("age") is not None else ""),
            (row.get("mass_kg") if row.get("mass_kg") is not None else ""),
            (row.get("height_cm") if row.get("height_cm") is not None else ""),
            row.get("test_date"), row.get("modality"),
        )

    # Save edit
    @app.callback(
        Output("modal-edit", "opened", allow_duplicate=True),
        Output("refresh-token", "data", allow_duplicate=True),
        Input("edit-save","n_clicks"),
        State("edit-row-id","data"),
        State("edit-subject_id","value"), State("edit-name","value"), State("edit-study","value"),
        State("edit-sex","value"),
        State("edit-age","value"), State("edit-height_cm","value"), State("edit-mass_kg","value"),
        State("edit-test_date","value"), State("edit-modality","value"),
        State("refresh-token","data"),
        prevent_initial_call=True
    )
    def save_edit(n, rid, subject_id, name, study, sex, age, height_cm, mass_kg, test_date, modality, refresh):
        if not n or not rid:
            raise dash.exceptions.PreventUpdate
        existing = get_participant(int(rid)) or {}
        data = {
            "subject_id": (subject_id or "").strip(),
            "name": (name or "").strip(),
            "study": (study or "").strip(),
            "sex": (sex or "").strip(),
            "age": int(float(age)) if age not in (None,"") else None,
            "height_cm": float(height_cm) if height_cm not in (None,"") else None,
            "mass_kg": float(mass_kg) if mass_kg not in (None,"") else None,
            "test_date": (test_date or "").strip(),
            "modality": (modality or "").strip(),
            "rer_max": None, "hr_peak": None, "hr_pct_max": None,
            "critical_power": None,
            "file_name": "",
            "file_path": existing.get("file_path"),
        }
        update_participant(int(rid), data)
        return False, (refresh or 0) + 1

    @app.callback(Output("modal-edit","opened"), Input("edit-cancel","n_clicks"), prevent_initial_call=True)
    def cancel_edit(n):
        if not n: raise dash.exceptions.PreventUpdate
        return False
    
    # Delete (confirm/cancel) — closes modal and refreshes table
    @app.callback(
        Output("modal-delete", "opened", allow_duplicate=True),
        Output("refresh-token", "data", allow_duplicate=True),
        Input("delete-confirm", "n_clicks"),
        Input("delete-cancel", "n_clicks"),
        State("delete-row-id", "data"),
        State("refresh-token", "data"),
        prevent_initial_call=True
    )
    def on_delete(confirm, cancel, rid, refresh):
        trigger = ctx.triggered_id
        if trigger == "delete-cancel":
            # Just close the modal, no refresh
            return False, dash.no_update
        if trigger == "delete-confirm" and (confirm or 0) > 0 and rid:
            delete_participant(int(rid))
            # Close modal and bump refresh-token so the table reloads
            return False, (refresh or 0) + 1
        raise dash.exceptions.PreventUpdate

    # ↓↓↓ NEW: build all five figures + the threshold tile when a row is opened,
    #          and honor the legend menus on each card.
    @app.callback(
        Output("fig-vslope","figure"),
        Output("fig-vo2","figure"),
        Output("fig-ve-equiv","figure"),
        Output("fig-pet","figure"),
        Output("fig-rer","figure"),
        Output("threshold-table","children"),
        Input("route","data"),
        State("selected-row-id","data"),
        Input("vt-overrides-version","data"),
        Input("legend-vslope","value"),  # ["points","slope","vt1","vt2"]
        Input("legend-vo2","value"),     # ["points","trace","vt1","vt2"]
        Input("legend-veeq","value"),    # ["vevo2","vevco2","vt1","vt2"]
        Input("legend-pet","value"),     # ["peto2","petco2","vt1","vt2"]
        Input("legend-rer","value"),     # ["rer","vt1","vt2"]
        prevent_initial_call=False
    )
    def _render_dashboard(route, rid, _override_version, vslope_opts, vo2_opts, veeq_opts, pet_opts, rer_opts):
        import plotly.graph_objects as go

        # nice placeholder when nothing is selected yet
        def _empty(msg="Open a test from the Directory to see graphs."):
            f = go.Figure()
            f.update_layout(margin=dict(l=12, r=12, t=8, b=12), height=260,
                            annotations=[dict(text=msg, x=0.5, y=0.5, xref="paper", yref="paper",
                                              showarrow=False, align="center")])
            return f

        if route != "dashboard" or not rid:
            msg = "Open a test from the Directory to see graphs."
            return _empty(msg), _empty(msg), _empty(msg), _empty(msg), _empty(msg), html.Div()

        row = get_participant(int(rid)) or {}
        path = (row.get("file_path") or "").strip()
        if not path:
            msg = "No file attached to this row."
            return _empty(msg), _empty(msg), _empty(msg), _empty(msg), _empty(msg), html.Div()

        try:
            overrides = get_vt_overrides(int(rid)) if rid else {}
            figs, vt_table_data = build_figures_from_file(path, overrides=overrides)
        except Exception as e:
            msg = f"Could not render from file.<br>{e}"
            return _empty(msg), _empty(msg), _empty(msg), _empty(msg), _empty(msg), html.Div()

        # normalize selections
        vslope_opts = set(vslope_opts or [])
        vo2_opts    = set(vo2_opts or [])
        veeq_opts   = set(veeq_opts or [])
        pet_opts    = set(pet_opts or [])
        rer_opts    = set(rer_opts or [])

        # helper: toggle visibility using legendgroup first, then by name
        def _apply(fig, mapping: dict):
            g = go.Figure(fig)
            for tr in g.data:
                lg = getattr(tr, "legendgroup", None)
                if lg in mapping:
                    tr.visible = bool(mapping[lg])
                elif tr.name in mapping:
                    tr.visible = bool(mapping[tr.name])
                # else: leave default visibility
            return g

        # V-Slope  (segments have legendgroup="slope"; points are named "VCO₂–VO₂ points")
        figs["vslope"] = _apply(figs["vslope"], {
            "slope":             ("slope"  in vslope_opts),
            "VCO₂–VO₂ points":   ("points" in vslope_opts),
            "VT1":               ("vt1"    in vslope_opts),
            "VT2":               ("vt2"    in vslope_opts),
        })

        # VO₂ vs Time  (points -> legendgroup "points", trendline -> "trace")
        figs["vo2"] = _apply(figs["vo2"], {
            "points":  ("points" in vo2_opts),
            "trace":   ("trace"  in vo2_opts),
            "VT1":     ("vt1"    in vo2_opts),
            "VT2":     ("vt2"    in vo2_opts),
        })

        # VE/VO₂ & VE/VCO₂
        figs["veeq"] = _apply(figs["veeq"], {
            "vevo2_pts":  ("vevo2_pts"  in veeq_opts),
            "vevo2_tr":   ("vevo2_tr"   in veeq_opts),
            "vevco2_pts": ("vevco2_pts" in veeq_opts),
            "vevco2_tr":  ("vevco2_tr"  in veeq_opts),
            "VT1":        ("vt1"        in veeq_opts),
            "VT2":        ("vt2"        in veeq_opts),
        })

        # PetO₂ / PetCO₂
        figs["pet"] = _apply(figs["pet"], {
            "peto2_pts":  ("peto2_pts"  in pet_opts),
            "peto2_tr":   ("peto2_tr"   in pet_opts),
            "petco2_pts": ("petco2_pts" in pet_opts),
            "petco2_tr":  ("petco2_tr"  in pet_opts),
            "VT1":        ("vt1"        in pet_opts),
            "VT2":        ("vt2"        in pet_opts),
        })

        # RER
        figs["rer"] = _apply(figs["rer"], {
            "rer_pts":    ("rer_pts"    in rer_opts),
            "rer_tr":     ("rer_tr"     in rer_opts),
            "VT1":        ("vt1"        in rer_opts),
            "VT2":        ("vt2"        in rer_opts),
        })

        return (
            figs["vslope"],
            figs["vo2"],
            figs["veeq"],
            figs["pet"],
            figs["rer"],
            threshold_detection_table(vt_table_data),
        )

    @app.callback(
        Output("modal-vt-edit", "opened"),
        Output("vt-edit-state", "data"),
        Output("vt-edit-graph", "figure"),
        Output("vt-edit-threshold", "children"),
        Output("vt-edit-undo", "disabled"),
        Output("vt-edit-redo", "disabled"),
        Output("vt-edit-save", "disabled"),
        Output("vt-edit-title", "children"),
        Output("vt-overrides-version", "data"),
        Input("btn-edit-vt", "n_clicks"),
        Input("vt-edit-close", "n_clicks"),
        Input("vt-edit-prev", "n_clicks"),
        Input("vt-edit-next", "n_clicks"),
        Input("vt-edit-graph", "relayoutData"),
        Input("vt-edit-undo", "n_clicks"),
        Input("vt-edit-redo", "n_clicks"),
        Input("vt-edit-save", "n_clicks"),
        State("modal-vt-edit", "opened"),
        State("vt-edit-state", "data"),
        State("route", "data"),
        State("selected-row-id", "data"),
        State("vt-overrides-version", "data"),
        prevent_initial_call=True,
    )
    def _handle_vt_edit(
        btn_open,
        btn_close,
        btn_prev,
        btn_next,
        relayout,
        btn_undo,
        btn_redo,
        btn_save,
        opened,
        state_data,
        route,
        rid,
        version,
    ):
        triggered = ctx.triggered_id
        version_in = version or 0
        version_out = dash.no_update

        if triggered is None:
            raise dash.exceptions.PreventUpdate

        state = copy.deepcopy(state_data) if state_data else None

        if triggered == "vt-edit-close":
            return False, None, dash.no_update, dash.no_update, True, True, True, dash.no_update, dash.no_update

        if triggered == "btn-edit-vt":
            if route != "dashboard" or not rid:
                raise dash.exceptions.PreventUpdate
            path = _get_path_for_id(int(rid))
            if not path:
                raise dash.exceptions.PreventUpdate
            try:
                analysis = compute_cpet_analysis(path)
                overrides = get_vt_overrides(int(rid))
                context = compute_vt_context(analysis, overrides)
            except Exception:
                raise dash.exceptions.PreventUpdate

            state = _init_edit_state(int(rid), analysis, context)
            active = state["active"]
            fig, meta = _build_edit_figure(active, state["analysis"], state["graphs"][active])
            state["graphs"][active]["meta"] = meta
            analysis_current = analysis_from_store(state["analysis"])
            context_current = compute_vt_context(analysis_current, _graphs_to_overrides(state["graphs"]))
            table = threshold_detection_table(context_current["vt_table_data"], highlight=EDIT_HIGHLIGHT.get(active, {}))
            return (
                True,
                state,
                fig,
                table,
                True,
                True,
                True,
                EDIT_GRAPH_LABELS.get(active, "Edit"),
                dash.no_update,
            )

        if state is None:
            raise dash.exceptions.PreventUpdate

        active = state.get("active", "vslope")
        needs_refresh = False

        if triggered in ("vt-edit-prev", "vt-edit-next"):
            order = EDIT_GRAPH_ORDER
            try:
                idx = order.index(active)
            except ValueError:
                idx = 0
            if triggered == "vt-edit-prev":
                idx = (idx - 1) % len(order)
            else:
                idx = (idx + 1) % len(order)
            state["active"] = order[idx]
            active = state["active"]
            needs_refresh = True

        if triggered == "vt-edit-graph" and relayout:
            new_state, changed = _apply_relayout(state, active, relayout)
            if changed:
                state = new_state
                needs_refresh = True

        if triggered == "vt-edit-undo":
            new_state, changed = _perform_undo(state, active)
            if changed:
                state = new_state
                needs_refresh = True

        if triggered == "vt-edit-redo":
            new_state, changed = _perform_redo(state, active)
            if changed:
                state = new_state
                needs_refresh = True

        if triggered == "vt-edit-save":
            row_id = state.get("row_id")
            if row_id:
                state["graphs"][active]["saved"] = copy.deepcopy(state["graphs"][active]["current"])
                overrides_to_save = _graphs_to_overrides(state["graphs"], use_saved=True)
                save_vt_overrides(int(row_id), overrides_to_save)
                version_new = version_in + 1
                version_out = version_new
                needs_refresh = True
                version_in = version_new

        if not needs_refresh:
            raise dash.exceptions.PreventUpdate

        active = state.get("active", "vslope")
        fig, meta = _build_edit_figure(active, state["analysis"], state["graphs"][active])
        state["graphs"][active]["meta"] = meta

        analysis_current = analysis_from_store(state["analysis"])
        context_current = compute_vt_context(analysis_current, _graphs_to_overrides(state["graphs"]))
        table = threshold_detection_table(context_current["vt_table_data"], highlight=EDIT_HIGHLIGHT.get(active, {}))

        graph_state = state["graphs"][active]
        undo_disabled = not bool(graph_state.get("undo"))
        redo_disabled = not bool(graph_state.get("redo"))
        save_disabled = _graph_states_equal(graph_state.get("current", {}), graph_state.get("saved", {}))

        return (
            True,
            state,
            fig,
            table,
            undo_disabled,
            redo_disabled,
            save_disabled,
            EDIT_GRAPH_LABELS.get(active, "Edit"),
            version_out,
        )
    return app

# -------------------- pywebview wrapper --------------------
def run_directory_desktop():
    import webview
    app = make_directory_app()
    port = find_free_port(8050)
    url = f"http://127.0.0.1:{port}"

    def serve():
        app.run(debug=False, host="127.0.0.1", port=port)

    th = threading.Thread(target=serve, daemon=True); th.start()

    if not wait_for_server("127.0.0.1", port, timeout=20):
        webview.create_window("CPET Directory – server failed to start",
                              html="<h3>Server failed to start.</h3><p>Check if another copy is running or port is blocked.</p>",
                              width=520, height=240)
        webview.start()
        sys.exit(1)

    webview.create_window("CPET Directory", url, width=1350, height=900, resizable=True, confirm_close=True)
    webview.start()

if __name__ == '__main__':
    run_directory_desktop()
